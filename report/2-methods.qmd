<!--

Research methods and justification:
Excellent description of data or methods, excellent methodological understanding, research is reproducible.

 -->

## Data {#sec-data}

All data is retrieved for the timespan from 2020 to 2022. This is because the _ACLED_ data is not available earlier, and the _DeReKo_ data is only released yearly with some delay, and not yet available for 2023 at the time of writing. All data sources are expected to be available for the next years, with the exception of data related to the COVID-19 pandemic.

```{python}
# | echo: false

import matplotlib.pyplot as plt
import pandas as pd
from matplotlib_inline.backend_inline import set_matplotlib_formats

set_matplotlib_formats("svg")

from src.data.protests import (
    load_climate_protests_with_labels,
    load_protests,
)

query = "date.dt.year in [2020, 2021, 2022] & country == 'Germany'"
protests = load_protests().query(query)
climate_protests = load_climate_protests_with_labels().query(query)
```

### Protest events

There are generally two source types for protest events:

1. __Newspaper articles__ are primarily used in the existing literature. [@hutterProtestEventAnalysis2014] give a historical and systematic overview and highlight the problem that this source is biased. They describe how several definitions for protest event analysis (PEA) and the broader political claim analysis (PCA), as well as associated coding practices have helped to formalize the (manual) data extraction process, such that results have become more valid and comparable.

2. __Police archives.__ The literature dismisses this source type as "biased", uninformative about the motives and organizers, uncomparable across regions, often unavailable or unobtainable, and because it is restricted to only registered demonstrations (Hutter 2014; @ProtestlandschaftDeutschland; @wiedemannGeneralizedApproachProtest2022). This criticism appears to me valid but overgeneralized, and there may well be regions where the advantages prevail over the problems. Especially for the goal of impact estimation, the avoidance of selection biases that are associated with newspaper articles [Hutter 2014; @jamesozdenLiteratureReviewProtest2022] is a strong argument for using data from police and demonstration authorities.

```{python}
# | label: fig-protest-history
# | fig-cap: History of the number of protest events in Germany per week.
# | column: page
# | echo: false

df = climate_protests.copy()
df = (
    df.groupby(["date", "source"])["actor"]
    .count()
    .unstack()
    .fillna(0)
    .astype(int)
    .reset_index()
)
df = df.set_index("date")
df = df.rename(columns=dict(acled="ACLED", gpreg="GPReg"))
df = df.resample("1W").sum()
df.plot(
    figsize=(14, 1.5),
    title="Number of climate protests in Germany per week",
    linewidth=1,
    ylabel="#protests",
)
plt.show()
```

#### ACLED and other existing protest datasets {#sec-acled}

My main data source for protest events is the [_Armed Conflict Location and Event Dataset_](https://acleddata.com/) (ACLED; @raleighIntroducingACLEDArmed2010a). ACLED is a grand effort that keeps track not only of violent conflicts and riots, but also of ordinary protest events. The data is human-curated based on newspaper reports, and contains coded information on dates, locations, actor groups, police interventions, and more, as well as a short free-text summary for each event, containing an estimate of the size as per the newspaper data source. Data for Germany is available starting from 2020 and is continuously updated. For the period from 2020-2022, it contains 13235 protest events, 1314 of which are organized by climate protest groups or mention the climate in their description.

<!-- For the period from 2020-2022, it contains `{python} len(protests.query("source == 'acled'"))` protest events, `{python} len(climate_protests.query("source == 'acled'"))` of which are organized by climate protest groups or mention the climate in their description. -->

Alternative existing sources of German or international protest data comprise [ProDat](https://www.wzb.eu/de/forschung/beendete-forschungsprogramme/zivilgesellschaft-und-politische-mobilisierung/projekte/prodat-dokumentation-und-analyse-von-protestereignissen-in-der-bundesrepublik)^[See also [Protestlandschaft Deutschland](https://protestdata.eu/methods). for additional data and interactive visualizations], [PolDem](https://poldem.eui.eu/download/protest-events/), the [Mass Mobilization Project](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HTTWYL), and the event database [GDELT](https://www.gdeltproject.org/). They do not cover recent years or are not very complete, and therefore inferior to ACLED for my purposes.

#### The German Protest Registrations dataset


\begingroup
\scriptsize\selectfont
```{python}
# | label: tbl-protest-groups
# | tbl-cap: Number of protest events 2020-2022 by protest group in the different data sources.
# | column: margin
# | echo: false

from src.data.protests.keywords import abbreviations
from IPython.display import Markdown

df = climate_protests.copy()
df = (
    df.groupby(["actor", "source"])["date"]
    .count()
    .unstack()
    .rename_axis(None, axis=1)
    .fillna(0)
    .astype(int)
    .reset_index()
)
df["actor"] = df["actor"].apply(lambda x: abbreviations[x])
df = df.rename(columns=dict(acled="ACLED", gpreg="GPReg"))
df["GPRep"] = "?"
df = df.sort_values("actor")
df = df.set_index("actor")
df.index.name = None
Markdown(df.to_markdown())
```
\endgroup

Protest statistics are often recorded by public authorities, either when organizers register a future demonstrations, or when the police reports about a past demonstration. Registering a demonstration is a common requirement for exercising the right to protest in European countries, however this requirement is only fulfilled by moderate protests, while more radical protests may purposefully ignore it and are thus not listed in such records. Often the estimated number of expected protesters is also recorded, but it is of course not reliable, and reliability may vary between different protest organizers. Police estimates of past demonstrations should be more reliable and consistent, however with the possibility for systematic bias, such as generally downplaying the number of participants, or specifically downplaying the number of participants for protests that are critical of the government or the police themselves.

\begingroup
\scriptsize\selectfont
```{python}
# | label: tbl-protest-most-common
# | tbl-cap: Number of protest events for the five most busy climate protest days 2020-2022; they are concentrated around the spring and autumn equinoxes. (More esoteric future work might explore the astrological determinants of protest activity.)
# | column: margin
# | echo: false

df = climate_protests.copy()
df = (
    df.groupby(["date", "source"])["notes"]
    .count()
    .unstack()
    .fillna(0)
    .astype(int)
    .reset_index()
)
df = df.set_index("date")
df["mean"] = (df["acled"] + df["gpreg"]) / 2
df = df.sort_values("mean", ascending=False)
df = df.drop(columns=["mean"])
df = df.head(5).sort_values("date")
df = df.reset_index()
df["date"] = df["date"].dt.strftime("%Y-%m-%d")
df = df.rename(columns=dict(acled="ACLED", gpreg="GPReg"))
df = df.set_index("date")
df.index.name = None
df = df.rename_axis(None, axis=1)
df["GPRep"] = "?"
Markdown(df.to_markdown())
```
\endgroup

Official documents, including protest statistics, can be obtained via _Freedom of Information_ laws. These exist in more than 100 countries and allow anyone to obtain public documents [@FreedomInformationLaws2023]. The specific requirements, exceptions, and costs vary greatly. In Germany, freedom of information exists on the federal level; but many authorities belong to the regional level, where the extent of freedom of information rights varies greatly [@InformationsfreiheitDeutschlandTransparenzranking]; and municipal authorities are not always covered by regional freedom of information laws, sometimes filling the gap with their own legislation.

Access to public documents has been democratized via platforms that streamline the process of sending requests, escalating the process to oversight authorities or courts if necessary, and making communication and obtained documents available to the public. The [Alaveteli](http://alaveteli.org/) network provides software and hosts such platforms in more than 30 countries across the world. Some independent platforms also exist, such as [Öffentlichkeitsgestz.ch](https://www.oeffentlichkeitsgesetz.ch/) in Switzerland, and _FragDenStaat_ [in Austria](https://fragdenstaat.at/) and [in Germany](https://fragdenstaat.de/). These open the possibility of obtaining official protest data at scale.

__Collection.__ I send 40 freedom of information requests to German demonstration authorities (depending on the region these are either part of the municipal administrations or of the police) and their supervisory bodies concerning protest data in 31 cities. These cities comprise the political capitals of all 16 regions in Germany, the 17 largest cities by population size, as well as some smaller cities for regions where the request in the regional capital is unsuccessful. 4 requests are not answered, 3 are rejected, 11 state that they do not possess such data, 2 have to be withdrawn due to demanded payments of multiple hundreds of euros, and 20 are been partially or completely successful. This yields 17 table documents with various amounts of information. The requests and responses including the original data files can be found at [FragDenStaat](https://fragdenstaat.de/anfragen/?q=demonstration+csv&first_after=2022-12-01&first_before=2023-07-31).

__Cleaning.__ I ignore one of the datasets (Augsburg) because I cannot convert the delivered PDF back to a table, two of them (Saarbrücken and Freiburg) because the data is too unstructured or requires too much cleaning, and one (Duisburg) because the data is delivered very late. The remaining 13 data tables are cleaned manually. One common problem is that the tables specify events that have a duration of multiple days, in some cases even multiple months. Out of concern for a simple data structure, as well as doubt whether these demonstrations really lasted so long, I reduce their duration to the single day when they start.

__Dataset__. The resulting dataset contains 49,800 events from 13 cities. For 11 cities the ex-ante number of expected participants are given, and for 2 of them (Berlin and Magdeburg) the ex-post extimates by the police are also included. For all cities the topic of the protest is given in, presumably as specified by the organizers themselves; and for 4 cities the name of the organizing group is also known. Various additional details such as exact specifications of location, time and duration, and distinctions between protest marches and pickets are available for some of the cities but not in any systematic manner. Further statistics about the dataset can be seen in table tbl-official-overview.

{{< embed ../src/data/protests/german_protest_registrations/data_map.ipynb#data-official-map >}}


#### The German Protest Reports dataset

@wiedemannGeneralizedApproachProtest2022 show how to detect protest events in newspaper articles. They employ the [`gelectra-large`](https://huggingface.co/deepset/gelectra-large) model, a transformer model that is fine-tuned on German texts of various genres. Their dataset consists of almost 4000 newspaper articles from 4 German cities, namely Leipzig, Dresden, Stuttgart, and Bremen, from between 2009 and 2016.

__Replication and experiments:__ I replicate their results and obtain F1-scores of 0.93 for in-distribution and 0.76 for out-of-distribution classification, which is almost identical to the authors' results. I try out some alternative approaches on their data: Simple machine learning models based on TFIDF-features; finetuning the more recent multilingual FlanT5 model; and using GPT 3.0 in a zero-shot setting. None of the alternatives perform closely to the `gelectra-large` model (see @tbl-glpn-alternative-methods for metrics).

\begingroup
\small\selectfont

| Model    | id F1 | ood F1 |
|----------|------:|-------:|
| XG-Boost | 0.87  | 0.60   |
| FlanT5   | 0.75  | 0.30   |
| GPT3     | 0.81  | 0.65   |
| gElectra | 0.93  | 0.76   |

: Results for using alternative classification methods on the GLPN dataset, for in-distribution (id) and out-of-distribution (ood) prediction. {#tbl-glpn-alternative-methods .column-margin}

\endgroup

In order to obtain protest events from a broader geographic spectrum, I retrieve metadata of online newspaper articles from MediaCloud (see @sec-mediacloud) for a query containing protest-related keywords.^[The query is based on the query used by Wiedemann, and reads: _'protest* OR demo OR demonstr* OR kundgebung OR versamm* OR "soziale bewegung" OR hausbesetz* OR streik* OR unterschriften* OR petition OR hasskriminalität OR unruhen OR aufruhr OR aufstand OR rebell* OR blockade OR blockier* OR sitzblock* OR boykott* OR riot OR aktivis* OR bürgerinitiative OR bürgerbegehren OR marsch OR aufmarsch OR parade OR mahnwache OR hungerstreik OR "ziviler ungehorsam"'_] From the obtained metadata, I scrape full-texts where possible. Special care is taken of website that appear scrapeable but contain only gibberish, by observing the distribution of letters.

{{< embed ../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-ts >}}

I label the texts myself using [Prodigy](https://prodi.gy/). For the positive class, I require that the article is a report about (potentially among other topics) a recent past protest event, and that basic details including the place and the protest concern are given. The other articles are mostly about completely different topics (such as "protest" but not in the political sense, or "demonstration" in the sense of showing something, "blockade" in a physical context, or the "protest-ant" church); or they mention protests in the context of an op-ed or an interview, where the concreteness and recency of the events is often not given.

{{< embed ../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-sources >}}

In a first labeling phase, I annotate 650 random articles for training and 500 random articles for evaluation. I train the model and use 500 articles that are predicted positive and label them as well and add them to the training data, in order to combat class imbalance. Training the `gelectra-large` model with the overall 1150 training samples and according to the hyperparameters suggested by Wiedemann, I finally obtain an in-distribution F1-score of 0.78 (precision=0.81, recall=0.75). Then, I use this model to predict the relevance of all the other scraped articles that contain protest-related keywords. Only 11% are relevant, resulting in 20,879 articles of which the (relatively good) model believes that they describe protest events.

\begingroup
\color{Red}TODO: Extraction of dates, locations, protest groups.
\endgroup

### Public discourse {#sec-data-discourse}

This thesis focuses on media coverage as an indicator, that is: How many articles are published on a certain date in a certain region that satisfy a certain search query.

__Queries:__ I use queries that allow to examine how many mentions of climate change occur in newspaper articles overall, and how this is further subdivided. I formulate 5 sub-queries (the full word lists are found in @sec-app-queries):

- _Topic:_ Whether an article mentions climate change or climate policy.
- _Protest:_ Whether an article mentions protest activity (including both general terms, and terms and organization names that are specific to the climate movement).
- _Framing:_ Whether more dramatic words than "climate change" are used, such as "climate crisis", "climate catastrophy", etc.
- _Goals_: Whether long-term goals of the climate movement such as carbon neutrality are mentioned.
- _Subsidiary goals:_ Whether more concrete measures such as a speed limit for cars, or a citizen's assembly on climate change are mentioned.

From these sub-queries, I use the _topic_ query as a standalone query, and combine each of the other queries with the _topic_ query to make sure that the terms are actually used in the context of climate change. (Many of the terms have an unambiguous relation to climate change anyway, but some, such as the protest forms or specific solutions, could also appear in other contexts.) I retrieve absolute article counts for each query, aggregated daily on the regional or on the national level.

The queries allow me to study not only research question 2 (how much overall coverage of climate change is affected); but also (to some extent) to investigate research question 3 (whether this does not backfire by focusing the discussion on the protests rather than the policy issues):

- If the article counts for the _topic `and not` protest_^[This query can be derived from the other queries logically.] query remain constant or even increase due to protests, then this is strong evidence that the protests do not backfire; and if it increases, then their effect is very strong such that they cause more discussion even when the protests are not themselves a topic. A decrease of the article count for this query does not tell us much, since it could still be, or not be, that relevant contents are transported as part of he articles that also mention protests.

- The other queries (_topic `and` framing_, _topic `and` goal_, _topic `and` subisidiary goal_) aim to look at topics where it would be a success for the protests if they occur more in public discourse. If their article counts increase due to protests, then backfiring is unlikely (but still possible in other topic niches that I am not querying for); and if they decrease, it is strong evidence that the protests are indeed backfiring. A result where the counts for some of these queries increase, while they decrease for others may indicate more complicated effects of protests that warrant further research.

- The _topic `and` protest_ query can serve as a sanity check: It would be very surprising if protest events did not cause the counts for this query to markedly increase. This is even more true for the _ACLED_ and _GPRep_ datasets, where the events are (manually or automatically) extracted from newspaper articles.

![The queries produce different lenses on the mass of articles about climate change. The left lens has the disadvantage that we do not know how much the articles that also mention the protests contribute to the discourse about the topic. The right lens has the disadvantage that it ignores aspects that we do not explicitly query for.](figures/queries.svg){.column-margin}

__Limitations:__ The querying approach that I employ for this study is very coarse, and will deliver clear conclusions only in some cases. It would also be very interesting to see how much room is typically given to the discussion of climate policy in an article that also mentions protests. Moreover, one could measure how prominent the various keywords are within each article, and what other words they cooccur with most, and what sentiments they are accompanied by. Another approach would use topic models to create topics in an unsupervised manner, and observe how their prevalence shifts in the face of protests; this has already been done by @chenHowClimateMovement2023a for the climate protest movement. All of these techniques require full-text data. For newspaper articles, full-text data is in principle available, but relatively hard to obtain (see the notes on fulltext availability in @sec-mediacloud, @sec-dereko); so I have not used full-texts here, in order to focus more on the causal aspect.

__Other types of public discourse__ could also be explored in future work. This includes Twitter data (@kratzkeMonthlySamplesGerman2023: a sample of full texts from Germany on a daily basis 2019-2022), [Google Trends](https://trends.google.com/) data (search query counts on a weekly and regional basis starting from 2005), or parliamentary speech (@abramiGermanParliamentaryCorpus2022: speeches from regional German parliaments from the nineties until 2021). Twitter data does not come with geographical annotations, and Google Trends and parliamentary speech are not available on a continuous daily basis, so I focus on newspaper articles here.

#### Online newspapers {#sec-mediacloud}

```{python}
# | label: fig-mediacloud-history
# | fig-cap: Number of daily online newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display. The effects of an outage of the collection system in January 2022 are visible.
# | column: page
# | echo: false

from src.data.news.mediacloud.word_counts import counts_for_region
from src.data.protests.keywords import climate_queries

fig, ax = plt.subplots(figsize=(14, 2))
for k, v in climate_queries().items():
    df = counts_for_region(v, "Bayern")
    df = df.query("index >= '2020-01-01' and index <= '2022-12-31'")
    df.rolling(7).mean().plot(ax=ax, linewidth=1)
ax.legend(climate_queries().keys())
ax.set_ylabel("#articles")
ax.set_xlabel(None)
ax.set_title("Article counts for online newspapers in Bayern")
plt.show()
```

[Media Cloud](https://www.mediacloud.org/) is an open data platform that continuously crawls newspaper websites around the world and stores article metadata and word counts in a database. Full texts are in principle available by following the links and scraping the websites oneself, but this is very slow and often hampered by anti-scraping measures of the websites. I use the [`api/v2/stories_public/count`](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#apiv2stories_publiccount) endpoint of their API. I query for tags from the [regional and national collections about Germany](https://search.mediacloud.org/collections/news/geographic). Baden-Württemberg and Mecklenburg-Vorpommern are missing from the collection. There has been a (partial) outage in January 2022 resulting in (near-)zero counts for that timespan. I do not exclude this timespan because it would be complicated and error-prone with respect to time-series analysis. This may lead to an under-estimation of eventual causal effect sizes of up to $\frac{1}{36}\approx 0.028$, but I do not expect it to influence my results in any other systematic way.

#### Print newspapers {#sec-dereko}

```{python}
# | label: fig-derekp-history
# | fig-cap: Number of daily print newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display.
# | column: page
# | echo: false

from src.data.news.dereko import counts_for_region
from src.data.protests.keywords import climate_queries

fig, ax = plt.subplots(figsize=(14, 2))
for k in climate_queries().keys():
    df = counts_for_region(k, "Bayern")
    df.rolling(7).mean().plot(ax=ax, linewidth=1)
ax.legend(climate_queries().keys())
ax.set_ylabel("#articles")
ax.set_xlabel(None)
ax.set_title("Article counts for print newspapers in Bayern")
plt.show()
```

The [German reference corpus](https://www.ids-mannheim.de/digspra/kl/projekte/korpora/) (_Deutsches Referenzkorpus_, DeReKo) archives the full texts of most German-language print newspapers and magazines in an online database for the purpose of linguistic research. An API contains access to a selected corpus, and by (automatically) navigating the user interface, an extended corpus can be searched. The content is renewed on an annual basis and with a delay of a few months, so no data for 2023 is available. Full texts cannot be retrieved from DeReKo, but large context windows for search results are available, which could be used for more nuanced further research. Here, I only use the functionality of obtaining daily article counts for a given query.

I extract an overview table of all newspapers from the corpora W1-W4, remove newspapers that are not available until 2022, remove newspapers that are about niche topics such as cars, beauty, or history, or that are published with less than weekly frequency. I annotate the remaining 154 newspapers on whether they have a national or regional scope, and retrieve the applicable regions for the regional ones, drawing from information on Wikipedia and the newspaper websites. 121 are from Germany, and 15 of these have a (primarily) national scope, while 106 have a regional scope. All regions are represented with at least one newspaper, except the city state of Bremen. Among the 4 (or more) German "newspapers of record" [see @NewspaperRecord2023], the conservative _Frankfurter Allgemeine Zeitung_ is missing, and the very popular tabloid _Bild_ is also missing.

I retrieve daily article counts for all queries and all thus filtered newspapers, and aggregate them by day on the regional level as well as into a category of national newspapers.

#### Press releases

As a source for events related to the climate crisis, I consider press release full texts. They contain unstructured textual information that can be made useful for the computation of propensity scores via text classifiers.

I retrieve press release full texts from the commercial _Nexis Uni_ database, querying for `klima*`, and restricting the results to German-language press releases from the _dpa-AFX ProFeed_, yielding 29,052 articles for 2020-2022.

### Regional sociodemographics

I consult the [Regionalatlas](https://regionalatlas.statistikportal.de) by the German statistical bureau, and select 29 variables from 2022 that are available on a regional level and do not incorporate or directly depend on the absolute areas or population sizes of the regions, so that they are more comparable. The variables are selected to cover diverse areas from demographics, economics, and sociology. Apart from the immigration/emigration balance, all variables are nonnegative. The full list of variables is included in @sec-app-sociodem.

### Weather

{{< embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-weather-time-series >}}

Weather data is obtained via the [Meteostat](https://meteostat.net/en/about) project from _Deutscher Wetterdienst_, containing the 8 variables displayed in @fig-weather-time-series.

### Pandemic restrictions

{{< embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-covid-19-time-series >}}

Available data includes the _stringency index_ calculated by the [Oxford Coronavirus Government Response Tracker](https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker) and provided by [Our World in Data](https://ourworldindata.org/covid-stringency-index)^[TODO: Plot this as well.]; and _Google Mobility Trends_ data, also provided by [Our World in Data](https://ourworldindata.org/covid-google-mobility-trends) [@fig-covid-19-time-series]. Both datasets are only on the national level for Germany, which eliminates concern (1.) above but also leads to lower resolution of the data. While the stringency index is rather static, the mobility trends data contains more randomness. The randomness may indirectly be influenced by the weather, which is neither a problem, nor an advantage, since I already use the weather variables directly.

TODO: Needs control for COVID word counts.

---

### NEW Regional and national data

My setting throughout all methods is that I estimate models based on regional data. However, I do not fit separate models for each region, but always a single model on a dataset that includes all regions. This has the benefits that __(a)__ it leads to more generalizable results and __(b)__ it increases the size of the dataset by a factor of 14 (in comparison to using national data, or to estimating single regional models), and thereby increases statistical power.

To integrate multiple time series from the various regions into a single dataset, I add static __dummy variables__ for each region, as is common practice for time series data. To capture the effect of regional differences properly, it would be necessary to also add interaction terms of all 14 region dummies and all 5 treatment variables, as well as potentially some of the control variables. This would lead to at least 70 interaction terms, which would make the interpretation of the results much harder.

The __differences between the regions__ -- especially in size, population size, and number of newspapers -- are potentially problematic for the estimation of a global model. I minimize this problem by (a) including previous amounts of coverage and (b) using absolute rather than relative coverage. While the relative coverage of a protest event will presumably be lower in larger regions (because a smaller proportion of the region is affected by any event), this will not be the case in absolute terms. However, it may be the case that there are major protest events with a strong relation to regional politics, and that they have an impact throughout the whole region, and in that case the size of the region might matter. This would not be captured by the model and could lead to a high variance the treatment effect estimates.

On the other hand, the __national impact__ of protests is politically more interesting, so I also estimate a model on the national level, which has the structure as any of the regional models, but with aggregated treatment variables and newspaper coverage from national rather than regional newspapers.

### NEW Delayed and cumulative impact

Protests may have an impact on newspaper converage not only on the day that they occur but also in the following days and weeks. For estimating these delayed impacts, I do _not_ extend the lags of the outcome further into the future, because the amount of coverage on or after the protest date likely mediates the impact on future coverage. These mediated impacts are hard to isolate. By not including potential mediators in the predictors, I make sure that all indirect impacts are also clearly attributable to the treatment. I do _not_ extend the lags of the treatment further into the future either (mostly motivated by efficiency gains that are related to implementation details), so indirect impacts that are mediated by future protests (if they exist) are also included in the impact estimate.

Next to the impact for each single day, the cumulative impact is of interest. Point estimates (expected values) can be computed by summing the effects from multiple days. This is not so easy for the variance (and thus standard errors and confidence intervals), since the variance of the sum of the effects depends on their covariance. In regression models the covariance could be determined using multivariate regression, but `scikit-learn` does not support standard errors and the `statsmodels` library does not support multivariate regression, and the author is too lazy to learn `R`. Instead, I estimate separate models for each cumulative outcome variable; that is, a model for the 1-day impact, for the 2-day impact, for the 3-day impact, and so on.



<!-- ### Evaluation

- bootstrapping for comparable standard errors
- placebo tests
  - negative outcome, esp. lagged outcome: Ding ch. 16.2.1
  - negative exposure: Ding ch. 16.2.2
- cross-validation (ood with one year gap) of
  - regression -> prediction mse
  - iv -> f1 for predicting protests (first stage) (and mse for predicting coverage (second stage)) -- or just directly the outcome?
  - synth -> predictive quality within different pre-fit areas
  - prop scores -> prop score f1 -- and the outcome? (esp for doubly robust)
- (E-values): how large would hidden confounding need to be? Ding ch. 17 -->


---

## NEW Instrumental variables {#sec-instrumental}

The idea of the _instrumental variable_ approach is to look for _natural experiments_, where a random variable (or a somewhat random variable) has an effect on the treatment. Like in randomized controlled trials, the randomness removes the problem of hidden confounding. Unlike in randomized trials, the treatment in an instrumental variable setting is only partially randomized. The intuitive approach is to identify this random component and then measure its effect on the outcome. Instrumental variables are also referred to as just _instruments_.

<!--
- https://bashtage.github.io/linearmodels/iv/index.html
- https://www.pywhy.org/dowhy/v0.10/dowhy.causal_estimators.html#module-dowhy.causal_estimators.two_stage_regression_estimator
-->

### Weather as an instrument

#### Validity of weather as an instrument

While the previous literature has mostly focused on rainfall, I consider all weather variables to be potentially useful and analyze all of them for suitability, addressing the concern of multiple testing.

Since the protest events in the main data set are aggregated daily on a regional level, I use regional weather data. For each region I determine the 10 cities with the most protests and average their weather data, weighted by the number of protests in each city.

Two systematic concerns have been raised about using weather as an instrumental variable. I briefly discuss their applicability to my setting:

__Indirect paths:__ @mellonRainRainGo2023 find 195 variables that have been linked to the weather in previous studies (ironically, many of them instrumental variable studies themselves), and that these undermine the exclusion criterion for instrumental variables, threatening the validity of the variables. The authors have constructed a comprehensive causal graph depicting the known effects of the weather. It shows that _protests_ as well as _violent protests_ are influenced by rainfall and temperature, and that protests have an influence on repression, voting behaviour, policy, and property values. There is no study confirming an influence of the weather on newspaper reporting, but possible indirect paths may include _mood_ and (for climate protests) _pollution_. Other variables such as _migration_ may also have an effect because attention to them might decrease attention to other topics in the news; however most of this kind of variables are only related to the weather in the long term and not in the short term.

__Spatial interdependence__: @coopermanRandomizationInferenceRainfall2017 raise concern about spatial interdependence of rainfall across regions. This applies particularly when the effect of rainfall across regions _on a single date_ is investigated, for example in the context of an election. In my setting I investigate the individual effects of protest events that are spread across multiple years. The amount of protests that take place on the same date is therefore very small, and spatial interdependence of the _weather_ among temporally separated events is very low. Spatial interdependence of the _climate_ (thus also influencing the weather) is still a problem. When removing the climate influence from the weather and only using the (climate-independent) weather as instrumental variables, the spatial interdependence should be mostly removed from the intrumental variables.
<!-- , and only affect the exogenous climate variables. -->

##### Seasonality

WIP

##### Detecting invalid instruments

WIP

#### The impact of the weather on protests

WIP

<!-- For evaluating the validity of an instrument, an important step is to consider the impact of the instrument __Z__ on the treatment __W__, which is relevant for condition (2.) on valid instruments from above. The _first stage_, that is, regressing __W__ on __Z__, can provide relevant information. -->

##### Precipitation

<!-- I make two separate regressions, one with protest occurrence, and one with protest size as dependent variables. All potential instrumental variables are used as independent variables, and the long-term weather components are used as control variables. Both regressions use linear regression (and _not_ logistic regression, even though the target is binary) due to consistency with the second stage. For the protest size variable, only days with protest occurrence are included in the data. To adjust for multiple testing, I use the Benjamini-Yekutieli procedure. It has less power than the Benjamini-Hochberg procedure, but accounts for potential correlations among the independent variables, which seem very likely here. I include regional dummies as control variables but do not include them in the adjustment procedure because I am not interested in their significance.

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#tbl-first-stage-with-control >}}
\endgroup

Results for the significant regression coefficients are shown in @tbl-first-stage-with-control and suggest that there is only one potential instrument with a somewhat statistically significant p-value of $0.03$ for protest occurrence and $0.10$ for protest size. This is consistent with the fact that the previous literature almost exclusively relies on this variable, and provides support for this practice. The finding that some of the long-term variables also have a somewhat statistically significant effect shows that it does indeed matter to separate them. -->

##### Other weather variables

WIP

##### Principal components

WIP

#### Making the weather more random

<!-- Describe the problem and show the impact on the BLM movement data. Explain that _controlling_ can help a lot here, or rather that IV is a nice addition to controlling. -->

##### Separating short-term and long-term weather components

An additional concern that has been identified and adjusted for by some previous studies (see @sec-weatherlit) is that weather contains a non-random component that is correlated both temporally with annual seasonality (which may be linked, for example, to media attention cycles, and many other variables), and geographically with places with generally nice or bad weather (which may be linked, for example, to economic indicators, or also to previous protest activity). This is in violation of condition (1.) on valid instruments from above. Therefore I try to split each weather variable into a long-term non-random variable and a short-term almost-random variable.

I follow @negroWhichSideAre2019 in using 10-year averages for each day of the year, additionally smoothing them. I find a $\pm 14$-day window using Bayesian smoothing to deliver more satisfactory results, that is, smoother climate variables, than the $\pm 3$-day moving average applied by the authors. Using this as a long-term variable, I construct the short-term variable by subtracting the long-term variable from the original weather weather variable. Results for the short-term weather variables are displayed in @fig-weather-time-series-2.

{{< embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-weather-time-series-2 >}}

The results still show some amount of seasonality across all years for the short-term variable -- especially for the _precipitation_ variable --, which may be due to the effects of climate change. Using a smoothing window on the current weather rather than on historic averages may be a more appropriate strategy, but is not pursued further here. The snow variable is still obviously seasonal after this procedure and should not be further considered a potential instrument.

<!-- __Aside: First-stage validity in previous work__

To underline the problems that I encounter, I apply my method to a case study from the literature, where an instrumental variables approach using the weather to instrument protest size has been successfully conducted. I choose the _Black Lives Matter_ movement in 2020 in the United States, which has recently received much scholarly attention and has been studied independently by both @kleinteeselinkWeatherProtestEffect2021 and @carenBlackLivesMatter2023, employing a similar methodical setting which may have been inspired by @wasowAgendaSeedingHow2020.

I use rainfall ... and protests from the ACLED dataset.

I only investigate the first stage.

Fig: Placebo test for monthly average. Conclusion: separate climate and weather! -->

##### Leveraging the gap between pre-registered and observed protest size

WIP

<!--
Predicting the change for all Berlin data:

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/gap/gap.ipynb#tbl-change-regression-all >}}
\endgroup

Placebo:

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/gap/gap.ipynb#fig-change-regression-placebo >}}
\endgroup

First stage for the climate protests, reasonable:

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/gap/gap.ipynb#tbl-change-regression-climate-reasonable >}}
\endgroup

and more suitable for 2-stage:

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/gap/gap.ipynb#tbl-change-regression-climate-useful >}}
\endgroup

and aggregated:

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/gap/gap.ipynb#tbl-change-regression-climate-useful-aggregated >}}
\endgroup

And results for the 2nd stage (the actually interesting thing):

\begingroup
\scriptsize\selectfont
embed ../src/models/instrumental_variable/gap/gap.ipynb#tbl-change-liml-climate >}}
\endgroup -->

### Pandemic restrictions as an instrument

The timespan covered by my dataset (mostly 2020-2022) coincides with the COVID-19 pandemic, which has had very drastic impacts in 2020 and 2021, and still some in 2022. This may open up the possibility for exploiting a new kind of instrumental variable, because the pandemic comes with both legal restrictions and psychological aversion against large gatherings, including demonstrations.

#### Validity of restrictions as an instrument

I see 3 reasons why pandemic restrictions may not be a valid instrument:

1. Just like the weather, the spread of the coronavirus is to some extent a natural event. It is, however, to some extent controlled by the behaviour of humans, and especially the restrictions due to COVID-19 have a large political component. I worry especially about geographical confounding: Restrictions in Germany have in large part been up to the regional legislators and governments, and perhaps those governing parties whose climate policy causes outrage tend to impose especially strict (or loose) COVID-19 restrictions for one reason or another.
2. Unlike the weather, COVID-19 restrictions are temporally correlated over longer timespans, that is, they change more slowly. This introduces some chance that they may be accidentally or systematically correlated with political processes and with media attention cycles.
3. There is a potential direct impact of COVID-19 on media coverage: Stricter restrictions may correlate with a more intense media focus on the pandemic, decreasing attention on any other topic. This could be measured and corrected for. Without such correction, we may overestimate the effect of protests, because the non-occurrence of protests may be correlated with decreased coverage of any non-covid topic, and the occurrence of protests may be correlated with the usual amount of coverage for non-covid topics.


<!--
### Placebo tests for instrumental variables

To further strengthen the evidence that the _precipitation_ variable has a significant impact on protest occurrence and size, I perform placebo tests where I try to predict protest occurrence and size not from the weather of the respective day, but from other days before and after the protest. I expect:

a. The weather after the protest should not have any effect on the treatment. For very few days after the protest there might still be a correlation because the weather on one day is correlated with the weather on the next day. This correlation should rapidly decline over the course of a few days and permanently go down to $0$.
b. For days before the protest, I expect a similar amount of correlation. In addition, I expect some small causal effects, because organizers and attendees may decide a few days before the protest whether it should take place or whether they want to attend, and might be influenced in their decision by the current weather, and not only the weather forecast; and even the weather forecast depends not only on the actual weather on the day, but substantially on the weather a few days earlier. In addition, the previous weather may have an impact on previous protests, which may in turn have an impact on the protest on the current date. Therefore I expect coefficients and significances before the protest date to also shrink to 0 in the long term, but on a much slower timescale, say, multiple days or weeks.
c. I expect these declines both before and after the protest dates to be smooth.
d. In similar manner to the coefficients of the relevant variables, I expect the overall predictive power of the regression (adjusted $Rˆ2$ / f-statistic) to continuously decline before and after the protest date, and much faster after the protest.
e. When performing regression with only the instruments and no control variables, I expect the predictive power to decline to 0 in both directions.

{{< embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-first-stage-time-series >}}

@fig-first-stage-time-series and @fig-fstat show the results of the two time series of placebo tests.

{{< embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-fstat >}}

It seems that the obtained coefficients are almost completely random, and that knowledge about the weather on the protest date does not improve predictive power in comparison to using the weather on any other day. -->
<!--

### Evaluation

- Placebo
- first stage Placebo
- statistical tests -->

## NEW Synthetic control {#sec-synth}

The synthetic control method [@abadieSyntheticControlMethods2010; @cunninghamCausalInferenceMixtape2021, ch. 10] leverages the idea of comparing a region where a protest happens with other regions where no protest happens on the same day. However it goes beyond a simple comparison. Instead it constructs a _synthetic region_ from all the control regions that is as close as possible to the treatment region. The synthetic region can then be used to model the counterfactual of no protest for the treatment region.


<!--

cite Abadie, Cunningham

### Selecting control regions based on the distance

- reverse and effect

### Selecting control regions based on sociodemographics

Variables

Methods:
- correlation
- linear regression
- PC regression
- PLS regression
- NMF regression

visualize "maps of Germany" based on first 2 components

select n_components based on cross-validation

### Selecting control regions based on high predictive quality

#### manually

#### using tf-causalimpact

### Bias from incomplete protest data

#### Difficulties with small protest events

#### Difficulties with large protest events -->

<!-- ### Evaluation

- Placebo
- balance of the covariates (=how good are the synthetic units in fundamental terms?)
- pre-treatment fit?
- (p-values) -->

## NEW Propensity scores

Propensity score methods help to remove the impact of _known_ confounders. They rely on the propensity score that specifies how likely it is that a protest occurs on a given date and in a given region. They can be computed from knowledge about the region and the date, and from lagged treatment and outcome data from the previous days. To account to some extent for the impact of _unknown_ confounders, I also obtain propensity scores from press releases about climate-related events.



### Propensity scores from press release texts

TODO

<!-- cite Wager, and causal NLP overview

Predicting propensity scores from text: cite causalNLP overviews
For example, @bundeskriminalamtbkaLagebildLetzteGeneration2023 hypothesize that "Die Fallzahlen unterliegen einem „wellenartigen“ Verlauf, welcher sich vornehmlich durch (das Ausbleiben von) Großveranstaltungen im gleichen Kontext erklären lässt."

possible models:

- gelectra: 100-300M parameters https://huggingface.co/deepset/gelectra-base
- igel: 6B parameters https://huggingface.co/philschmid/instruct-igel-001
- llama 2 german https://huggingface.co/flozi00/Llama-2-7b-german-assistant-v2

faster finetuning: https://github.com/huggingface/peft -->
