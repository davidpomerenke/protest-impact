---
execute:
  freeze: true
---

```{python}
# | echo: false

from matplotlib_inline.backend_inline import set_matplotlib_formats

set_matplotlib_formats("svg")
```
<!--

Analysis of the results with graphics like bargraphs and boxplots has been made. Statistical methods have been employed to compare different results. AUCs have been obtained. Minimal verification.
+ Attention has been paid to the distribution of the data. Verification has been carried out. Attention is paid to overfitting.
+ Results have been analysed with proper statistics. Model assumptions of statistical methods are verified or methods that do not make assumptions were employed for non-Gaussian data. Checks were made to avoid hidden overfitting.
+ Best approach for obtaining significant results was taken while refraining from p-value hacking.

 -->

## Results

### Evaluation of methods

#### Regression {#sec-res-reg}

The best model uses only a single time-series lag, as well as moving averages and difference features. Metrics for the OLS and the regularized regression models are shown in @tbl-reg-hypopt. Even though the bias is minimized, it is still substantial at around -14 articles within a timespan of one week. (This is only for time-series splits; the bias for conventional shuffled cross-validation splits is very close to 0 for all models.) A regression table with coefficients is appended in @sec-app1-reg.

| Model          | Hyp. opt. obj. | RMSE          | Bias         |
| -------------- | -------------- | ------------- | ------------ |
| OLS            | min RMSE       | 110.6 ± 24.2  | -18.8 ± 10.4 |
| OLS            | min bias       | 130.9 ± 21.5  | -14.3 ± 10.1 |
| BayesianRidge  | min bias       | 119.7 ± 23.4  | -3.85 ± 15.2 |
| LassoLarsIC    | min bias       | 118.9 ± 24.5  | -2.89 ± 15.7 |

: Bias (mean error) and root mean squared error (RMSE) as a measure for variance for the best models that result from hyperparameter optimization. {#tbl-reg-hypopt}

```{python}
# | echo: False

from src.models.regression.hyperopt import best_regression

r = best_regression(ignore_group=True)
t = "occ_protest_lag0"
results = r.params[t], tuple(r.conf_int().loc[t]), r.pvalues[t]
```

#### Instrumental variables

\begingroup
\scriptsize\selectfont
```{python}
# | label: fig-iv-wald
# | fig-cap: Correlations between the instruments and the treatment (corr_w) and between the instruments and the outcome (corr_y), and Wald estimator results.
# | echo: false
from src.models.instrumental_variable import get_covariances

get_covariances("weather_covid")
```
\endgroup

Correlations and Wald estimator results of the original variable are shown in @fig-iv-wald. Note that the Wald estimator is not valid for weak instruments.

Automatically binarizing the variables based on an optimally chosen threshold does not generally increase the covariances, and decreases them slightly in most cases. This is also true for precipiation: The optimal threshold for maximizing the covariance with protest occurrence is at prcp > 0, which is consistent with the choice in most related work (see @sec-lit-causal), but the binarization does not substantially change the covariance.

\begingroup
\scriptsize\selectfont
```{python}
# | label: tbl-iv-basic
# | fig-cap: First-stage impact of the original instruments. Regression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. Results are sorted by original p-values and adjusted p-values (p_bh = Benjamini-Hochberg, p_by=Benjamini-Yekutieli) and first-stage f-statistics for using each variable as an instrument on its own are displayed.
# | echo: False

from src.models.instrumental_variable import get_coefficients

get_coefficients("weather_covid")[0].sort_values(by="p")
```
\endgroup

\begingroup
\scriptsize\selectfont
```{python}
# | label: tbl-iv-deseason
# | fig-cap: First-stage impact of the seasonal and residual parts of the instruments. Regression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. Results are sorted by original p-values and adjusted p-values (p_bh = Benjamini-Hochberg, p_by=Benjamini-Yekutieli) and first-stage f-statistics for using each variable as an instrument on its own are displayed. Only the 10 most significant variables are displayed.
# | echo: False

from src.models.instrumental_variable import get_coefficients

get_coefficients("weather_covid_season")[0].sort_values(by="p").head(10)
```
\endgroup

\begingroup
\footnotesize\selectfont
```{python}
# | label: tbl-iv-deseason-pc
# | fig-cap: First-stage impact of principal components calculated separately for the seasonal and residual parts of the instruments. Regression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. Results are sorted by original p-values and adjusted p-values (p_bh = Benjamini-Hochberg, p_by=Benjamini-Yekutieli) and first-stage f-statistics for using each variable as an instrument on its own are displayed. Only the 10 most significant variables are displayed.
# | echo: False

from src.models.instrumental_variable import get_coefficients

get_coefficients("pc_weather_covid_season")[0].sort_values(by="p").head(10)
```
\endgroup

```{python}
# | label: fig-iv-pc-vis
# | fig-cap: The three most important nonseasonal principal components in terms of the original nonseasonal (residual) instruments.
# | column: page
# | echo: false

from src.models.instrumental_variable import pc_vis

pc_vis("pc_weather_covid_season", numbers=[9, 8, 11], dfs=slice(1, 2))
```

Multiple steps are shown for the impact of the instruments on the treatment while controlling for known confounders and other instruments:

1. @tbl-iv-basic shows the impact of the original instruments. Three of the covid variables are relatively significant, the weather variables less so, with _wind speed_ being most significant and precipitation least significant.
2. @tbl-iv-deseason shows the impact for the variables after splitting them into seasonal and residual components. The most significant variables are seasonal ones derived from covid variables. Of the residuals, the _stringency index_, the movement data for "grocery and pharmacy", and _wind speed_ are most significant.
3. @tbl-iv-deseason-pc shows the principal components for the seasonal and residual variables from the previous step. The top two variables are much more significant than without PC, and one of them is a residual variable. The meaning of the three most significant reidual variables is shown in @fig-iv-pc-vis. According to the "rule of thumb" (@InstrumentalVariablesEstimation2023) the threshold for weak instruments is around f=10, so pc_resid_9 would be a strong instrument but the other ones would all be weak.

Placebo tests for the first stage are given in @fig-iv-1-placebo. The instrument has a significant impact on protest occurrence for a few days around the date where the instrument was measured. For days that are further away there is less impact, but not exactly zero. Placebo tests for the second stage are shown together with the other methods in @sec-res-placebo.

```{python}
# | label: fig-iv-1-placebo
# | fig-cap: First stage placebo tests for using the principal component pc_resid_9 to instrument protest occurrence. Values for the instrument from after the protest date are used. These values cannot have an impact on protest occurrence if the instrument is valid.
# | echo: false
from src.models.time_series import instrumental_variable_liml
import matplotlib.pyplot as plt

results = instrumental_variable_liml(
    target="media_combined_protest",
    treatment="occ_protest",
    instruments="pc_weather_covid_season",
    iv_instruments=["pc_resid_9"],
    lags=range(-7, 1),
    ignore_group=True,
    ignore_medium=True,
    cumulative=False,
    steps=range(-30, 31),
    shift_instruments=True,
    show_progress=False,
)
fig, ax = plt.subplots(figsize=(8, 3))
ax.plot(results.step, results.first_stage_coef, marker=".")
ax.fill_between(
    results.step,
    results.first_stage_ci_lower,
    results.first_stage_ci_upper,
    alpha=0.2,
    color="C0",
)
ax.axhline(0, color="k", linewidth=0.5)
ax.axvline(0, color="k", linestyle="--")
ax.set_xlabel("Day of instrument (relative to protest)")
ax.set_ylabel("First stage coefficient")
ax.set_title(
    "First stage placebo tests with shifted treatment: Impact of pc_resid_9 on protest occurrence"
)
plt.tight_layout()
plt.show()
```

#### Synthetic control

@fig-synth-hyperopt shows how the length of the pre-treatment period influences the bias of the causal estimate. Bias is most reduced at n=180, with a bias (mean error) of -0.330±1.13, and an RMSE of 65.8±2.40.

```{python}
# | label: fig-synth-hyperopt
# | fig-cap: "Hyperparameter optimization: Influence of the pre-period length on bias (mean error)."
# | echo: false

import matplotlib.pyplot as plt
from src.models.synthetic_control.hyperopt import hyperopt

results, _ = hyperopt(show_progress=False)
fig, ax = plt.subplots(figsize=(5, 2))
ax.plot([abs(r["lags"][0]) for r in results], [r["bias"] for r in results], marker=".")
plt.fill_between(
    [abs(r["lags"][0]) for r in results],
    [r["bias"] - r["bias_std"] for r in results],
    [r["bias"] + r["bias_std"] for r in results],
    alpha=0.2,
)
ax.axhline(0, color="black", linewidth=0.5)
ax.set_xlabel("Pre-period length (days)")
ax.set_ylabel("Bias (#articles)")
ax.set_title("Bias vs. pre-period length")
ax.set_xticks([abs(r["lags"][0]) for r in results])
plt.tight_layout()
plt.show()
```

@fig-sc-long shows the fit for the optimized unbiased model (specifically: unbiased for estimating the -day cumulative coverage).

```{python}
# | label: fig-sc-long
# | fig-cap: Synthetic control fit around the treatment for a pre-treatment period of n=180. Values are aggregates from synthetic controls for all protest events. Weekly patterns are due to regularities in protest event timing (Fridays for Future) and weekly cycles in general newspaper coverage.
# | echo: false

import matplotlib.pyplot as plt
from src.models.synthetic_control import sc_plot

titlenames = [
    ("articles mentioning protest", "media_combined_protest"),
    ("articles NOT mentioning protest", "media_combined_not_protest"),
]
fig, axes = plt.subplots(2, 1, figsize=(6, 4))
for i, (t, n) in enumerate(titlenames):
    sc_plot(t, n, scale="demean", pre_period=180, post_period=20, ax=axes[i])
    axes[i].set_xlim(-20, 7)
fig.tight_layout()
plt.show()
```

@fig-sc-short shows the fit for a shorter pre-treatment period and with better pre-treatment fit.

```{python}
# | label: fig-sc-short
# | fig-cap: Synthetic control fit around the treatment for a pre-treatment period of n=22. Values are aggregates from synthetic controls for all protest events. Weekly patterns are due to regularities in protest event timing (Fridays for Future) and weekly cycles in general newspaper coverage.
# | echo: false
# | layout-nrow: 2

import matplotlib.pyplot as plt
from src.models.synthetic_control import sc_plot

titlenames = [
    ("articles mentioning protest", "media_combined_protest"),
    ("articles NOT mentioning protest", "media_combined_not_protest"),
]
fig, axes = plt.subplots(2, 1, figsize=(6, 4))
for i, (t, n) in enumerate(titlenames):
    sc_plot(t, n, scale="demean", pre_period=22, post_period=20, ax=axes[i])
    axes[i].set_xlim(-20, 7)
fig.tight_layout()
plt.show()
```

@fig-sc-longterm gives an impression of the long-term impact estimate. Rolling averages are used for preprocessing, so the absolute impacts cannot directly be retrieved.

```{python}
# | label: fig-sc-longterm
# | fig-cap: Synthetic control with pre-treatment period of two years and longterm effects for half a year. Outcomes have been preprocessed with weekly rolling averages. No bias checks have been made for this model.
# | echo: false

import matplotlib.pyplot as plt
from src.models.synthetic_control import sc_plot

titlenames = [
    ("articles mentioning protest", "media_combined_protest"),
    ("articles NOT mentioning protest", "media_combined_not_protest"),
]
fig, axes = plt.subplots(2, 1, figsize=(6, 4))
for i, (t, n) in enumerate(titlenames):
    sc_plot(t, n, scale="demean", pre_period=2*360, post_period=180, rolling=7, ax=axes[i])
    axes[i].set_xlim(-2*360, 180)
fig.tight_layout()
plt.show()
```

In the _ACLED_ dataset there is a protest in every single region on March 19, 2021, so no control region can be constructed. For the _GPRep_ dataset this also occurs on September 9, 2021 and on March 25, 2022.

#### Propensity scores

Hyperparameter optimization shows that the best model is a logistic regression model without balanced class weights, using all available features (moving averages, differences, and log-scaled protest sizes), 4 days of time-series lags, and z-score standardization of all feature variables.

The baseline value for the F1 score can be calculated by setting all predictions positive. This results in F1=0.118 for my dataset.

The best logistic regression model achieves a 5-fold time-series cross-validated score of F1=0.233±0.044, while a similar model with balanced class weights achieves F1=0.213±0.017.

Brief experiments with doubly robust estimation show that other than expected it gives estimates that are multiple orders of magnitudes higher than those of regression or inverse propensity weighting; it estimates chaotic time series; and it is overly sensitive to the hyperparameters that create the time series features (number of lags, inclusion of moving averages, etc.), much more than regression or IPW. I do not further investigate the problem and exclude the method from the analysis.

__Propensity scores from text.__ Model finetuning takes roughly 2 hours on 8 RTX 4090 GPUs, at a rental cost of roughly 6 euros. Loss curves are shown in TODO. The F1-score plateaus around 0.25, with the best checkpoint at F1=0.278 (but this may be in part by chance). No cross-validation is performed to save resources. La

### Placebo tests {#sec-res-placebo}

@fig-placebo-outcome shows placebo tests for the outcome for all models. Further placebo tests concern the treatments: For @fig-placebo-treatment-regional, the treatments are randomized within each region, while for @fig-placebo-treatment-global they are randomized across region (see @sec-meth-placebo).

```{python}
# | label: fig-placebo-outcome
# | fig-cap: Placebo tests for the outcome. The protests event date is at x=0. To the right of it are impact estimates for subsequent days, where it is possible that there actually is a causal impact. To the left of it are the days prior to the event data, where a causal impact is not possible. Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false

import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=False, steps=range(-28, 8), show_progress=False)
fig.suptitle("Placebo test: estimating the causal impact on outcomes before the event")
axes[0].set_xticks(range(-28, 8, 7))
axes[0].set_ylim(-30, 30)
axes[1].set_ylim(-30, 30)
axes[2].set_ylim(-5, 5)
axes[3].set_ylim(-5, 5)
axes[4].set_ylim(-300, 300)
plt.tight_layout()
plt.show()
```


```{python}
# | label: fig-placebo-treatment-regional
# | fig-cap: Placebo tests for the treatment, where treatments are randomized but the protest day proportions among regions are not, potentially causing some bias. Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(
    cumulative=False,
    steps=range(-15, 15),
    random_treatment_regional=25,
    show_progress=False,
)
fig.suptitle("Placebo test: estimating the causal impact of random events")
axes[0].set_xticks(range(-14, 14, 7))
axes[0].set_ylim(-30, 30)
axes[1].set_ylim(-30, 30)
axes[2].set_ylim(-5, 5)
axes[3].set_ylim(-5, 5)
axes[4].set_ylim(-1000, 1000)
plt.tight_layout()
plt.show()
```


```{python}
# | label: fig-placebo-treatment-global
# | fig-cap: Placebo tests for the treatment, with completely randomized treatments across regions. Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(
    cumulative=False,
    steps=range(-15, 15),
    random_treatment_global=56,
    show_progress=False,
)
fig.suptitle("Placebo test: estimating the causal impact of random events")
# axes[0].set_ylim(-3, 5)
axes[0].set_xticks(range(-14, 15, 7))
axes[0].set_ylim(-5, 5)
axes[1].set_ylim(-5, 5)
axes[2].set_ylim(-5, 5)
axes[3].set_ylim(-5, 5)
axes[4].set_ylim(-1000, 1000)
plt.tight_layout()
plt.show()
```

### Causal impact estimates {#sec-res-est}

@fig-impact-ts and @fig-impact-ts-cum show time series of the absolute and cumulative causal impact estimates, for protest-related and non-protest-related media coverage and for all causal methods. The order of magnitude of the causal effects differs substantially between some of the methods.

```{python}
# | label: fig-impact-ts
# | fig-cap: Causal impact estimates by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=False, show_progress=False)
fig.suptitle("Time series of the causal impact by method and coverage dimension")
axes[0].set_ylim(-30, 30)
axes[1].set_ylim(-30, 30)
axes[2].set_ylim(-5, 5)
axes[3].set_ylim(-5, 5)
axes[4].set_ylim(-200, 200)
plt.tight_layout()
plt.show()
```

```{python}
# | label: fig-impact-ts-cum
# | fig-cap: Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=True, show_progress=False)
fig.suptitle(
    "Cumulative time series of the causal impact by method and coverage dimension"
)
axes[0].set_ylim(-100, 300)
axes[1].set_ylim(-100, 300)
axes[2].set_ylim(-10, 30)
axes[3].set_ylim(-10, 30)
axes[4].set_ylim(-500, 1500)
plt.tight_layout()
plt.show()
```

@fig-impact-dims summarizes the 7-day cumulative impacts by coverage dimension and includes the impact for three specific sub-topics (see @sec-data-discourse).

```{python}
# | label: fig-impact-dims
# | fig-cap: 7-day cumulative causal impact estimates by method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.
# | column: page
# | echo: false

# problem: y axis visualization; maybe switch to matplotlib
import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="methods", step=6)
```

@fig-impact-medium differentiates between the impact on online newspapers and on print newspapers, only for the synthetic control method. @fig-impact-groups-7 break down the 7-day cumulative impact for the different protest groups, as estimated by the synthetic control method.

```{python}
# | label: fig-impact-medium
# | fig-cap: Causal impact estimates for online vs print newspapers, as estimated by the synthetic control method. The protest day is at x=0.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import _synthetic_control, plot_impact_ts

fig, axes = plt.subplots(1, 2, figsize=(6, 4), sharey=True, sharex=True)
targets = [
    "media_online_protest",
    "media_online_not_protest",
    "media_print_protest",
    "media_print_not_protest",
]

results = _synthetic_control(
    target=targets,
    treatment="occ_protest",
    steps=range(15),
    ignore_group=True,
    ignore_medium=False,
    positive_queries=False,
    add_features=["size", "ewm"],
    lags=range(-180,1),
)
plot_impact_ts(results, "occ_protest", targets[:2], ax=axes[0])
axes[0].set_title("Online newspapers")
plot_impact_ts(results, "occ_protest", targets[2:], ax=axes[1])
axes[1].set_title("Print newspapers")
handles, labels = axes[0].get_legend_handles_labels()
labels = [
    "articles mentioning climate change AND protest",
    "articles mentioning climate change AND NOT protest",
]
fig.legend(handles, labels, loc="lower center", ncol=1, bbox_to_anchor=(0.5, -0.1))
fig.tight_layout()
plt.show()
```

```{python}
# | label: fig-impact-groups-7
# | fig-cap: 7-day cumulative causal impact estimates by protest group, as estimated by the synthetic control method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.
# | column: page
# | echo: false

import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="groups", step=6)
```

@fig-impact-dataset and @fig-impact-groups-sources show how the impact estimates differ by dataset, for using the synthetic control method. Detailed results for the _GPReg_ and _GPRep_ datasets for all causal methods are in the appendix in @fig-impact-ts-gpreg and @fig-impact-ts-gprep, respectively.

```{python}
# | label: fig-impact-dataset
# | fig-cap: Causal impact estimates by dataset, as estimated by the synthetic control method. The protest day is at x=0.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import _synthetic_control, plot_impact_ts

fig, axes = plt.subplots(1, 3, figsize=(9, 4), sharey=True, sharex=True)
titles = [
    "Registrations data (GPReg)",
    "Reports data automated (GPRep)",
    "Reports data curated (ACLED)"
]
targets = [
    "media_combined_protest",
    "media_combined_not_protest",
]
for i, ds in enumerate(["GPReg", "GPRep", "ACLED"]):
    results = _synthetic_control(
        target=targets,
        treatment="occ_protest",
        steps=range(15),
        ignore_group=True,
        ignore_medium=True,
        positive_queries=False,
        add_features=["size", "ewm"],
        lags=range(-180,1),
        protest_source=ds.lower(),
    )
    plot_impact_ts(results, "occ_protest", targets, ax=axes[i])
    axes[i].set_title(titles[i])
handles, labels = axes[0].get_legend_handles_labels()
labels = [
    "articles mentioning climate change AND protest",
    "articles mentioning climate change AND NOT protest",
]
fig.legend(handles, labels, loc="lower center", ncol=1, bbox_to_anchor=(0.5, -0.1))
fig.tight_layout()
plt.show()
```


```{python}
# | label: fig-impact-groups-sources
# | fig-cap: 7-day cumulative causal impact estimates by protest group, as estimated by the synthetic control method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.
# | column: page
# | echo: false

import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="sources", step=6)
```
