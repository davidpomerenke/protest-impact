---
execute:
  freeze: auto
---


<!--

Analysis of the results with graphics like bargraphs and boxplots has been made. Statistical methods have been employed to compare different results. AUCs have been obtained. Minimal verification.
+ Attention has been paid to the distribution of the data. Verification has been carried out. Attention is paid to overfitting.
+ Results have been analysed with proper statistics. Model assumptions of statistical methods are verified or methods that do not make assumptions were employed for non-Gaussian data. Checks were made to avoid hidden overfitting.
+ Best approach for obtaining significant results was taken while refraining from p-value hacking.

 -->

## Results

### Evaluation of methods

#### Regression {#sec-res-reg}

Hyperparameter optimization shows that the best OLS regression model uses 7 time-series lags of all variables and no additional features. On 5 time-series cross-validation splits, it achieves a predictive performance with a root mean squared error (RMSE) of 36.5±6.2 and a (cross-validated) R² of 0.88±0.02. (The dimension is the sum of the number of climate articles published within a given date and the following day.) This is almost identical to a similarly tuned Bayesian Ridge regression model, which achieves an RMSE of 36.5±6.3 and the same R² value. A detailed regression table for the best OLS model can be found in @sec-app1-reg.

```{python}
# | echo: False

from src.models.regression.hyperopt import best_regression

r = best_regression(ignore_group=True)
t = "occ_protest_lag0"
results = r.params[t], tuple(r.conf_int().loc[t]), r.pvalues[t]
```

The coefficients for the protest variables are equivalent to the ATT (see @sec-app2-reg). Statistically significant at p=0.05 are only protest events by Fridays for Future, Letzte Generation, and groups that are coded as "other" groups. All protest coefficients are positive except for Ende Gelände and Fridays for Future + X, with negative coefficients at p-values of 0.89 and 0.18 respectively. For the aggregated protest occurrence variable (which does not consider the organizing protest group) the estimate is +5.79 additional articles in the first two days, with a confidence interval [+2.67, +8.92] and a p-value of 0.0003. More estimates are displayed in @sec-res-est.

<!-- MSE generalizability -->

#### Instrumental variables

Out of the 15 potential instrumental variables, 5 pandemic instruments and 4 weather instruments have a statistically significant impact on protest occurrence (see @fig-iv-basic), but when using them in a combined regression the coefficients are much less significant. Precipitation is not among the significant variables.

Automatically binarizing the variables based on an optimally chosen threshold does not generally increase the coefficients and siginificances, and decreases them slightly in most cases. This is also true for precipiation: The optimal threshold for maximizing the covariance with protest occurrence is at prcp > 0, which is consistent with the choice in most related work (see @sec-weatherlit). I find that such binarization is not systematically better or worse than using the continuous value. (For the single regression, it slightly decreases the coefficient, and for the combined regression with other variables it slightly increases the coefficient.)

```{python}
# | echo: false
# | fig-label: fig-iv-pc
# | fig-cap: Principal components of the
from src.models.instrumental_variable import pc_vis

pc_vis("pc_weather_covid", numbers=[0, 7, 11])
```

<!-- pc_0 at p=0.0005, pc_7 at p=0.007, and pc_11 at p=0.008 -->

Principal component decomposition isolates three very significant components with p<0.01, while the other components have p>0.05.^[This is without adjusting for multiple testing since no hypothesis tests or thresholds are used, but the analysis is rather exploratory.] The three components are displayed in terms of the original variables in @fig-iv-pc.

```{python}
# | echo: false
# | fig-label: fig-iv-pc-deseasoned
# | fig-cap: Principal components of the
from src.models.instrumental_variable import pc_vis

pc_vis("pc_weather_covid_season", numbers=[9, 8, 11], dfs=slice(1, 2))
```

Deseasoning the original variables and then performing separate principle component analyses on seasonal and residual parts shows that most of the significant variables are seasonal in nature; but there is also one very significant residual variable pc_resid_9 at p=0.0005 and two somewhat significant residual variables pc_resid_8 at p=0.05 and pc_resid_11 at p=0.07, while all other residual components have p>0.15 (without adjusting for multiple testing). The more significant components are broken down in @fig-iv-pc-deseasoned. The first-stage f-statistic for pc_resid_9 is f=33.82; f=2.08 for pc_resid_8; and f=2.02. According to the "rule of thumb" (@InstrumentalVariablesEstimation2023) the threshold for weak instruments is around f=10, so pc_resid_9 would be a strong instrument but the other ones would all be weak. The combined f-statistic of the three mentioned components is f=38.74.

Placebo tests for the first stage (the impact of the instrument on the treatment) are given in @fig-iv-1-placebo. From day 3 after the protest date there is no longer a significant impact of the instrument on the treatment

```{python}
# | fig-label: fig-iv-1-placebo
# | fig-cap: First stage placebo tests for using the principal component pc_resid_9 to instrument protest occurrence. Values for the instrument from after the protest date are used. These values cannot have an impact on protest occurrence if the instrument is valid.
# | echo: false
from src.models.time_series import instrumental_variable_liml
import matplotlib.pyplot as plt

results = instrumental_variable_liml(
    target="media_combined_protest",
    treatment="occ_protest",
    instruments="pc_weather_covid_season",
    iv_instruments=["pc_resid_9"],
    lags=range(-7, 1),
    ignore_group=True,
    ignore_medium=True,
    cumulative=False,
    steps=range(-7, 29),
    shift_instruments=True,
)
fig, ax = plt.subplots(figsize=(8, 4))
ax.plot(results.step, results.first_stage_coef, marker=".")
ax.fill_between(
    results.step,
    results.first_stage_ci_lower,
    results.first_stage_ci_upper,
    alpha=0.2,
    color="C0",
)
ax.axhline(0, color="k", linewidth=0.5)
ax.axvline(0, color="k", linestyle="--")
ax.set_xlabel("Day of instrument (relative to protest)")
ax.set_ylabel("First stage coefficient")
ax.set_title(
    "First stage placebo tests with shifted outcome: Impact of pc_resid_9 on protest occurrence"
)
plt.tight_layout()
plt.show()
```

#### Synthetic control

RMSE: 55.7±1.2, bias -2.64±2.78

Pre-fit MSE, plots

Difficulties with large protest events: plot size vs #regions

#### Propensity scores

F1

### Placebo tests

#### Placebo outcome

```{python}
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=False, lags=range(-7, 1), steps=range(-28, 8))
fig.suptitle("Placebo test: estimating the causal impact on past outcomes")
# axes[0].set_ylim(-3, 5)
axes[0].set_xticks(range(-28, 8, 7))
plt.show()
```

#### Placebo treatment

```{python}
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(
    cumulative=False,
    lags=range(-7, 1),
    steps=range(-15, 15),
    random_treatment_global=56,
)
fig.suptitle("Placebo test: estimating the causal impact of random events")
# axes[0].set_ylim(-3, 5)
axes[0].set_xticks(range(-14, 15, 7))
plt.show()
```

```{python}
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(
    cumulative=False,
    lags=range(-7, 1),
    steps=range(-15, 15),
    random_treatment_regional=25,
)
fig.suptitle("Placebo test: estimating the causal impact of random events")
# axes[0].set_ylim(-3, 5)
axes[0].set_xticks(range(-14, 14, 7))
plt.show()
```

```{python}
# | fig-caption: Error bars are 95% confidence intervals.
# | column: page
# | echo: false

# Does this even make so much sense, placebo for protest groups? maybe leave out.

import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="methods", step=1, random_treatment_global=True)
```

### Causal impact estimates {#sec-res-est}

#### Time series

```{python}
# | fig-cap: Note that the y-axes are shared between some of the plots, but the instrumental variable plot has a much larger y-axis.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=False)
fig.suptitle("Time series of the causal impact by method and coverage dimension")
axes[0].set_ylim(-5, 5)
axes[1].set_ylim(-5, 5)
axes[2].set_ylim(-250, 250)
plt.show()
```

#### Cumulative impact

```{python}
# | fig-cap: Note that the y-axes are shared between some of the plots, but the instrumental variable plot has a much larger y-axis.
# | column: page
# | echo: false
fig, axes = plot_trends(cumulative=True)
fig.suptitle(
    "Cumulative time series of the causal impact by method and coverage dimension"
)
axes[0].set_ylim(-10, 30)
axes[1].set_ylim(-10, 30)
axes[2].set_ylim(-500, 1500)
plt.show()
```

#### Protest groups

Causal effects for the individual protest groups differ substantially between regression and inverse propensity weighting and are not statistically significant at p=0.05 for the doubly robust estimator.

```{python}
# | fig-caption: Error bars are 95% confidence intervals.
# | column: page
# | echo: false

import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="groups", step=1)
```

```{python}
# | fig-caption: Error bars are 95% confidence intervals.
# | column: page
# | echo: false

import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="groups", step=6)
```

```{python}
# | fig-caption: Error bars are 95% confidence intervals.
# | column: page
# | echo: false

import altair as alt
from src.visualization.impacts import plot_groups

alt.renderers.enable("altair_saver", fmts=["html", "svg"])
plot_groups(kind="methods", step=6)
```
