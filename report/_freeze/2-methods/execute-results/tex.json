{
  "hash": "3134a2a657dfe0e5cb1671b822096ce6",
  "result": {
    "markdown": "---\ntitle: Methods\n---\n\n\n<!--\n\nResearch methods and justification:\nExcellent description of data or methods, excellent methodological understanding, research is reproducible.\n\n -->\n\n\n### Data sources and preprocessing {#sec-data}\n\nAll data is retrieved for the timespan from 2020 to 2022. This is because the _ACLED_ data is not available earlier, and the _DeReKo_ data is only released yearly with some delay, and not yet available for 2023 at the time of writing. All data sources are expected to be available for the next years, with the exception of data related to the COVID-19 pandemic.\n\n\n\n\n#### Protest events {#sec-acled}\n\nThere are generally two source types for protest events:\n\n1. __Newspaper articles__ are primarily used in the existing literature. [@hutterProtestEventAnalysis2014] give a historical and systematic overview and highlight the problem that this source is biased. They describe how several definitions for protest event analysis (PEA) and the broader political claim analysis (PCA), as well as associated coding practices have helped to formalize the (manual) data extraction process, such that results have become more valid and comparable.\n\n2. __Police archives.__ The literature dismisses this source type as \"biased\", uninformative about the motives and organizers, uncomparable across regions, often unavailable or unobtainable, and because it is restricted to only registered demonstrations (Hutter 2014; @ProtestlandschaftDeutschland; @wiedemannGeneralizedApproachProtest2022). This criticism appears to me valid but overgeneralized, and there may well be regions where the advantages prevail over the problems. Especially for the goal of impact estimation, the avoidance of selection biases that are associated with newspaper articles [Hutter 2014; @jamesozdenLiteratureReviewProtest2022] is a strong argument for using data from police and demonstration authorities.\n\n::: {.cell .column-page execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![History of the number of protest events in Germany per week.](2-methods_files/figure-pdf/fig-protest-history-output-1.svg){#fig-protest-history}\n:::\n:::\n\n\n__ACLED.__ My main data source for protest events is the [_Armed Conflict Location and Event Dataset_](https://acleddata.com/) (ACLED; @raleighIntroducingACLEDArmed2010a). ACLED is a grand effort that keeps track not only of violent conflicts and riots, but also of ordinary protest events. The data is human-curated based on newspaper reports, and contains coded information on dates, locations, actor groups, police interventions, and more, as well as a short free-text summary for each event, containing an estimate of the size as per the newspaper data source. Data for Germany is available starting from 2020 and is continuously updated. For the period from 2020-2022, it contains 13235 protest events, 1314 of which are organized by climate protest groups or mention the climate in their description.\n\n<!-- For the period from 2020-2022, it contains `{python} len(protests.query(\"source == 'acled'\"))` protest events, `{python} len(climate_protests.query(\"source == 'acled'\"))` of which are organized by climate protest groups or mention the climate in their description. -->\n\n__Other existing protest datasets.__ Alternative existing sources of German or international protest data comprise [ProDat](https://www.wzb.eu/de/forschung/beendete-forschungsprogramme/zivilgesellschaft-und-politische-mobilisierung/projekte/prodat-dokumentation-und-analyse-von-protestereignissen-in-der-bundesrepublik)^[See also [Protestlandschaft Deutschland](https://protestdata.eu/methods). for additional data and interactive visualizations], [PolDem](https://poldem.eui.eu/download/protest-events/), the [Mass Mobilization Project](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HTTWYL), and the event database [GDELT](https://www.gdeltproject.org/). They do not cover recent years or are not very complete, and therefore inferior to ACLED for my purposes.\n\n#### The German Protest Registrations dataset\n\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-protest-groups .cell .column-margin tbl-cap='Number of protest events 2020-2022 by protest group in the different data sources.' execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=3}\n|                        |   ACLED |   GPReg |   gprep | GPRep   |\n|:-----------------------|--------:|--------:|--------:|:--------|\n| Ende Gelände           |      46 |       1 |      26 | ?       |\n| Extinction Rebellion   |     171 |      89 |      90 | ?       |\n| Fridays for Future     |     801 |    1078 |     551 | ?       |\n| Fridays for Future + X |      81 |       3 |      22 | ?       |\n| Greenpeace             |      74 |     103 |      42 | ?       |\n| Letzte Generation      |     145 |      26 |      22 | ?       |\n| Other                  |     225 |    1626 |     366 | ?       |\n:::\n:::\n\n\n\\endgroup\n\nProtest statistics are often recorded by public authorities, either when organizers register a future demonstrations, or when the police reports about a past demonstration. Registering a demonstration is a common requirement for exercising the right to protest in European countries, however this requirement is only fulfilled by moderate protests, while more radical protests may purposefully ignore it and are thus not listed in such records. Often the estimated number of expected protesters is also recorded, but it is of course not reliable, and reliability may vary between different protest organizers. Police estimates of past demonstrations should be more reliable and consistent, however with the possibility for systematic bias, such as generally downplaying the number of participants, or specifically downplaying the number of participants for protests that are critical of the government or the police themselves.\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-protest-most-common .cell .column-margin tbl-cap='Number of protest events for the five most busy climate protest days 2020-2022; they are concentrated around the spring and autumn equinoxes. (More esoteric future work might explore the astrological determinants of protest activity.)' execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n|            |   ACLED |   GPReg |   gprep | GPRep   |\n|:-----------|--------:|--------:|--------:|:--------|\n| 2020-09-25 |      97 |      17 |      38 | ?       |\n| 2021-03-19 |      65 |      40 |      18 | ?       |\n| 2021-09-24 |     105 |      35 |       0 | ?       |\n| 2022-03-25 |      59 |      21 |       0 | ?       |\n| 2022-09-23 |      30 |      25 |       1 | ?       |\n:::\n:::\n\n\n\\endgroup\n\nOfficial documents, including protest statistics, can be obtained via _Freedom of Information_ laws. These exist in more than 100 countries and allow anyone to obtain public documents [@FreedomInformationLaws2023]. The specific requirements, exceptions, and costs vary greatly. In Germany, freedom of information exists on the federal level; but many authorities belong to the regional level, where the extent of freedom of information rights varies greatly [@InformationsfreiheitDeutschlandTransparenzranking]; and municipal authorities are not always covered by regional freedom of information laws, sometimes filling the gap with their own legislation.\n\nAccess to public documents has been democratized via platforms that streamline the process of sending requests, escalating the process to oversight authorities or courts if necessary, and making communication and obtained documents available to the public. The [Alaveteli](http://alaveteli.org/) network provides software and hosts such platforms in more than 30 countries across the world. Some independent platforms also exist, such as [Öffentlichkeitsgestz.ch](https://www.oeffentlichkeitsgesetz.ch/) in Switzerland, and _FragDenStaat_ [in Austria](https://fragdenstaat.at/) and [in Germany](https://fragdenstaat.de/). These open the possibility of obtaining official protest data at scale.\n\n__Collection.__ I send 40 freedom of information requests to German demonstration authorities (depending on the region these are either part of the municipal administrations or of the police) and their supervisory bodies concerning protest data in 31 cities. These cities comprise the political capitals of all 16 regions in Germany, the 17 largest cities by population size, as well as some smaller cities for regions where the request in the regional capital is unsuccessful. 4 requests are not answered, 3 are rejected, 11 state that they do not possess such data, 2 have to be withdrawn due to demanded payments of multiple hundreds of euros, and 20 are been partially or completely successful. This yields 17 table documents with various amounts of information. The requests and responses including the original data files can be found at [FragDenStaat](https://fragdenstaat.de/anfragen/?q=demonstration+csv&first_after=2022-12-01&first_before=2023-07-31).\n\n__Cleaning.__ I ignore one of the datasets (Augsburg) because I cannot convert the delivered PDF back to a table, two of them (Saarbrücken and Freiburg) because the data is too unstructured or requires too much cleaning, and one (Duisburg) because the data is delivered very late. The remaining 13 data tables are cleaned manually. One common problem is that the tables specify events that have a duration of multiple days, in some cases even multiple months. Out of concern for a simple data structure, as well as doubt whether these demonstrations really lasted so long, I reduce their duration to the single day when they start.\n\n__Dataset__. The resulting dataset contains 49,800 events from 13 cities. For 11 cities the ex-ante number of expected participants are given, and for 2 of them (Berlin and Magdeburg) the ex-post extimates by the police are also included. For all cities the topic of the protest is given in, presumably as specified by the organizers themselves; and for 4 cities the name of the organizing group is also known. Various additional details such as exact specifications of location, time and duration, and distinctions between protest marches and pickets are available for some of the cities but not in any systematic manner. Further statistics about the dataset can be seen in table tbl-official-overview.\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/2-methods.ipynb|:../src/data/protests/german_protest_registrations/data_map.ipynb#data-official-map |  | echo:false,warning:false,asis:true,eval:false -->\n\n\n#### The German Protest Reports dataset\n\n@wiedemannGeneralizedApproachProtest2022 show how to detect protest events in newspaper articles. They employ the [`gelectra-large`](https://huggingface.co/deepset/gelectra-large) model, a transformer model that is fine-tuned on German texts of various genres. Their dataset consists of almost 4000 newspaper articles from 4 German cities, namely Leipzig, Dresden, Stuttgart, and Bremen, from between 2009 and 2016.\n\n__Replication and experiments:__ I replicate their results and obtain F1-scores of 0.93 for in-distribution and 0.76 for out-of-distribution classification, which is almost identical to the authors' results. I try out some alternative approaches on their data: Simple machine learning models based on TFIDF-features; finetuning the more recent multilingual FlanT5 model; and using GPT 3.0 in a zero-shot setting. None of the alternatives perform closely to the `gelectra-large` model (see @tbl-glpn-alternative-methods for metrics).\n\n\\begingroup\n\\small\\selectfont\n\n| Model    | id F1 | ood F1 |\n|----------|------:|-------:|\n| XG-Boost | 0.87  | 0.60   |\n| FlanT5   | 0.75  | 0.30   |\n| GPT3     | 0.81  | 0.65   |\n| gElectra | 0.93  | 0.76   |\n\n: Results for using alternative classification methods on the GLPN dataset, for in-distribution (id) and out-of-distribution (ood) prediction. {#tbl-glpn-alternative-methods .column-margin}\n\n\\endgroup\n\nIn order to obtain protest events from a broader geographic spectrum, I retrieve metadata of online newspaper articles from MediaCloud (see @sec-data-discourse) for a query containing protest-related keywords.^[The query is based on the query used by Wiedemann, and reads: _'protest* OR demo OR demonstr* OR kundgebung OR versamm* OR \"soziale bewegung\" OR hausbesetz* OR streik* OR unterschriften* OR petition OR hasskriminalität OR unruhen OR aufruhr OR aufstand OR rebell* OR blockade OR blockier* OR sitzblock* OR boykott* OR riot OR aktivis* OR bürgerinitiative OR bürgerbegehren OR marsch OR aufmarsch OR parade OR mahnwache OR hungerstreik OR \"ziviler ungehorsam\"'_] From the obtained metadata, I scrape full-texts where possible. Special care is taken of websites that appear scrapeable but contain only gibberish because the actual content is paywalled: The letters on these websites appear not to be shuffled but transformed by some other processing methods, so the frequency of common characters is very different on these websites than in actual texts, and the websites can be detected and ignored.\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/2-methods.ipynb|:../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-ts |  | echo:false,warning:false,asis:true,eval:false -->\n\nI label the texts myself using [Prodigy](https://prodi.gy/). For the positive class, I require that the article is a report about (potentially among other topics) a recent past protest event, and that basic details including the place and the protest concern are given. The other articles are mostly about completely different topics (such as \"protest\" but not in the political sense, or \"demonstration\" in the sense of showing something, \"blockade\" in a physical context, or the \"protest-ant\" church); or they mention protests in the context of an op-ed or an interview, where the concreteness and recency of the events is often not given.\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/2-methods.ipynb|:../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-sources |  | echo:false,warning:false,asis:true,eval:false -->\n\nIn a first labeling phase, I annotate 650 random articles for training and 500 random articles for evaluation. I train the model and use 500 articles that are predicted positive and label them as well and add them to the training data, in order to combat class imbalance. Training the `gelectra-large` model with the overall 1150 training samples and according to the hyperparameters suggested by Wiedemann, I finally obtain an in-distribution F1-score of 0.78 (precision=0.81, recall=0.75). Then, I use this model to predict the relevance of all the other scraped articles that contain protest-related keywords. Only 11% are relevant, resulting in 20,879 articles of which the (relatively good) model believes that they describe protest events.\n\n\\begingroup\n\\color{Red}TODO: Extraction of dates, locations, protest groups.\n\\endgroup\n\n#### Newspaper coverage {#sec-data-discourse}\n\n::: {.cell .column-page execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Number of daily online newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display. The effects of an outage of the collection system in January 2022 are visible.](2-methods_files/figure-pdf/fig-mediacloud-history-output-1.svg){#fig-mediacloud-history}\n:::\n:::\n\n\n__Online newspapers.__ [Media Cloud](https://www.mediacloud.org/) is an open data platform that continuously crawls newspaper websites around the world and stores article metadata and word counts in a database. Full texts are in principle available by following the links and scraping the websites oneself, but this is very slow and often hampered by anti-scraping measures of the websites. I use the [`api/v2/stories_public/count`](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#apiv2stories_publiccount) endpoint of their API. I query for tags from the [regional and national collections about Germany](https://search.mediacloud.org/collections/news/geographic). Baden-Württemberg and Mecklenburg-Vorpommern are missing from the collection. There has been a (partial) outage in January 2022 resulting in (near-)zero counts for that timespan. I do not exclude this timespan because it would be complicated and error-prone with respect to time-series analysis. This may lead to an under-estimation of eventual causal effect sizes of up to $\\frac{1}{36}\\approx 0.028$, but I do not expect it to influence my results in any other systematic way.\n\n::: {.cell .column-page execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Number of daily print newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display.](2-methods_files/figure-pdf/fig-dereko-history-output-1.svg){#fig-dereko-history}\n:::\n:::\n\n\n__Print newspapers.__ The [German reference corpus](https://www.ids-mannheim.de/digspra/kl/projekte/korpora/) (_Deutsches Referenzkorpus_, DeReKo) archives the full texts of most German-language print newspapers and magazines in an online database for the purpose of linguistic research. An API contains access to a selected corpus, and by (automatically) navigating the user interface, an extended corpus can be searched. The content is renewed on an annual basis and with a delay of a few months, so no data for 2023 is available. Full texts cannot be retrieved from DeReKo, but large context windows for search results are available, which could be used for more nuanced further research. Here, I only use the functionality of obtaining daily article counts for a given query.\n\nI extract an overview table of all newspapers from the corpora W1-W4, remove newspapers that are not available until 2022, remove newspapers that are about niche topics such as cars, beauty, or history, or that are published with less than weekly frequency. I annotate the remaining 154 newspapers on whether they have a national or regional scope, and retrieve the applicable regions for the regional ones, drawing from information on Wikipedia and the newspaper websites. 121 are from Germany, and 15 of these have a (primarily) national scope, while 106 have a regional scope. All regions are represented with at least one newspaper, except the city state of Bremen. Among the 4 (or more) German \"newspapers of record\" [see @NewspaperRecord2023], the conservative _Frankfurter Allgemeine Zeitung_ is missing, and the very popular tabloid _Bild_ is also missing. I retrieve daily article counts for all queries and all thus filtered newspapers, and aggregate them by day on the regional level as well as into a category of national newspapers.\n\n__Topic queries.__ I use queries that allow to examine how many mentions of climate change occur in newspaper articles overall, and how this is further subdivided. I formulate 5 sub-queries (the full word lists are found in @sec-app-queries):\n\n- _Topic:_ Whether an article mentions climate change or climate policy.\n- _Protest:_ Whether an article mentions protest activity (including both general terms, and terms and organization names that are specific to the climate movement).\n- _Framing:_ Whether more dramatic words than \"climate change\" are used, such as \"climate crisis\", \"climate catastrophy\", etc.\n- _Goals_: Whether long-term goals of the climate movement such as carbon neutrality are mentioned.\n- _Subsidiary goals:_ Whether more concrete measures such as a speed limit for cars, or a citizen's assembly on climate change are mentioned.\n\nFrom these sub-queries, I use the _topic_ query as a standalone query, and combine each of the other queries with the _topic_ query to make sure that the terms are actually used in the context of climate change. (Many of the terms have an unambiguous relation to climate change anyway, but some, such as the protest forms or specific solutions, could also appear in other contexts.) I retrieve absolute article counts for each query, aggregated daily on the regional or on the national level.\n\nThe queries allow me to study not only research question 2 (how much overall coverage of climate change is affected); but also (to some extent) to investigate research question 3 (whether this does not backfire by focusing the discussion on the protests rather than the policy issues):\n\n- If the article counts for the _topic `and not` protest_^[This query can be derived from the other queries logically.] query remain constant or even increase due to protests, then this is strong evidence that the protests do not backfire; and if it increases, then their effect is very strong such that they cause more discussion even when the protests are not themselves a topic. A decrease of the article count for this query does not tell us much, since it could still be, or not be, that relevant contents are transported as part of he articles that also mention protests.\n\n- The other queries (_topic `and` framing_, _topic `and` goal_, _topic `and` subisidiary goal_) aim to look at topics where it would be a success for the protests if they occur more in public discourse. If their article counts increase due to protests, then backfiring is unlikely (but still possible in other topic niches that I am not querying for); and if they decrease, it is strong evidence that the protests are indeed backfiring. A result where the counts for some of these queries increase, while they decrease for others may indicate more complicated effects of protests that warrant further research.\n\n- The _topic `and` protest_ query can serve as a sanity check: It would be very surprising if protest events did not cause the counts for this query to markedly increase. This is even more true for the _ACLED_ and _GPRep_ datasets, where the events are (manually or automatically) extracted from newspaper articles.\n\n![The queries produce different lenses on the mass of articles about climate change. The left lens has the disadvantage that we do not know how much the articles that also mention the protests contribute to the discourse about the topic. The right lens has the disadvantage that it ignores aspects that we do not explicitly query for.](figures/queries.svg){.column-margin}\n\n__Alternative topic representations.__ The querying approach that I employ for this study is very coarse, and will deliver clear conclusions only in some cases. It would also be very interesting to see how much room is typically given to the discussion of climate policy in an article that also mentions protests. Moreover, one could measure how prominent the various keywords are within each article, and what other words they cooccur with most, and what sentiments they are accompanied by. Another approach would use topic models to create topics in an unsupervised manner, and observe how their prevalence shifts in the face of protests; this has already been done by @chenHowClimateMovement2023a for the climate protest movement. All of these techniques require full-text data. For newspaper articles, full-text data is in principle available, but relatively hard to obtain (see the notes on fulltext availability in the paragraphs on online and print newspaper sources); so I have not used full-texts here, in order to focus more on the causal aspect.\n\n__Alternative soruces of public discourse.__ Future work could also explore Twitter data (@kratzkeMonthlySamplesGerman2023: a sample of full texts from Germany on a daily basis 2019-2022), [Google Trends](https://trends.google.com/) data (search query counts on a weekly and regional basis starting from 2005), or parliamentary speech (@abramiGermanParliamentaryCorpus2022: speeches from regional German parliaments from the nineties until 2021). Twitter data does not come with geographical annotations, and Google Trends and parliamentary speech are not available on a continuous daily basis, so I focus on newspaper articles here.\n\n#### Instruments {#sec-meth-data-instr}\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/2-methods.ipynb|:../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-weather-time-series |  | echo:false,warning:false,asis:true,eval:false -->\n\n__Weather.__ Weather data is obtained via the [Meteostat](https://meteostat.net/en/about) project from _Deutscher Wetterdienst_, containing the 8 variables displayed in @fig-weather-time-series. Related work on causal methods for protest impact analysis typically uses precipitation or rainfall, and in some cases additionally temperature and windspeed as instruments. I consider all available weather variables as potential instruments. Two systematic concerns have been raised about using weather variables as instruments:\n\n1. _Indirect paths._ @mellonRainRainGo2023 find 195 variables that have been linked to the weather in previous studies (ironically, many of them instrumental variable studies themselves), and that these undermine the exclusion criterion for instrumental variables, threatening the validity of the variables. The authors have constructed a comprehensive causal graph depicting the known effects of the weather. It shows that _protests_ as well as _violent protests_ are influenced by rainfall and temperature, and that protests have an influence on repression, voting behaviour, policy, and property values. There is no study confirming an influence of the weather on newspaper reporting, but possible indirect paths may include _mood_ and (for climate protests) _pollution_. Other variables such as _migration_ may also have an effect because attention to them might decrease attention to other topics in the news; however most of this kind of variables are only related to the weather in the long term and not in the short term.\n\n2. _Spatial interdependence._ @coopermanRandomizationInferenceRainfall2017 raise concern about spatial interdependence of rainfall across regions. This applies particularly when the effect of rainfall across regions _on a single date_ is investigated, for example in the context of an election. In my setting I investigate the individual effects of protest events that are spread across multiple years. The amount of protests that take place on the same date is therefore very small, and spatial interdependence of the _weather_ among temporally separated events is very low. Spatial interdependence of the _climate_ (thus also influencing the weather) is still a problem. When removing the climate influence from the weather and only using the (climate-independent) weather as instrumental variables, the spatial interdependence should be mostly removed from the intrumental variables.\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Pandemic restriction variables (1). The figure displays 6 different variables that show how often various place categories are visited.](2-methods_files/figure-pdf/fig-covid-19-time-series-output-1.svg){#fig-covid-19-time-series}\n:::\n:::\n\n\n::: {.cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![Pandemic restriction variables (2). The figure gives the stringency index, an aggregated measure of expert estimates of the severity of restrictions along multiple dimensions.](2-methods_files/figure-pdf/fig-covid-19-time-series-2-output-1.svg){#fig-covid-19-time-series-2}\n:::\n:::\n\n\n__Pandemic restrictions.__ The timespan covered by my dataset coincides with the Covid-19 pandemic, which has had very drastic impacts in 2020 and 2021, and still some in 2022. This may open up the possibility for exploiting a new kind of instrumental variable, because the pandemic comes with both legal restrictions and psychological aversion against large gatherings, including demonstrations. Available data includes the _stringency index_ calculated by the [Oxford Coronavirus Government Response Tracker](https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker) and provided by [Our World in Data](https://ourworldindata.org/covid-stringency-index) [@fig-covid-19-time-series-2]; and _Google Mobility Trends_ data, also provided by [Our World in Data](https://ourworldindata.org/covid-google-mobility-trends) [@fig-covid-19-time-series]. Both datasets are only on the national level for Germany. While the stringency index is rather static, the mobility trends data contains more randomness. The randomness may indirectly be influenced by the weather, which is neither a problem, nor an advantage, since I already use the weather variables directly. Two reasons may threaten the validity of the pandemic variables as an instrument.\n\n1. _Temporal correlation._ Unlike the weather, COVID-19 restrictions are temporally correlated over longer timespans, that is, they change more slowly. This introduces some chance that they may be accidentally or systematically correlated with political processes and with media attention cycles.\n2. _Direct media impact._ There is a potential direct impact of COVID-19 on media coverage: Stricter restrictions may correlate with a more intense media focus on the pandemic, decreasing attention on any other topic. Controlling for coverage levels before the protests can decrease this problem.\n\n### Data aggregation {#sec-agg}\n\nThe data is aggregated by region and date. For every day and region there is a row that contains information about all causal variables. In causal terms, days are the _treatment units_, and the treatment is whether or not a protest (by a certain group) takes place on a given day in a given region. Summarizing and categorizing the variables that are described in detail in the above sections, we have:\n\n- Treatment __W__:\n  - For each protest group, a dummy variable whether it organizes at least one protest event in the given region (that is, a _binary_ treatment).^[Alternatively, I could use for each protest group the number of protesters in the given region as a _continuous_ treatment; but this requires (a) slightly more complicated methods to deal with continuous treatments, and (b) difficult assumptions about scaling -- does the number of participants have a linear impact, or a logistic one, or is it more complicated?]\n- Outcome __Y__:\n  - Number of newspaper articles published that mention the climate crisis, across 5 dimensions (see @sec-data-discourse): overall mentions; mentioning protest activity; mentioning long-term goals; mentioning specific short-term goals; using a drastic or catastrophic framing. I also use multiple impact timespans, see below.\n- Instruments __Z__:\n  - Weather: min/max/avg temperature, air pressure, precipitation, snowfall, wind speed, and peak gust\n  - Covid restrictions: stringency index of the restrictions, and movement variables for 6 location types\n- Known confounders __X__:\n  - Day of the week, as dummy variables\n  - Holiday occurrence in the given region\n  - Region dummies\n  - Time-series lags of all variables (with variable number of lags, subject to hyperparameter optimization)\n  - Exponential moving averages of $W$ to account for the long-term impact of previous protests (with spans of 7, 28, 112, 224 days each)\n  - Time-series differences of $Y$ to account for trends in media coverage (with distances of 1, 7, 28, 91, 182, 364 days each)\n- Unknown confounders __U__:\n  - __*?*__\n\n__Regional aggregation__. My setting throughout all methods is that I estimate models based on regional data. However, I do not fit separate models for each region, but always a single model on a dataset that includes all regions. This has the benefits that _(a)_ it leads to more generalizable results and _(b)_ it increases the size of the dataset by a factor of 14 (in comparison to using national data, or to estimating single regional models), and thereby increases statistical power. To integrate multiple time series from the various regions into a single dataset, I add static _dummy variables_ for each region. Limitations of this approach are:\n\n1. To capture the effect of regional differences properly, it would be necessary to also add _interaction terms_ of all 14 region dummies and all 5 treatment variables, as well as potentially some of the control variables. This would lead to at least 70 interaction terms, which would make the interpretation of the results much harder.\n\n2. The _differences_ between the regions -- especially in size, population size, and number of newspapers -- are potentially problematic for the estimation of a global model. I minimize this problem by (a) including previous amounts of coverage and (b) using absolute rather than relative coverage. While the relative coverage of a protest event will presumably be lower in larger regions (because a smaller proportion of the region is affected by any event), this will not be the case in absolute terms. However, it may be the case that there are major protest events with a strong relation to regional politics, and that they have an impact throughout the whole region, and in that case the size of the region might matter. This would not be captured by the model and could lead to a high variance the treatment effect estimates.\n\n3. On the other hand, the _national impact_ of protests is politically more interesting, so I also estimate a model on the national level, which has the structure as any of the regional models, but with aggregated treatment variables and newspaper coverage from national rather than regional newspapers.\n\n__Outcome time series.__ Protests may have an impact on newspaper converage not only on the day that they occur but also in the following days and weeks, so I estimate time series of causal impacts, as well as of cumulative impacts. For estimating the delayed impacts, I do _not_ extend the time series lags further into the future, because the amount of coverage on or after the protest date likely mediates the impact on future coverage. These mediated impacts are hard to isolate. By not including potential mediators in the predictors, I make sure that all indirect impacts are also clearly attributable to the treatment. I do _not_ extend the lags of the treatment further into the future either (mostly motivated by efficiency gains that are related to implementation details), so indirect impacts that are mediated by future protests (if they exist) are also included in the impact estimate.\n\n### Causal impact estimation\n\nFor the selection of suitable models, I specify the treatment as the occurrence of a protest event by any protest group, and the outcome as the one-week amount of total newspaper coverage mentioning the climate crisis. I then use these models to also estimate more specific impacts for events from specific groups; and for the coverage during single days, in order to build impact estimate time series.\n\nFor the main experiments I use the ACLED dataset as source for protest events; and as source for media coverage I use the sum of both online and print newspaper articles.\n\n#### Regression {#sec-meth-reg}\n\nI estimate an OLS regression model, in order to interpret the coefficients for the treatments causally. This assumes the complete and correct specification of all confounding variables, and a linear model; see @sec-app2-reg for formal details.\n\nI perform hyperparameter optimization by 5-fold time-series cross-validation. Hyperparameters are: number of time series lags, inclusion of region dummies, inclusion of moving average features, and inclusion of time-series difference features (see @sec-agg).\n\nAn interesting question is what metric to optimize for. In predictive contexts this would typically be the (root) mean squared error ((R)MSE) or the mean average error (MAE); they minimize variance in the first place. For causal impact estimation, we want the estimates to be _unbiased_ much more than we want them to have a low variance. Therefore I minimize the bias, operationalized as the absolute value of the mean error (ME). Unlike the MAE, this takes the direction of the errors into account.\n\nOLS is unbiased for in-distribution data anyway. I want a model that also generalizes to out-of-distribution data -- this is what we generally want from causal models -- and OLS is not automatically unbiased for this. By using time-series cross-validation splits, I create a situation that is slightly out-of-distribution. Future work could also create situations that are more extremely out-of-distribution, for example by using large gaps for the time-series splits, or by using geographic splits.\n\nTo set the generalization capabilities of the OLS model into perspective, I also estimate similarly optimized Ridge and Lasso regression models. But I cannot use them for causal impact estimation because the coefficients are regularized and thus biased.\n\nI use the `OLS` implementation from the `statsmodels` package [@perktoldStatsmodelsStatsmodelsRelease2023] with `HC3` heteroskedacity-robust covariance estimation, and the `BayesianRidge` and `LassoLarsIC` implementations from `scikit-learn` [@pedregosaScikitlearnMachineLearning2011]. `statsmodels` does not support multivariate regression, so I run separate univariate models for each target variable.\n\n#### Instrumental variables {#sec-instrumental}\n\nI have 16 candidate variables for potential instruments. Their nature and validity is discussed in @sec-meth-data-instr. I procede in multiple exploratory steps.\n\n1. __Correlation.__ I compute correlations and Wald estimates (see @sec-app2-iv-ils) and compare them to each other. The Wald estimator is only valid for strong instruments.\n2. __Regression.__ I perform first-stage regression, that is, I regress protest occurrence on all instruments, controlling for the known confounders (time series data, in the same format of the hyperparameter optimization from @sec-res-reg). I adjust p-values for multiple testing via the Benjamini-Yekutieli procedure [@benjaminiControlFalseDiscovery2001a] because the variables are likely very correlated.\n3. __Deseasoning.__ Instrumental variables should be (almost) random, which is violated by seasonality, and most candidate variables have obvious seasonal patters. I compute seasonal components by taking 90-day rolling averages with a Gaussian window with a standard deviation of 30 days. I consider only the nonseasonal components, that is the residuals of the seasonal components, are potentially valid instruments. Again I perform first-stage regression on these residuals, controlling for the knwon confounders and the seasonal components. <!-- (The residual components seem much more meaningful when given the seasonal components.) -->\n4. __Principal components.__ Since there is probably a high correlation among the covid variables as well as among the weather variables, I compute principal components both for the seasonal and for the nonseasonal components, separately. The intent is (a) to potentially find components that have a higher impact than the individual instruments, because they may find and isolate patters, and (b) to account for the problem that regression may underestimate the impact of multicollinear variables.\n\nThen I use an alternative of two-stage least squares (see @sec-app2-2sls) that is more robust to weak instruments, namely _limited information maximum likelihood_ (LIML) to estimate the causal effect. I include the same confounders as from the optimized regression model (@sec-res-reg). I use the `IVLIML` implementation from the `linearmodels` library [@sheppardBashtageLinearmodelsRelease2023a].\n\n#### Synthetic control {#sec-synth}\n\nI fit a synthetic control for each protest event.[^global] Control regions are all regions that do not have a protest event on the given date. For all regions, outcome variables[^sociodemographic] of all coverage dimensions are considered during a specified pre-treatment period. Values of the different dimensions are stacked, resulting in one column per region. The columns for the control regions are scaled, where the scaling options are: demeaning (subtraction of the mean), as suggested by @fermanSyntheticControlsImperfect2021; subtraction of the values from the last date within the pre-treatment period; z-score standardization; mean normalization (division by the mean); and logarithmic scaling. Nonnegative least squares (NNLS) regression is performed to predict the treatment region values from the control region values; alternatively, interpolation is performed, which is similar to NNLS but demands that the coefficients for the regions um up to 1. The obtained weights are then used to predict the counterfactual for the post-treatment period from the control regions. The difference between actual values and counterfactual is the causal impact. (See @sec-app2-synth for mathematical model assumptions.)\n\n[^global]: Estimating region weights globally rather than for every single protest event is not possible because the available control regions vary between events.\n\n[^sociodemographic]: Alternatively to regressing on pre-treatment outcomes, weights can also be obtained by fitting on fundamental characteristics of the regions (such as sociodemographic or economic statistics) that are considered predictive of the outcome [@abadieSyntheticControlMethods2010]. I discard such an approach because the choice of variables biases the causal impact estimate, and I find it hard to justify any specific variables that would be predictive of climate change newspaper coverage.\n\nFor the synthetic control method, significance is typically evaluated by using permutation tests. In my setting I do not only have a single estimate, but rather a large number of estimates from fitting many synthetic controls, so I can compute confidence intervals based on the population variance of the estimates.\n\nI manually evaluate the suitability of the scaling and fitting methods by plotting the pre-treatment fit. The length of the pre-treatment period is chosen by hyperparameter optimization. The objective is an unbiased estimation of the counterfactual in the post-treatment period. Since the counterfactual is unknown, a workaround is to minimize the post-treatment bias in the general case. If the weights generally represent the \"true\" relationship between the regions, then they will also do so for the counterfactual, subject to the model assumptions from @sec-app2-synth. Therefore I perform hyperparameter optimization for minimizing the post-treatment error in synthetic control settings for randomly selected dates (rather than actual protest dates).[^pretreat] This is similar to having a large number of train-test splits, to which the synthetic control method is applied, and additional cross-validation is not necessary.\n\n[^pretreat]: An alternative is to focus on the pre-treatment fit. Theoretically both approaches are similarly justified. By referring to propensities, anticipation effects, or missing data, one may practically argue in favour of one approach or the other; see @sec-disc-synth for further discussion.\n\nI use a custom implementation that builds on @facurealvesCausalInferenceBrave2022 [ch. 15]. Future work may also use a _Bayesian structural time series_ model [@brodersenInferringCausalImpact2015a], which makes similar assumptions and is practically more flexible.\n\n#### Propensity scores\n\n_Propensity scores_ quantify the probability of the treatment, that is: _How likely is it on a given day in a given region that a protest takes place?_ (See @sec-app2-ps for mathematical details.)\n\nI obtain propensity scores by training probabilistic classifier models to predict the treatment (the occurrence of protests) from the known confounders (primarily past time-series values and features, see @sec-agg). I consider Naive Bayes and logistic regression models because they both produce well-calibrated probabilities. I optimize the following hyperparameters on a 5-fold time-series split: number of time series lags, inclusion of region dummies, inclusion of moving average features, inclusion of time-series difference features, and inclusion of log-scaled participant numbers (and corresponding moving averages) in the past time series (in addition to the binary protest occurrence variables). For logistic regression I also consider whether balanced class weights are used. Optimization objective is the F1 score.\n\nAs final propensity scores I use cross-predicted probabilities from a conventional 5-fold cross-validation split, because time-series splits would not yield predictions for the start of the time series.\n\nI use _inverse propensity weighting_ (IPW) as a pure propensity score model. IPW essentially calculates a weighted mean, where more weight is given to protest days with a low probability for a protest, and to non-protest days with a high probability for a protest (see @sec-app2-ipw for details). IPW can be combined with regression, which is called _doubly robust estimation_ (DRE), and which is theoretically valid if the assumptions of at least one of its parts hold (see @sec-app2-dre).\n\nI use the IPW implementation from the `DoWhy` Python package [@sharmaDoWhyEndtoEndLibrary2020], with a normalized weighting scheme (that is, the Hájek estimator, see @sec-app2-ps) for ATT estimation. As an implementation for DRE I use the `LinearDRLearner` from the `EconML` Python package [@econml] with their `StatsModelsLinearRegression` model as regression model. For the computation of propensity scores I use `LogisticRegressionCV` from `scikit-learn` [@pedregosaScikitlearnMachineLearning2011] with the `liblinear` solver.\n\n<!--\n\n##### Propensity scores from full texts\n\ncite Wager, and causal NLP overview\n\nPredicting propensity scores from text: cite causalNLP overviews\nFor example, @bundeskriminalamtbkaLagebildLetzteGeneration2023 hypothesize that \"Die Fallzahlen unterliegen einem „wellenartigen“ Verlauf, welcher sich vornehmlich durch (das Ausbleiben von) Großveranstaltungen im gleichen Kontext erklären lässt.\"\n\npossible models:\n\n- gelectra: 100-300M parameters https://huggingface.co/deepset/gelectra-base\n- igel: 6B parameters https://huggingface.co/philschmid/instruct-igel-001\n- llama 2 german https://huggingface.co/flozi00/Llama-2-7b-german-assistant-v2\n\nfaster finetuning: https://github.com/huggingface/peft -->\n\n#### Evaluation {#sec-meth-placebo .appendix}\n\nThere is no straightforward way to evaluate causal models, since the true causal impacts are unknown.\n\n__Subsidiary metrics.__ The sections above describe the optimization and evaluation of subsidiary metrics for the individual methods:\n\n- For the regression method I evaluate the predictive quality on time-series splits in terms of bias. The best model is also used for the parts of the other methods that use regression (the individual stages of the 2SLS instrumental variables estimator, and the second stage of the doubly robust estimaor).\n- Similarly for the synthetic control I evaluate bias on time-series splits, just that the underlying regression works differently.\n- For the propensity score methods I evaluate the classification quality in terms of the F1 score in time-series splits. (Conventional splits are used for prediction.)\n\n__Placebo tests.__ An evaluation method that is specifically suited to causal models are _placebo tests_. They cannot show that a model is correct, but they can make it much more plausible [@dingFirstCourseCausal2023, ch. 16]. I use two types of placebo tests:\n\n- _Negative outcome_ [see @dingFirstCourseCausal2023, ch. 16.2.1]. Here I compute the causal impacts of protest events on newspaper coverage before the occurrence of the events. These outcomes are very similar to the outcomes that I actually want to estimate, but we know that there is no causal impact, due to the order in time. (See @sec-disc-synth for discussion of anticipation effects.)\n- _Negative exposure_ [see @dingFirstCourseCausal2023, ch. 16.2.2]. Here I compute the impact of random days rather than days with protest events. I assign the random treatments by sampling without replacement from the actual treatments; so the distribution of protest and non-protest days remains the same. I perform two sampling procedures: (a) sampling within each region, so that the protest-day proportions among the regions remain intact and some bias is retained; and (b) sampling across regions, so that treatments are completely random.\n\nThe expectation for the placebo tests is that the models should estimate zero causal impacts for them. If they estimate clear non-zero impacts, then the models are shown to be incorrect.\n\n",
    "supporting": [
      "2-methods_files"
    ],
    "filters": []
  }
}
