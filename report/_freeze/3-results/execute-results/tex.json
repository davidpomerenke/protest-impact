{
  "hash": "98d1811be09bc817506a1ac428f731ad",
  "result": {
    "markdown": "---\nexecute:\n  freeze: true\ntitle: Results\n---\n\n\n\n\n<!--\n\nAnalysis of the results with graphics like bargraphs and boxplots has been made. Statistical methods have been employed to compare different results. AUCs have been obtained. Minimal verification.\n+ Attention has been paid to the distribution of the data. Verification has been carried out. Attention is paid to overfitting.\n+ Results have been analysed with proper statistics. Model assumptions of statistical methods are verified or methods that do not make assumptions were employed for non-Gaussian data. Checks were made to avoid hidden overfitting.\n+ Best approach for obtaining significant results was taken while refraining from p-value hacking.\n\n -->\n\n\n### Evaluation of methods\n\n#### Regression {#sec-res-reg}\n\n| Model          | Hyp. opt. obj. | RMSE          | Bias         |\n| -------------- | -------------- | ------------- | ------------ |\n| OLS            | min RMSE       | 110.6 ± 24.2  | -18.8 ± 10.4 |\n| OLS            | min bias       | 130.9 ± 21.5  | -14.3 ± 10.1 |\n| BayesianRidge  | min bias       | 119.7 ± 23.4  | -3.85 ± 15.2 |\n| LassoLarsIC    | min bias       | 118.9 ± 24.5  | -2.89 ± 15.7 |\n\n: Using 5-fold time-series split. (Results for using conventional cross-validation split are approximately unbiased (bias < 0.02).) {#tbl-reg-hypopt}\n\nHyperparameter optimization shows that the best OLS regression model uses 7 time-series lags of all variables and no additional features. On 5 time-series cross-validation splits, it achieves a predictive performance with a root mean squared error (RMSE) of 36.5±6.2 and a (cross-validated) R² of 0.88±0.02. (The dimension is the sum of the number of climate articles published within a given date and the following day.) This is almost identical to a similarly tuned Bayesian Ridge regression model, which achieves an RMSE of 36.5±6.3 and the same R² value. A detailed regression table for the best OLS model can be found in @sec-app1-reg.\n\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n(1.3852660355293869,\n (-3.859322529582423, 6.629854600641197),\n 0.6046745119960286)\n```\n:::\n:::\n\n\nThe coefficients for the protest variables are equivalent to the ATT (see @sec-app2-reg). Statistically significant at p=0.05 are only protest events by Fridays for Future, Letzte Generation, and groups that are coded as \"other\" groups. All protest coefficients are positive except for Ende Gelände and Fridays for Future + X, with negative coefficients at p-values of 0.89 and 0.18 respectively. For the aggregated protest occurrence variable (which does not consider the organizing protest group) the estimate is +5.79 additional articles in the first two days, with a confidence interval [+2.67, +8.92] and a p-value of 0.0003. More estimates are displayed in @sec-res-est.\n\n<!-- MSE generalizability -->\n\n#### Instrumental variables\n\nOut of the 15 potential instrumental variables, 5 pandemic instruments and 4 weather instruments have a statistically significant impact on protest occurrence (see @fig-iv-basic), but when using them in a combined regression the coefficients are much less significant. Precipitation is not among the significant variables.\n\nAutomatically binarizing the variables based on an optimally chosen threshold does not generally increase the coefficients and siginificances, and decreases them slightly in most cases. This is also true for precipiation: The optimal threshold for maximizing the covariance with protest occurrence is at prcp > 0, which is consistent with the choice in most related work (see @sec-weatherlit). I find that such binarization is not systematically better or worse than using the continuous value. (For the single regression, it slightly decreases the coefficient, and for the combined regression with other variables it slightly increases the coefficient.)\n\n::: {.cell fig-label='fig-iv-pc' execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![Principal components of the](3-results_files/figure-pdf/cell-3-output-1.pdf){}\n:::\n:::\n\n\n<!-- pc_0 at p=0.0005, pc_7 at p=0.007, and pc_11 at p=0.008 -->\n\nPrincipal component decomposition isolates three very significant components with p<0.01, while the other components have p>0.05.^[This is without adjusting for multiple testing since no hypothesis tests or thresholds are used, but the analysis is rather exploratory.] The three components are displayed in terms of the original variables in @fig-iv-pc.\n\n::: {.cell fig-label='fig-iv-pc-deseasoned' execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![Principal components of the](3-results_files/figure-pdf/cell-4-output-1.pdf){}\n:::\n:::\n\n\nDeseasoning the original variables and then performing separate principle component analyses on seasonal and residual parts shows that most of the significant variables are seasonal in nature; but there is also one very significant residual variable pc_resid_9 at p=0.0005 and two somewhat significant residual variables pc_resid_8 at p=0.05 and pc_resid_11 at p=0.07, while all other residual components have p>0.15 (without adjusting for multiple testing). The more significant components are broken down in @fig-iv-pc-deseasoned. The first-stage f-statistic for pc_resid_9 is f=33.82; f=2.08 for pc_resid_8; and f=2.02. According to the \"rule of thumb\" (@InstrumentalVariablesEstimation2023) the threshold for weak instruments is around f=10, so pc_resid_9 would be a strong instrument but the other ones would all be weak. The combined f-statistic of the three mentioned components is f=38.74.\n\nPlacebo tests for the first stage (the impact of the instrument on the treatment) are given in @fig-iv-1-placebo. From day 3 after the protest date there is no longer a significant impact of the instrument on the treatment\n\n::: {.cell fig-label='fig-iv-1-placebo' execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![First stage placebo tests for using the principal component pc_resid_9 to instrument protest occurrence. Values for the instrument from after the protest date are used. These values cannot have an impact on protest occurrence if the instrument is valid.](3-results_files/figure-pdf/cell-5-output-1.pdf){}\n:::\n:::\n\n\n#### Synthetic control\n\n180 lags\nrmse 65.8+-2.40\nbias\n-0.330+-1.13\n\n::: {.cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-6-output-1.pdf){}\n:::\n:::\n\n\n::: {.cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-7-output-1.pdf){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-7-output-2.pdf){}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![with 7-day rolling average](3-results_files/figure-pdf/cell-8-output-1.pdf){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-8-output-2.pdf){}\n:::\n:::\n\n\nDifficulties with large protest events: plot size vs #regions\n\n#### Propensity scores\n\nhypopt n lags, ewm, diffs, log sizes\n\npredicting all positive: 0.118\n\nlogistic regression unbalanced with diffs, ewms, sizes, 4 lags\n\nF1: 0.233±0.044\nbalanced: 0.213+-0.017\n\n### Placebo tests\n\n#### Placebo outcome\n\n::: {.cell .column-page execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-9-output-1.pdf){}\n:::\n:::\n\n\n#### Placebo treatment\n\n::: {.cell .column-page execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-10-output-1.pdf){}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![](3-results_files/figure-pdf/cell-11-output-1.pdf){}\n:::\n:::\n\n\n\n\n### Causal impact estimates {#sec-res-est}\n\n#### Time series\n\n::: {.cell .column-page execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![Note that the y-axes are shared between some of the plots, but the instrumental variable plot has a much larger y-axis.](3-results_files/figure-pdf/cell-13-output-1.pdf){}\n:::\n:::\n\n\n#### Cumulative impact\n\n::: {.cell .column-page execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![Note that the y-axes are shared between some of the plots, but the instrumental variable plot has a much larger y-axis.](3-results_files/figure-pdf/cell-14-output-1.pdf){}\n:::\n:::\n\n\n#### Protest groups\n\nCausal effects for the individual protest groups differ substantially between regression and inverse propensity weighting and are not statistically significant at p=0.05 for the doubly robust estimator.\n\n::: {.cell .column-page fig-caption='Error bars are 95% confidence intervals.' execution_count=14}\n\n::: {.cell-output .cell-output-display execution_count=14}\n![](3-results_files/figure-pdf/cell-15-output-1.svg){}\n:::\n:::\n\n\n::: {.cell .column-page fig-caption='Error bars are 95% confidence intervals.' execution_count=15}\n\n::: {.cell-output .cell-output-display execution_count=15}\n![](3-results_files/figure-pdf/cell-16-output-1.svg){}\n:::\n:::\n\n\n::: {.cell .column-page fig-caption='Error bars are 95% confidence intervals.' execution_count=16}\n\n::: {.cell-output .cell-output-display execution_count=16}\n![](3-results_files/figure-pdf/cell-17-output-1.svg){}\n:::\n:::\n\n\n#### Datasets\n\nTODO\n\n",
    "supporting": [
      "3-results_files"
    ],
    "filters": []
  }
}
