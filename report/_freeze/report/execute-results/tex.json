{
  "hash": "b91166c9310ce0533454783518b7a82d",
  "result": {
    "markdown": "---\nauthor-meta: David Pomerenke\ntoc: true\ntoc-depth: 3\ntitle-meta: How do protests shape discourse? - Causal methods for determining the impact of protest events on newspaper coverage\nlicense: CC BY-NC\ndate-meta: August 30, 2023\ninclude-before-body: titlepage.tex\ntitle: \" \"\n---\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nThe difference between the goals and/or context of the thesis with existing solutions (e.g. found in literature) were studied and clearly described to support the problem definition, clearly indicating the innovative part of the thesis task.\n\nthe introduction defines the problem, sets it in terms of the state-of-the-art and clearly indicates what the contribution of the thesis is\n\n -->\n\n## Introduction\n\n### Problem statement\n\nAre protests effective, and how much? Or do they also backfire, by distracting from the discussion of the protest concern, and by merely causing discussion about the protests themselves? Protest groups, participants, supporters, and opponents can use media impact analysis and count the number of newspaper articles that appear to be caused by a protest event. Such analyses may be biased due to possible confounding: Protests and increased media coverage may stem from shared sources. In the case of climate protests, extreme weather events, climate conferences, political decisions, or the intensity of public discussion are candidates for such confounders, and there may also be hidden confounders that do not easily come to mind.\n\n<!--\n\nAt least three research questions are present and relevant.\n+ research questions are well-positioned in the research context.\n+ research questions are well-positioned in the literature.\n\n -->\n\n__Research questions.__ This master thesis applies and evaluates multiple causal inference techniques that aim to rigorously estimate the causal impact of protest events on regional newspaper coverage. The methods are _regression_, _instrumental variables_ [@staigerInstrumentalVariablesRegression1997], _synthetic control_ [@abadieSyntheticControlMethods2010], and _propensity score_ methods [@rosenbaumModelBasedDirectAdjustment1987]. Specifically, I aim to answer the following research questions:\n\n1. Can the causal methods be applied to study the impact of protest events on newspaper attention? What limitations apply, and what problems occur? Are the estimates consistent, and how do they differ from each other?\n\n2. What is the _Average Treatment Effect on the Treated_[^ATT] (ATT) of protest events on newspaper coverage; for climate protests in general, and with respect to the protest group that organizes the protest?\n\n3. What can we say about the hypothesis that climate protests _distract_ from discussing solutions to the climate crisis constructively?\n\n4. (Are datasets obtained (a) from authorities or (b) via semi-automated collection and processing suitable alternatives to manually curated protest event data?) - _I hope that I can still compare the datasets, otherwise I'll leave it out._\n\n[^ATT]: The _Average Treatment Effect on the Treated_ (ATT) is the effect that the protests that took place have actually caused, on average, in comparison to the case that they had not taken place. It differs from the _Average Treatment Effect_ (ATE) by focusing on the effect of the protest days rather than the potential effect of all days. See @sec-app2-reg for mathematical definition.\n\n__Protest event analysis.__ @hutterProtestEventAnalysis2014 gives the sociological foundations by definint the method of _protest event analysis_, and discusses coding methods for defining and distinguishing protest events.\n\n__Protest impact.__ Research into the impact of protest movements has recently been spearheaded by a series of literature reviews and expert interviews by Ozden and Glover. In the context of effective altruism, they aim to assess how effective protest movements are as a means for political change, and what factors determine their success. In their literature review on protest outcomes @jamesozdenLiteratureReviewProtest2022, they conclude that _causal inferences on protest outcomes are generally challenging to draw due to confounding, and it is even harder to determine the long-term effect_. They warn that the average effect size of protests is likely over-estimated in the existing literature, due to selection bias on the level of media coverage, researcher interest, and statistical significance (publication bias). Based on their review, they estimate that protest movements (consisting of many single protest events) may raise salience and support for the issue by 2-10%, and may influence voting behavior by 1-6 percentage points. The influence on public discourse may be high in certain cases, and in the case of the Black Lives Matter movement may have amplified coverage by a factor of 10.\n\nIn interviews with researchers, @jamesozdenExpertInterviewsProtest2022 establish that while there is much research on protest outcomes, the causal connections between protests and their outcomes are an underexplored research area (interview with Robyn Gulliver in the cited report); that a causal link between protests and certain outcomes is plausible, but hard to attribute to any specific protest group (interview with Ruud Wouters in the cited report); and that causal effects are typically measurable only on a local level due to the lack of a control group at the national level. More generally, protest outcomes may be subject to confounding, and the causal arrow between protests and increased concern may point in either direction. The interviews with researchers, as well as interviews with UK policymakers [@jamesozdenPolicymakerInterviewsProtest2022], suggest that the causal effect of protest on policy is strongly if not completely mediated by public opinion.\n\nIn a follow-up, [@samgloverLiteratureReviewProtest2022; @jamesozdenWhatMakesProtest2023] review the factors that causally affect the success of protest movements. They attribute a high importance to the number of participants, and to the nonviolent nature of the protest, as well as a favourable sociopolitical context, including media coverage. A moderate effect is attributed to the diversity and the unity of the movement. They also look at the so-called _radical flank effect_, a theory that moderate movements benefit from the simultaneous presence of a more radical movement for the same issue. Their review finds moderate effects from a radical flank, but only if the radical flank is also nonviolent.\n\n__Relevance of newspaper coverage.__ Protest movements are often highly strategic [see @englerThisUprisingHow2016 for discussion]. Newspaper coverage is a typical criterion by which protest groups and funding organizations quantify impact: Four of the most relevant German climate protest groups maintain press review databases ([1](https://fridaysforfuture.de/presse/pressespiegel/), [2](https://letztegeneration.org/presse/berichterstattung-1/), [3](https://extinctionrebellion.de/presse/pressespiegel/), [4](https://www.ende-gelaende.org/pressespiegel/)), and a major international protest funding organization uses the \"number of triggered media items\" as one of three evaluation criteria [@knuthFinanzierungKlimaaktivismusAm2023]. The reason is either that the protests aim to raise public attention in the first place, or that they consider media coverage as a proxy for further impact, including eventually policy change. Protests are directly observed by typically only a small number of people, and it is plausible that media coverage is an important mediator for further impact (todo: find citation). Alternative plausible mediators are social media posts, public opinion (as measured in opinion surveys), or parliamentary speech. For methodical reasons (see @sec-data-discourse), I focus on newspaper data, and more specifically _regional_ newspaper articles, because they allow for the application of the synthetic control method. These methodical decisions may well be considered as \"looking under the lamppost\" (@fig-lamppost), but they may enable the analysis of more interesting data in the future.\n\n![\"Looking under the lamppost\" by [Sketchplanations](https://sketchplanations.com/) (CC-BY-NC)](figures/lamppost.png){.column-margin #fig-lamppost}\n\n__Causal impact evaluation.__ Academic work on protest impact analysis is aware of the problem of confounding. Previous work has used _regression_, _difference-in-differences_, and to a large extent the _instrumental variables_ method (see @sec-lit-causal). With a single exception [@huet-vaughnQuietRiotCausal2013], the aggregate impact of protest movements that stretch over longer timespans is evaluated, rather than the impact of single events. Causal inference has developed the _synthetic control method_ [@abadieSyntheticControlMethods2010] for the analysis of single events, as well as extensions including _synthetic difference-in-differences_ [@arkhangelskySyntheticDifferenceinDifferences2021] and _Bayesian structural time series_ [@brodersenInferringCausalImpact2015a]. _Propensity score methods_ are not specifically made for the analysis of events but can be easily adapted by using time series data for the estimation of the propensity scores. Alternatively, they can be estimated from full text data [@keithTextCausalInference2020; @weldAdjustingConfoundersText2022]. _Event history analysis_ [@tekleEventHistoryAnalysis2012] is concerned with estimating the risk of the occurrence of events, which is not my research objective, but is relevant because it is similar to estimating propensity scores from time series. Related work using causal approaches for protest impact analysis is reviewed in more detail in @sec-lit-causal.\n\n<!--\n\nResearch has advanced state of the art. Described thesis research would lead to a publication in an international peer-reviewed journal or an international peer-reviewed conference.\n\nThe research itself is very theoretical or highly interdisciplinary requiring the student to read into both challenging and theoretical material well beyond the scope of the programme.\n+ this attitude is constructive and well-balanced.\n\n -->\n\n__Contribution.__ I study the causal impact of disaggregated protest events. This is different from the mainstream of the protest impact literature (see @sec-lit-causal) and similar only to @huet-vaughnQuietRiotCausal2013 -- but unlike them I leverage the setting to determine the individual impacts of protest groups that act during the same timespan in a shared geographic space. I simultaneously apply multiple causal methods, optimize their hyperparameters with respect to bias, and evaluate them in three different placebo tests; while @wasowAgendaSeedingHow2020 excellently combines multiple causal methods, I also compare them systematically. I consider eight different weather variables and covid-19-related variables and perform preprocessing and variable selection for instrumental variables, whereas the previous literature focuses on one or two hand-selected variables (see @sec-weatherlit). I use multiple aggregated synthetic controls, allowing for debiasing via hyperparameter optimization, rather than ad-hoc debiasing as suggested by @facurealvesCausalInferenceBrave2022. I compute propensity scores for single protests, rather than just for matching geographic regions as in @wasowAgendaSeedingHow2020. Like @walgraveComplexAgendaSettingPower2012 I use time series data, but I use it with daily resolution and basic trend features, and not just for regression. While previous work has measured the impact of protests on newspaper coverage (see @sec-newslit), I use multiple queries to logically subdivide the article space; this allows me to analyze backfiring effects that have previously only been debated theoretically @harlowNewProtestParadigm2023. Impressive datasets have previously been created via searching and manual annotation [@raleighIntroducingACLEDArmed2010a]. Due to the advancement in transparency laws and natural language processing, I introduce two new types of datasets: one is based on official records by municipalities -- the most similar dataset has been created by the German government itself and is specific to right-wing extremism [@kanolRightWingExtremistMobilization2021]; the other dataset is based on semi-automated protest event detection, where I replicate and apply the approach from @wiedemannGeneralizedApproachProtest2022 on a larger scale.\n\n### Literature review {#sec-lit}\n\n#### Impact of protests on newspaper coverage {#sec-newslit}\n\nWIP: still have to tidy this up.\n\n@walgraveComplexAgendaSettingPower2012 use time-series regression on a substantive set of political variables in Berlgium from 1993 to 2000. They find significant impacts of protests on newspaper attention, as well as a significant impact of newspaper coverage on parliamentary questions, although not on governmental decisions. This gives empirical evidence that media coverage may indeed play an important mediating role.\n\nThe \"protest paradigm\" [@mcleodManufacturePublicOpinion1992] theorizes that news coverage of protesters tends to be a double-edged sword, because the coverage of protests that challenge the status quo is usually negative. This paradigm is recently being challenged, and the formation of amore nuanced theory is underway that considers under what conditions the protest paradigm does or does not hold [see @harlowNewProtestParadigm2023].\n\n@schwartzParadoxConfrontationExperimental2016: protests themselves have a negative impact on public support, but media coverage has a positive impact\n\n@cristanchoProtestersNewsGates2022 investigate experimentally how different features of protests as well as of journalists have an impact on the prominence of the protests in the news (measured by front-page placement), finding that protest size is the most important feature\n\n@hellmeierSpotlightAnalyzingSequential2018 find support for their hypothesis that salient protest events that receive a lot of media coverage lead to a higher coverage of subsequent protest events, and that the effect decreases with spatial and temporal distance.\n\n@barrieDoesProtestInfluence: time series effects on tweets by uk mps, recent and very nice (not strictly causal, but really plausible; or could perhaps consider it a discontinuity design)\n\n@chenHowClimateMovement2023a analyze the coverage of the climate movement on Twitter as well as in online newspapers. They use topic modelling to find major themes in discourse, and plot the quantitative evolution of these themes over time from 2018 to 2021, overlaying it with information about the occurrence of the semi-annual global climate strikes.\n\n@AttentionClimateChange2023 find that the Covid-19 pandemic has led to a fewer discussion of climate protests on Twitter, albeit not to fewer discussion of the climate crisis itself.\n\n@seitzWhoCaresClimate2021 find that certain innate personality traits of German citizens strongly predict the priority given to climate change policy and the support for specific climate policies. They call on future work to investigate the causal pathway and suggest that personal media attention might be an important mediator.\n\n@repkeAttentionClimateChange2023 explore the impact of the covid-19 pandemic on climate discourse on Twitter. They report that in general there is only a temporary negative attention decrease, but that topics related to protest movements have been very strong in 2019 before the pandemic and much less so in 2020 and 2021.\n\n@simonteuneZwischenEmphaseUnd2017 implicitly investigate causal questions about the relation between single protest events and media coverage cycles. They characterize four possible \"ideal types\" of (non)interaction: _Superposition_, where protests tend to happen when coverage increases; _trigger_, where the protest causes the coverage to rise; _show-down_, where the protest approximately marks the tip of a period of heightened media attention, suggesting a more complex causal picture; and _reminder_, where continuously repeated protests serve to keep the topic on the newspaper agenda, but each single event has only a small impact. They use case studies for protest events relating to various topics in Germany to assess the theory.\n\n#### Causal approaches to protest event analysis {#sec-lit-causal}\n\nIn the context of protest event analysis, the most commonly used methods are: _regression_ with an extensive set of control variables; the _instrumental variable_ method, mostly using rainfall or precipitation as an instrument; and _difference in differences_.\n\n__Regression.__ The traditional standard method in protest impact research is linear regression. @walgraveComplexAgendaSettingPower2012 conduct an elaborate regression study themselves, and they also give a clear review of related regression studies on protest impacts.\n\n__Instrumental variables.__ This is a very common approach to causal impact estimation. Most related work investigates aggregate impacts from longer timespans (a week or a month), and the causal outcomes are often temporally separate (for example, the outcome of protests on election is estimated, where the election takes place multiple months after the protest period); With the exception of @huet-vaughnQuietRiotCausal2013, all previous literature has a setting where they look at a fixed timeframe and compare effects across regional units. Only @huet-vaughnQuietRiotCausal2013 have a methodical approach that is more similar to mine, looking at a larger dataset where events are scattered across regions and also across time.\n\n- @collinsEconomicAftermath1960s2007 use rainfall and local political structure as instruments to investigate the effect of riot severity on the later development of property values. They use rainfall in the month following the assassination of Martin Luther King, during which many protests occurred across the US, as an instrumental variable.\n\n- @madestamPoliticalProtestsMatter2013 use rainfall as an instrumental variable to measure the effect of Tea Party rallies on votes for the Republican Party in the US. They use rainfall on a single important day of Tea Party rallies across counties in the US to measure the effect of additional protesters on Republican Party vote share half a year later, finding that an additional protester leads to way more additional votes than just a single one. They also measure the effect on newspaper coverage of the Tea Party, and find increased attention especially during later important Tea Party events. They operationalize rainfall as a dummy variable of whether there were at least 0.1 inches (2.5 mm) of rainfall.\n\n- @huet-vaughnQuietRiotCausal2013 investigate the effect of protest violence on protest \"success\" across 15 years of single (potentially multi-day) protest events in France, using precipitation and temperature as instrumental variables. They operationalize precipitation as a dummy variable representing whether there was some precipitation during any day of a series of protest days, and temperature as a dummy variable about whether the maximum temperature during these days falls in the range of 60-75° Fahrenheit (16-24° Celsius), which is derived from studies about the effect of temperature on disorderly conduct. As an additional instrument they use the occurrence of school holidays.\n\n- @negroWhichSideAre2019 are interested in the effect of the size of LGBTQ protests on the presence of \"movement-affiliated organizations\". They use two instrumental variables, the first one measuring whether the precipitation on the protest date exceeds 2.5 mm (as per @madestamPoliticalProtestsMatter2013), and the second one being the average rainfall in the last 10 years on the $\\pm3$-day window around the protest date.^[In my opinion this is a good idea but it should be labeled as a control, not as an instrument. See @sec-meth-data-instr for discussion.] They find the first instrument to have a statistically significant effect on the protest size ($p<0.01$), but not the second one ($p\\geq 0.05$).\n\n- @wasowAgendaSeedingHow2020 use rainfall in the month following the murder of Martin Luther King to estimate the effect of violent protests on the vote share of the Democratic Party in the US in the elections half a year later. They operationalize rainfall as \"average rainfall in millimeters from weather stations within a 50 mile radius of the county center.\" Using two-stage least-squares regression, they find a significant shift in vote share in predominantly white counties due to protests in the first week after the assassination. They also apply placebo tests using rainfall from the week before the assassination, and from the remainder of the month after the assassination (containing only 5% of the protests from that month), and do not find significant effects for either of them, which strengthens their result.\n\n- @kleinteeselinkWeatherProtestEffect2021 use rainfall as an instrument to determine the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They use rainfall from the two weeks following the murder of George Floyd by the police to measure the effect of the per-county number of total protest attendees during this time window on the election half a year later. (A very similar setting as above.) They use a linear variable to operationalize rainfall. They use the \"probability of rain\" to control for \"general climatic conditions that may correlate with voting-relevant characteristics such as the average age, income, and ethnic composition of a county.\" The operationalization and motivation for this are a bit unclear.^[I find it plausible that the rain forecast may be relevant because the organizers may decide already a few days in advance of the protest whether or not it should take place, and for this decision they cannot rely on the actual weather but merely on the forecast.] Moreover they stress the importance of taking spatial depencies into account, and solve the problem using a spatial weighting matrix. They use demographic control variables (racial composition and median age) as well as economic control variables (median income and unemployment rate) for all regression steps. Placebo tests for first-stage linear regression show that the coefficients for the effect of weather on protest attendance is much lower for time windows before the protests took place, but still highly statistically significant.\n\n- @carenBlackLivesMatter2023 use multiple weather variables, also to estimate the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They operationalize days with _bad weather_ as days with either a maximum temperature above 90° Fahrenheit (32° Celsius), more than 0.1 inches (2.5 mm) of precipitation, or a wind speed of more than 10 mph (16 km/h). As their instrument they use the number of days with bad weather during the month that followed the murder of George Floyd by the police. Their treatment is _protest intensity_, which they define as the inverse hyperbolic sine (which behaves similarly to the logarithm) of the cumulative protest size, divided by the population size of the county. They use a large list of sociodemographic and political variables on the county level as control variables for all regression steps.\n\n- Other literature uses instruments that are less clearly random, such as whether the protest took place on a Friday [@butcherFridayMyMind2022], its distance to focal points[@ketchleyUnpopularProtestMass2021], or the commute time in the city where the protest takes place [@carenBlackLivesMatter2023].\n<!-- or even sociological variables concerning the political structure and efficiency.  -->\nArguing that such instruments are valid requires solid expert knowledge (and perhaps insider knowledge), and such instruments are therefore less suitable for a data-driven analysis as I envision it here. (Even the weather variable is not completely free from such problems, unfortunately, as is discussed in the next section.)\n\n__Synthetic control.__ The synthetic control method has not seen much use for protest impact estimation. @tianSyntheticControlMethod2023 estimate the impact of the Hong Kong 2019 protests on the national economy. They construct a control from 48 other national economies that is fitted from 2011 to 2018, and evaluate the cumulative impact in 2019, when the protests took place. For this purpose, they extend the method for nonlinear synthetic controls.\n\n__Propensity scores.__ @wasowAgendaSeedingHow2020 substantially leverage causal inference techniques for protest impact estimation: They use instrumental variables, as well as propensity matching and inverse propensity weighting with covariate-balanced propensity scores (CBPS) from logistic regression. The treatment units are counties, and the effect of the occurrence of a protest in April 1968 (after the assassination of Martin Luther King) on democratic vote share is estimated. Using simulations, they conclude that the protests likely tipped the presidential election in November 1986. More details on the instrumental variable approach in this paper are in the instrumental variable review below.\n\n__Other methods.__ Besides the methods mentioned above, the _difference in difference_ method is notable. @enosCanViolentProtest2019 study the impact of the 1992 Los Angeles riots after the beating of Rodney King by the police. Their outcome variable is support for public school spending, and they measure the change between voting in referendums in 1990 and 1992, and \"difference out\" the analogous change in higher education spending in order to remove confounding bias. They verify results by checking that individuals with a high predicted voting change reside geographically close to the center of the riot.\n\n### Causal impact estimation {#intro-causal}\n\nCausality [@humeEnquiryConcerningHuman2008; @spohnStochasticIndependenceCausal1980; @spirtesCausationPredictionSearch1993; @pearlCausalityModelsReasoning2000; @imbensCausalInferenceStatistics2015]\n\nTODO: I'll go over this again, tidy it up and make it a bit more precise. And add citations for the methods and references to @sec-app2 with the formulas.\n\n<!-- Causality[^invented by Spohn xxxx] -->\n\nHere I give an overview of the causal model that I generally assume. Then I give an overview of the different causal methods used in this project, how they exploit the causal model, and what additional assumptions they make.\n\n<!-- Since _time series methods_ may be used in various contexts, I also briefly introduce their structure and show how they can be applied to various machine learning problems that arise as part of the causal methods. -->\n\n\n```{dot}\n// | label: fig-causal-graph-simple\n// | fig-cap: Simple causal graph showing the structure of the research problem, ignoring the time-series aspect. I want to determine the effect of the treatment __W__ on the outcome __Y__, and there are known confounders __X__, but also unknown confounders __U__ that influence both treatment and outcome and thus complicate the matter. Instrumental variables __Z__ may help, because they only affect the outcome via their effect on the treatment.\n// | fig-width: 180px\n// | fig-height: 120px\n// | column: body\n// | fig-pos: 'H'\ndigraph D {\n  rankdir=LR\n  {X, U} -> {W, Y}\n  {Z} -> {W}\n  {W} -> {Y} [color=green]\n}\n```\n\n\nTODO: fix figure number\n\n@fig-causal-graph-simple shows a typical causal situation: The impact of the treatment __W__ on the outcome __Y__ is of interest. Both treatment and outcome are also affected by known confounders __X__ and unknown confounders __U__. Instruments __Z__ affect the treatment, but do not have a direct impact on the outcome.\n\nThe core of the model is the relation $W \\rightarrow Y$ that I want to investigate. However, there are multiple problems of increasing difficulty:\n\n1. The outcome __Y__ is affected not only by the treatment but also by the covariates __X__. This is a common situation, even in experiments that are randomized, and we can approach it, for example, by using regression to control for the covariates.\n2. Not only the outcome __Y__, but also the treatment __W__ is affected by the covariates __X__, which makes them _confounders_. This is a common feature of observational studies. We can use methods based on the _propensity score_ (the probability of receiving the treatment) to approach this problem, as long as we know all relevant confounders.\n3. There are likely unknown confounders __U__. We are dealing with a sociological situation where a lot of variables could potentially be relevant. For example, external events like elections, legislative processes, or conferences could play a big role. Or the current mindset and stress level of journalists could play a role. Or many other things, that we may not even think of. Even though we cannot list all of these variables, there are alternative approaches:\n   1. Assuming that the unknown confounders affect all regions similarly, we can make cross-region comparisons, for example, by using the __*synthetic control*__ method.\n   2. We can leverage __*instrumental variables*__ __Z__, for which we assume that they do not affect the outcome __Y__ directly, and trace their effect on __Y__ via the treatment __W__.\n   3. We can assume that certain texts such as press releases may cover many relevant unknown confounders, and learn __*propensity scores from texts*__, without needing to specify the confounders explicitly.\n\nAll three methods can be combined with controlling for known confounders. The following table gives an overview over the methods, which causal inference principles they use, what data they rely on, and whether they are useful for dealing with know and unknown confounders:\n\n:::{.column-body}\n\n\\begin{tabular}{l| c c c c}\n& Regression & Instr. var. & Synth. contr. & Prop. score \\\\\n\\hline\nInstrumenting & & \\bullet &  &  \\\\\nControlling & \\bullet & (\\bullet) & (\\bullet) & (\\bullet) \\\\\nBalancing &  &  & \\bullet & \\bullet \\\\\n\\hline\nTime series & \\bullet & (\\bullet) & (\\bullet) & \\bullet \\\\\nRegions &  &  & \\bullet &  \\\\\nWeather &  & \\bullet &  &  \\\\\nTexts &  &  &  & (\\bullet) \\\\\n\\hline\nConfounders? & $\\checkmark^1$ & $\\checkmark^2$ & $\\checkmark^3$ & $\\checkmark^4$ \\\\\nHidden conf.? &  & $\\checkmark^2$ & $\\checkmark^3$ & $\\checkmark^{4,5}$ \\\\\n\\end{tabular}\n\nCore assumptions:$^1$ Linearity;$^2$ Valid instrument;$^3$ No regional confounding;$^4$ Overlap;$^5$ Hidden confounding is captured by text.\n\n:::\n\nHere I give a conceptual overview of the 3 mentioned methods that are potentially suitable for dealing with unknown confounders. Mathematical assumptions and definitions are given in @sec-app2.\n\n\n```{dot}\n// | label: fig-causal-graph-corr\n// | fig-cap: Causal graph for naive analysis.\n// | fig-width: 100px\n// | fig-height: 100px\n// | column: margin\ndigraph D {\n  {W, X} -> {Y} [color=blue]\n}\n```\n\n\n__Correlation.__ Naive regression is not a causal method, but is used for comparison with the causal methods. It neglects most of the causal model and only regards the direct relationship between treatment and outcome, possibly controlling for covariates, but neglecting their role as confounders. The result is known as the _prima facie_ causal effect. It suffers from _selection bias_, because the model does not take the treatment assignment process into account -- but it should, because the treatment is not randomized.\n\n\n```{dot}\n// | label: fig-causal-graph-reg\n// | fig-cap: Causal graph for regression.\n// | fig-width: 100px\n// | fig-height: 100px\n// | column: margin\ndigraph D {\n  {W, X} -> {Y} [color=blue]\n}\n```\n\n\n__Regression.__ Controlling for the known confounders can already help to substantially reduce the bias, especially if the relationships are linear, and may as well be considered a causal method.\n\n\n```{dot}\n// | label: fig-causal-graph-iv\n// | fig-cap: Causal graph for the instrumental variable method.\n// | fig-width: 150px\n// | fig-height: 150px\n// | column: margin\ndigraph D {\n  {W} -> {Y}\n  {Z} -> {W} [color=blue]\n  {X} -> {W, Y}\n}\n```\n\n\n__Instrumental variables.__ The _instrumental variable_ approach leverages _natural experiments_, where a random variable (or an almost random variable) influences the treatment. The _exclusion restriction_ (see @sec-app2-iv) assumes that the instrument does not have a direct impact on the outcome, but only via the treatment. We can then trace how the instrument affects the outcome via the treatment, and thereby establish the causal impact of the treatment on the outcome.\n\n... This is especially true for approximately random variables, such as the weather. (The weather is not purely random but also contains regional and seasonal components; but we can try to isolate them or work around the problem.)\n\nIn the simplest case, we can compare the effect of __Z__ on __W__ with the effect of __Z__ on __Y__ to obtain the desired estimate for the effect of __W__ on __Y__. We can also apply _two-stage_ approaches to first isolate the part of __W__ that is caused by __Z__, and then estimate its impact on __Y__.\n\nThanks to instrumental variables, we can legitimately ignore the unknown confounders. A requirement is always that the instrument is valid and sufficiently strong, that is, that it has a strong effect on the treatment __W__.\n\n\n```{dot}\n// | label: fig-causal-graph-synth\n// | fig-cap: Causal graph for the synthetic control method.\n// | fig-width: 180px\n// | fig-height: 220px\n// | column: margin\ndigraph D {\n  {X, U} -> {W} -> {Y}\n  {X, U} -> {Y}\n  {region} -> {U} [style=dotted, color=blue, label=\"determine\"]\n  {date} -> {U} [style=dotted, color=blue]\n}\n```\n\n\n__Synthetic control.__ The synthetic control method [@abadieSyntheticControlMethods2010; @cunninghamCausalInferenceMixtape2021, ch. 10] leverages the idea of comparing a region where a protest happens with other regions where no protest happens on the same day. However it goes beyond a simple comparison. Instead it constructs a _synthetic region_ from all the control regions that is as close as possible to the treatment region. The synthetic region can then be used to model the counterfactual of no protest for the treatment region.\n\nThe underlying assumption for the synthetic control method is that the unknown confounders affect the different regions uniformly: On any given day, the impact of the confounders is the same for all regions. This assumption is plausible especially for confounders coming from global and national politics and events; it is violated by regional confounders, but maybe they are not so important and we can live with it.\n\nUnder this assumption, we can perform matching based on the date: To estimate the impact of a protest group in one region on a given date, we find other regions where no such event has taken place, and compare the effect.\n\nThe synthetic control method goes a bit further and also takes the effect of known differences between the regions into account. From all the available control regions, it constructs a _synthetic region_. The synthetic region interpolates between the control regions such that the interpolated region is as close as possible to the treatment region in some respect. This interpolation can be performed in terms of sociodemographic similarity, or in terms of maximizing the predictive accuracy of the outcome variable, based on past observations. (This is a bit of a simplification, the details are explained in @sec-synth.)\n\n\n```{dot}\n// | label: fig-causal-graph-prop\n// | fig-cap: Causal graph for propensity score methods.\n// | fig-width: 100px\n// | fig-height: 150px\n// | column: margin\ndigraph D {\n  {W} -> {Y}\n  {X} -> {W} [color=blue]\n  {X} -> {Y}\n}\n```\n\n\n__Propensity scores.__ Propensity score methods help to remove the impact of _known_ confounders. They rely on the propensity score that specifies how likely it is that a protest occurs on a given date and in a given region. They can be computed from knowledge about the region and the date, and from lagged treatment and outcome data from the previous days. To account to some extent for the impact of _unknown_ confounders, I also obtain propensity scores from press releases about climate-related events.\n\nPropensity score methods estimate the probability (propensity) of receiving the treatment. There are various strategies for eliminating selection bias with the use of propensity scores: notably propensity score matching, propensity score stratification, inverse propensity weighting. Double machine learning estimators such as causal forests help with estimating heterogenous treatment effects.\n\nPropensity score methods still suffer from _omitted variable bias_ if there are unknown confounders. This can be mitigated by learning propensity scores from less structured big data such as texts, using classification models from natural language processing. The advantage of doing so is that the unknown confounders need not be pre-specified. The assumption is that the texts need to contain all of the unknown confounders, and in some detectable form. While this will never completely be the case (and cannot be verified anyway), I can hope that it at least substantially reduces the bias.\n\n__Time-series modelling.__ The variables on one day may also be influenced by the same set of variables from the previous day. On the one hand, this makes modeling more complicated. On the other hand, it is an advantage, because we have the data from the previous days already in the dataset, and using them can help reduce the amount of unknown confounding. Specifically, I consider all variables from the previous day as potential confounders for the current day. Variables from multiple days earlier may still be relevant, but less so, so it will be acceptable to make a cutoff at some point. We can restrict the previous variables to those from the same region, or we can also include previous variables from other regions where it seems useful. ...\n\n\n```{dot}\n// | label: fig-causal-graph-time-series\n// | fig-cap: TODO fix the graph! Version of the causal graph (@fig-causal-graph-simple) from a time series perspective. The variables of each day are influenced by the variables from the previous days in the same region. We can model that by including all variables from one day as potential confounders for the following day.\n// | fig-width: 200px\n// | fig-height: 400px\n// | column: margin\n\ndigraph D {\n  rankdir=LR\n  compound=true\n\n  U0 [label=\"U\"]\n  W0 [label=\"W\"]\n  X0 [label=\"X\"]\n  Y0 [label=\"Y\"]\n  Z0 [label=\"Z\"]\n\n  U1 [label=\"U\"]\n  W1 [label=\"W\"]\n  X1 [label=\"X\"]\n  Y1 [label=\"Y\"]\n  Z1 [label=\"Z\"]\n\n  U2 [label=\"U\"]\n  W2 [label=\"W\"]\n  X2 [label=\"X\"]\n  Y2 [label=\"Y\"]\n  Z2 [label=\"Z\"]\n\n  subgraph cluster_0 {\n    label=\"Day -2\"\n    {X0, U0} -> {W0} -> {Y0}\n    {X0, U0} -> {Y0}\n    {Z0} -> {W0}\n    dummy_0 [shape=point style=invis constraint=false]\n  }\n  subgraph cluster_1 {\n    label=\"Day -1\"\n    {X1, U1} -> {W1} -> {Y1}\n    {X1, U1} -> {Y1}\n    {Z1} -> {W1}\n    dummy_1 [shape=point style=invis constraint=false]\n  }\n  subgraph cluster_2 {\n    label=\"Day 0\"\n    {X2, U2} -> {W2} -> {Y2}\n    {X2, U2} -> {Y2}\n    {Z2} -> {W2}\n    dummy_2 [shape=point style=invis constraint=false]\n  }\n  dummy_0 -> X1 [ltail=cluster_0 style=dotted label=\"include\\nvariables\" constraint=false]\n  dummy_1 -> X2 [ltail=cluster_1 style=dotted label=\"include\\nvariables\" constraint=False]\n}\n```\n\n\n\n### Case study\n\n__Greenpeace (GP), Ende Gelände (EG), Extinction Rebellion (XR).__ The climate protest movement in Germany has only stepped into existence toward the end of the 2010's. Before then, climate activism was mostly associated with established environmental NGOs such as Greenpeace, which did not play a major role in the media. In 2015 the activist formation _Ende Gelände_ (EG) was established, and began organizing occupations, blockades, and demonstrations directly in coal mining areas [@EndeGelaende2023]. In late 2018 _Extinction Rebellion_ (XR) was established in Germany to protest the biodiversity crisis that comes along with the climate crisis, through demonstrations as well as blockades [@ExtinctionRebellion2023].\n\n__Fridays for Future (FFF).__ Around the same time, the global _Fridays for Future_ (FFF) movement gained traction in Germany, accumulating a huge momentum -- more than a million protesters --, especially among high school and university students, and later also among other social groups with sub-movements such as _Scientists for Future_, _Parents for Future_, and _Grandparents for Future_ [@FridaysFuture2023]. They emphasize constructive discourse and inclusivity, organize exclusively pre-registered demonstrations, and often collaborate with other protest groups. However, they mostly protest on Fridays, that is, during school time, which has caused outrage from conservative politicians and media. As part of this outrage, the argument was first raised that the protests may run counter to their goals by stirring discussions about the appropriateness of their methods, and thereby divert attention from climate policy issues themselves.^[Supporters of the movement may claim that the argument is hypocritical and is mostly used by persons who are actually opposed to climate policy.]\n\n__Letzte Generation (ALG) and controversy.__ A contrary (or complimentary) strategy is taken by _Letzte Generation_ (originally _Aufstand der Letzten Generation_, ALG), which was founded by the participants of a hunger strike during the pre-election phase in 2021 [@LetzteGeneration2023]. Since 2021 the group -- consisting only of dozens or hundreds of members -- employs highly disruptive tactics: most prominently unregistered sit-ins on car highways, as well as supplementary action forms including throwing soup at paintings (which are protected by glass sheets), turning off oil pipelines, or vandalizing symbols of climate-afflicting luxury. The group has concrete demands including a citizen's assembly on climate policy, a ban on food waste, a speed limit for cars, and heavily subsidized public transport tickets. The protesters face a vast backlash, are criticized by politicians from across the poltical spectrum as well as by many media formats, and are pursued under terrorism laws by public prosecutors (who in Germany report to the regional governments); at the same time they have successfully negotiated with multiple mayors to support their concern, have held talks with the chancellor and the minister for traffic, and have been endorsed by the UN general secretary and by some religious organizations. Again, and this time perhaps with even more plausibility, the argument has been raised that the caused disruption runs counter to the goals of the group by diverting attention from climate change policy issues themselves, and by annoying the public.^[A version of this argument is presented by @jansteckelKlimaprotestAufAbwegen2022, and not without [controversy](https://twitter.com/jan_c_steckel/status/1601048858129477632).]\n\n__Related work on the German climate movement.__ @moreincommonWieSchautDeutsche2023 is a survey on support for the German climate protest movement in 2021 and 2023. Over this period they find a roughly 50% decline in support across the sociopolitical spectrum, which is accompanied by widespread disapproval of street blockades (mostly associated with ALG). @gonzattiAnalyseberichtZurStudie2023 use an \"experimental\" setting where participants are told about a fictitious climate protest in Germany, and also find low approval for street blockades and soup throwing, but do not find a positive or negative impact on support for climate policy for any protest form.\n\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nResearch methods and justification:\nExcellent description of data or methods, excellent methodological understanding, research is reproducible.\n\n -->\n\n## Methods\n\n### Data sources and preprocessing {#sec-data}\n\nAll data is retrieved for the timespan from 2020 to 2022. This is because the _ACLED_ data is not available earlier, and the _DeReKo_ data is only released yearly with some delay, and not yet available for 2023 at the time of writing. All data sources are expected to be available for the next years, with the exception of data related to the COVID-19 pandemic.\n\n\n\n#### Protest events {#sec-acled}\n\nThere are generally two source types for protest events:\n\n1. __Newspaper articles__ are primarily used in the existing literature. [@hutterProtestEventAnalysis2014] give a historical and systematic overview and highlight the problem that this source is biased. They describe how several definitions for protest event analysis (PEA) and the broader political claim analysis (PCA), as well as associated coding practices have helped to formalize the (manual) data extraction process, such that results have become more valid and comparable.\n\n2. __Police archives.__ The literature dismisses this source type as \"biased\", uninformative about the motives and organizers, uncomparable across regions, often unavailable or unobtainable, and because it is restricted to only registered demonstrations (Hutter 2014; @ProtestlandschaftDeutschland; @wiedemannGeneralizedApproachProtest2022). This criticism appears to me valid but overgeneralized, and there may well be regions where the advantages prevail over the problems. Especially for the goal of impact estimation, the avoidance of selection biases that are associated with newspaper articles [Hutter 2014; @jamesozdenLiteratureReviewProtest2022] is a strong argument for using data from police and demonstration authorities.\n\n::: {.cell .column-page execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![History of the number of protest events in Germany per week.](report_files/figure-pdf/fig-protest-history-output-1.svg){#fig-protest-history}\n:::\n:::\n\n\n__ACLED.__ My main data source for protest events is the [_Armed Conflict Location and Event Dataset_](https://acleddata.com/) (ACLED; @raleighIntroducingACLEDArmed2010a). ACLED is a grand effort that keeps track not only of violent conflicts and riots, but also of ordinary protest events. The data is human-curated based on newspaper reports, and contains coded information on dates, locations, actor groups, police interventions, and more, as well as a short free-text summary for each event, containing an estimate of the size as per the newspaper data source. Data for Germany is available starting from 2020 and is continuously updated. For the period from 2020-2022, it contains 13235 protest events, 1314 of which are organized by climate protest groups or mention the climate in their description.\n\n<!-- For the period from 2020-2022, it contains `{python} len(protests.query(\"source == 'acled'\"))` protest events, `{python} len(climate_protests.query(\"source == 'acled'\"))` of which are organized by climate protest groups or mention the climate in their description. -->\n\n__Other existing protest datasets.__ Alternative existing sources of German or international protest data comprise [ProDat](https://www.wzb.eu/de/forschung/beendete-forschungsprogramme/zivilgesellschaft-und-politische-mobilisierung/projekte/prodat-dokumentation-und-analyse-von-protestereignissen-in-der-bundesrepublik)^[See also [Protestlandschaft Deutschland](https://protestdata.eu/methods). for additional data and interactive visualizations], [PolDem](https://poldem.eui.eu/download/protest-events/), the [Mass Mobilization Project](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HTTWYL), and the event database [GDELT](https://www.gdeltproject.org/). They do not cover recent years or are not very complete, and therefore inferior to ACLED for my purposes.\n\n#### The German Protest Registrations dataset\n\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-protest-groups .cell .column-margin tbl-cap='Number of protest events 2020-2022 by protest group in the different data sources.' execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=3}\n|                        |   ACLED |   GPReg |   gprep | GPRep   |\n|:-----------------------|--------:|--------:|--------:|:--------|\n| Ende Gelände           |      46 |       1 |      26 | ?       |\n| Extinction Rebellion   |     171 |      89 |      90 | ?       |\n| Fridays for Future     |     801 |    1078 |     551 | ?       |\n| Fridays for Future + X |      81 |       3 |      22 | ?       |\n| Greenpeace             |      74 |     103 |      42 | ?       |\n| Letzte Generation      |     145 |      26 |      22 | ?       |\n| Other                  |     225 |    1626 |     366 | ?       |\n:::\n:::\n\n\n\\endgroup\n\nProtest statistics are often recorded by public authorities, either when organizers register a future demonstrations, or when the police reports about a past demonstration. Registering a demonstration is a common requirement for exercising the right to protest in European countries, however this requirement is only fulfilled by moderate protests, while more radical protests may purposefully ignore it and are thus not listed in such records. Often the estimated number of expected protesters is also recorded, but it is of course not reliable, and reliability may vary between different protest organizers. Police estimates of past demonstrations should be more reliable and consistent, however with the possibility for systematic bias, such as generally downplaying the number of participants, or specifically downplaying the number of participants for protests that are critical of the government or the police themselves.\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-protest-most-common .cell .column-margin tbl-cap='Number of protest events for the five most busy climate protest days 2020-2022; they are concentrated around the spring and autumn equinoxes. (More esoteric future work might explore the astrological determinants of protest activity.)' execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n|            |   ACLED |   GPReg |   gprep | GPRep   |\n|:-----------|--------:|--------:|--------:|:--------|\n| 2020-09-25 |      97 |      17 |      38 | ?       |\n| 2021-03-19 |      65 |      40 |      18 | ?       |\n| 2021-09-24 |     105 |      35 |       0 | ?       |\n| 2022-03-25 |      59 |      21 |       0 | ?       |\n| 2022-09-23 |      30 |      25 |       1 | ?       |\n:::\n:::\n\n\n\\endgroup\n\nOfficial documents, including protest statistics, can be obtained via _Freedom of Information_ laws. These exist in more than 100 countries and allow anyone to obtain public documents [@FreedomInformationLaws2023]. The specific requirements, exceptions, and costs vary greatly. In Germany, freedom of information exists on the federal level; but many authorities belong to the regional level, where the extent of freedom of information rights varies greatly [@InformationsfreiheitDeutschlandTransparenzranking]; and municipal authorities are not always covered by regional freedom of information laws, sometimes filling the gap with their own legislation.\n\nAccess to public documents has been democratized via platforms that streamline the process of sending requests, escalating the process to oversight authorities or courts if necessary, and making communication and obtained documents available to the public. The [Alaveteli](http://alaveteli.org/) network provides software and hosts such platforms in more than 30 countries across the world. Some independent platforms also exist, such as [Öffentlichkeitsgestz.ch](https://www.oeffentlichkeitsgesetz.ch/) in Switzerland, and _FragDenStaat_ [in Austria](https://fragdenstaat.at/) and [in Germany](https://fragdenstaat.de/). These open the possibility of obtaining official protest data at scale.\n\n__Collection.__ I send 40 freedom of information requests to German demonstration authorities (depending on the region these are either part of the municipal administrations or of the police) and their supervisory bodies concerning protest data in 31 cities. These cities comprise the political capitals of all 16 regions in Germany, the 17 largest cities by population size, as well as some smaller cities for regions where the request in the regional capital is unsuccessful. 4 requests are not answered, 3 are rejected, 11 state that they do not possess such data, 2 have to be withdrawn due to demanded payments of multiple hundreds of euros, and 20 are been partially or completely successful. This yields 17 table documents with various amounts of information. The requests and responses including the original data files can be found at [FragDenStaat](https://fragdenstaat.de/anfragen/?q=demonstration+csv&first_after=2022-12-01&first_before=2023-07-31).\n\n__Cleaning.__ I ignore one of the datasets (Augsburg) because I cannot convert the delivered PDF back to a table, two of them (Saarbrücken and Freiburg) because the data is too unstructured or requires too much cleaning, and one (Duisburg) because the data is delivered very late. The remaining 13 data tables are cleaned manually. One common problem is that the tables specify events that have a duration of multiple days, in some cases even multiple months. Out of concern for a simple data structure, as well as doubt whether these demonstrations really lasted so long, I reduce their duration to the single day when they start.\n\n__Dataset__. The resulting dataset contains 49,800 events from 13 cities. For 11 cities the ex-ante number of expected participants are given, and for 2 of them (Berlin and Magdeburg) the ex-post extimates by the police are also included. For all cities the topic of the protest is given in, presumably as specified by the organizers themselves; and for 4 cities the name of the organizing group is also known. Various additional details such as exact specifications of location, time and duration, and distinctions between protest marches and pickets are available for some of the cities but not in any systematic manner. Further statistics about the dataset can be seen in table tbl-official-overview.\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/report.qmd|:../src/data/protests/german_protest_registrations/data_map.ipynb#data-official-map |  | echo:false,warning:false,asis:true,eval:false -->\n\n\n#### The German Protest Reports dataset\n\n@wiedemannGeneralizedApproachProtest2022 show how to detect protest events in newspaper articles. They employ the [`gelectra-large`](https://huggingface.co/deepset/gelectra-large) model, a transformer model that is fine-tuned on German texts of various genres. Their dataset consists of almost 4000 newspaper articles from 4 German cities, namely Leipzig, Dresden, Stuttgart, and Bremen, from between 2009 and 2016.\n\n__Replication and experiments:__ I replicate their results and obtain F1-scores of 0.93 for in-distribution and 0.76 for out-of-distribution classification, which is almost identical to the authors' results. I try out some alternative approaches on their data: Simple machine learning models based on TFIDF-features; finetuning the more recent multilingual FlanT5 model; and using GPT 3.0 in a zero-shot setting. None of the alternatives perform closely to the `gelectra-large` model (see @tbl-glpn-alternative-methods for metrics).\n\n\\begingroup\n\\small\\selectfont\n\n| Model    | id F1 | ood F1 |\n|----------|------:|-------:|\n| XG-Boost | 0.87  | 0.60   |\n| FlanT5   | 0.75  | 0.30   |\n| GPT3     | 0.81  | 0.65   |\n| gElectra | 0.93  | 0.76   |\n\n: Results for using alternative classification methods on the GLPN dataset, for in-distribution (id) and out-of-distribution (ood) prediction. {#tbl-glpn-alternative-methods .column-margin}\n\n\\endgroup\n\nIn order to obtain protest events from a broader geographic spectrum, I retrieve metadata of online newspaper articles from MediaCloud (see @sec-data-discourse) for a query containing protest-related keywords.^[The query is based on the query used by Wiedemann, and reads: _'protest* OR demo OR demonstr* OR kundgebung OR versamm* OR \"soziale bewegung\" OR hausbesetz* OR streik* OR unterschriften* OR petition OR hasskriminalität OR unruhen OR aufruhr OR aufstand OR rebell* OR blockade OR blockier* OR sitzblock* OR boykott* OR riot OR aktivis* OR bürgerinitiative OR bürgerbegehren OR marsch OR aufmarsch OR parade OR mahnwache OR hungerstreik OR \"ziviler ungehorsam\"'_] From the obtained metadata, I scrape full-texts where possible. Special care is taken of websites that appear scrapeable but contain only gibberish because the actual content is paywalled: The letters on these websites appear not to be shuffled but transformed by some other processing methods, so the frequency of common characters is very different on these websites than in actual texts, and the websites can be detected and ignored. Note that this dataset starts already in 2019 and has very little data for the end of 2021 and for all of 2022 due to issues with my scraping implementation. Future work may consider the use of commercial scraping tools to simplify this step.\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/report.qmd|:../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-ts |  | echo:false,warning:false,asis:true,eval:false -->\n\nI label the texts myself using [Prodigy](https://prodi.gy/). For the positive class, I require that the article is a report about (potentially among other topics) a recent past protest event, and that basic details including the place and the protest concern are given. The other articles are mostly about completely different topics (such as \"protest\" but not in the political sense, or \"demonstration\" in the sense of showing something, \"blockade\" in a physical context, or the \"protest-ant\" church); or they mention protests in the context of an op-ed or an interview, where the concreteness and recency of the events is often not given.\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/report.qmd|:../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-sources |  | echo:false,warning:false,asis:true,eval:false -->\n\nIn a first labeling phase, I annotate 650 random articles for training and 500 random articles for evaluation. I train the model and use 500 articles that are predicted positive and label them as well and add them to the training data, in order to combat class imbalance. Training the `gelectra-large` model with the overall 1150 training samples and according to the hyperparameters suggested by Wiedemann, I finally obtain an in-distribution F1-score of 0.78 (precision=0.81, recall=0.75). Then, I use this model to predict the relevance of all the other scraped articles that contain protest-related keywords. Only 11% are relevant, resulting in 20,879 articles of which the (relatively good) model believes that they describe protest events.\n\nFor the current study I filter the set of relevant articles for thos that contain \"Klima\" in their full text. For entity extraction of dates and places I use the GPT3.5 large language model (a finetuned version of @brownLanguageModelsAre2020); I do not perform an evaluation of this step. Places are matched to regions by using OpenStreetMap's [Nominatim](https://nominatim.org/) service. This yields 1401 climate protest events, and for 1353 of them both the date and the region can be extracted.\n\n#### Newspaper coverage {#sec-data-discourse}\n\n::: {.cell .column-page execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Number of daily online newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display. The effects of an outage of the collection system in January 2022 are visible.](report_files/figure-pdf/fig-mediacloud-history-output-1.svg){#fig-mediacloud-history}\n:::\n:::\n\n\n__Online newspapers.__ [Media Cloud](https://www.mediacloud.org/) is an open data platform that continuously crawls newspaper websites around the world and stores article metadata and word counts in a database. Full texts are in principle available by following the links and scraping the websites oneself, but this is very slow and often hampered by anti-scraping measures of the websites. I use the [`api/v2/stories_public/count`](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#apiv2stories_publiccount) endpoint of their API. I query for tags from the [regional and national collections about Germany](https://search.mediacloud.org/collections/news/geographic). Baden-Württemberg and Mecklenburg-Vorpommern are missing from the collection. There has been a (partial) outage in January 2022 resulting in (near-)zero counts for that timespan. I do not exclude this timespan because it would be complicated and error-prone with respect to time-series analysis. This may lead to an under-estimation of eventual causal effect sizes of up to $\\frac{1}{36}\\approx 0.028$, but I do not expect it to influence my results in any other systematic way.\n\n::: {.cell .column-page execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Number of daily print newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display.](report_files/figure-pdf/fig-dereko-history-output-1.svg){#fig-dereko-history}\n:::\n:::\n\n\n__Print newspapers.__ The [German reference corpus](https://www.ids-mannheim.de/digspra/kl/projekte/korpora/) (_Deutsches Referenzkorpus_, DeReKo) archives the full texts of most German-language print newspapers and magazines in an online database for the purpose of linguistic research. An API contains access to a selected corpus, and by (automatically) navigating the user interface, an extended corpus can be searched. The content is renewed on an annual basis and with a delay of a few months, so no data for 2023 is available. Full texts cannot be retrieved from DeReKo, but large context windows for search results are available, which could be used for more nuanced further research. Here, I only use the functionality of obtaining daily article counts for a given query.\n\nI extract an overview table of all newspapers from the corpora W1-W4, remove newspapers that are not available until 2022, remove newspapers that are about niche topics such as cars, beauty, or history, or that are published with less than weekly frequency. I annotate the remaining 154 newspapers on whether they have a national or regional scope, and retrieve the applicable regions for the regional ones, drawing from information on Wikipedia and the newspaper websites. 121 are from Germany, and 15 of these have a (primarily) national scope, while 106 have a regional scope. All regions are represented with at least one newspaper, except the city state of Bremen. Among the 4 (or more) German \"newspapers of record\" [see @NewspaperRecord2023], the conservative _Frankfurter Allgemeine Zeitung_ is missing, and the very popular tabloid _Bild_ is also missing. I retrieve daily article counts for all queries and all thus filtered newspapers, and aggregate them by day on the regional level as well as into a category of national newspapers.\n\n__Topic queries.__ I use queries that allow to examine how many mentions of climate change occur in newspaper articles overall, and how this is further subdivided. I formulate 5 sub-queries (the full word lists are found in @sec-app-queries):\n\n- _Topic:_ Whether an article mentions climate change or climate policy.\n- _Protest:_ Whether an article mentions protest activity (including both general terms, and terms and organization names that are specific to the climate movement).\n- _Framing:_ Whether more dramatic words than \"climate change\" are used, such as \"climate crisis\", \"climate catastrophy\", etc.\n- _Goals_: Whether long-term goals of the climate movement such as carbon neutrality are mentioned.\n- _Subsidiary goals:_ Whether more concrete measures such as a speed limit for cars, or a citizen's assembly on climate change are mentioned.\n\nFrom these sub-queries, I use the _topic_ query as a standalone query, and combine each of the other queries with the _topic_ query to make sure that the terms are actually used in the context of climate change. (Many of the terms have an unambiguous relation to climate change anyway, but some, such as the protest forms or specific solutions, could also appear in other contexts.) I retrieve absolute article counts for each query, aggregated daily on the regional or on the national level.\n\nThe queries allow me to study not only research question 2 (how much overall coverage of climate change is affected); but also (to some extent) to investigate research question 3 (whether this does not backfire by focusing the discussion on the protests rather than the policy issues):\n\n- If the article counts for the _topic `and not` protest_^[This query can be derived from the other queries logically.] query remain constant or even increase due to protests, then this is strong evidence that the protests do not backfire; and if it increases, then their effect is very strong such that they cause more discussion even when the protests are not themselves a topic. A decrease of the article count for this query does not tell us much, since it could still be, or not be, that relevant contents are transported as part of he articles that also mention protests.\n\n- The other queries (_topic `and` framing_, _topic `and` goal_, _topic `and` subisidiary goal_) aim to look at topics where it would be a success for the protests if they occur more in public discourse. If their article counts increase due to protests, then backfiring is unlikely (but still possible in other topic niches that I am not querying for); and if they decrease, it is strong evidence that the protests are indeed backfiring. A result where the counts for some of these queries increase, while they decrease for others may indicate more complicated effects of protests that warrant further research.\n\n- The _topic `and` protest_ query can serve as a sanity check: It would be very surprising if protest events did not cause the counts for this query to markedly increase. This is even more true for the _ACLED_ and _GPRep_ datasets, where the events are (manually or automatically) extracted from newspaper articles.\n\n![The queries produce different lenses on the mass of articles about climate change. The left lens has the disadvantage that we do not know how much the articles that also mention the protests contribute to the discourse about the topic. The right lens has the disadvantage that it ignores aspects that we do not explicitly query for.](figures/queries.svg){.column-margin}\n\n__Alternative topic representations.__ The querying approach that I employ for this study is very coarse, and will deliver clear conclusions only in some cases. It would also be very interesting to see how much room is typically given to the discussion of climate policy in an article that also mentions protests. Moreover, one could measure how prominent the various keywords are within each article, and what other words they cooccur with most, and what sentiments they are accompanied by. Another approach would use topic models to create topics in an unsupervised manner, and observe how their prevalence shifts in the face of protests; this has already been done by @chenHowClimateMovement2023a for the climate protest movement. All of these techniques require full-text data. For newspaper articles, full-text data is in principle available, but relatively hard to obtain (see the notes on fulltext availability in the paragraphs on online and print newspaper sources); so I have not used full-texts here, in order to focus more on the causal aspect.\n\n__Alternative soruces of public discourse.__ Future work could also explore Twitter data (@kratzkeMonthlySamplesGerman2023: a sample of full texts from Germany on a daily basis 2019-2022), [Google Trends](https://trends.google.com/) data (search query counts on a weekly and regional basis starting from 2005), or parliamentary speech (@abramiGermanParliamentaryCorpus2022: speeches from regional German parliaments from the nineties until 2021). Twitter data does not come with geographical annotations, and Google Trends and parliamentary speech are not available on a continuous daily basis, so I focus on newspaper articles here.\n\n#### Instruments {#sec-meth-data-instr}\n\n<!-- 12A0366C|/Users/david/Repositories/protest-impact/report/report.qmd|:../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-weather-time-series |  | echo:false,warning:false,asis:true,eval:false -->\n\n__Weather.__ Weather data is obtained via the [Meteostat](https://meteostat.net/en/about) project from _Deutscher Wetterdienst_, containing the 8 variables displayed in @fig-weather-time-series. Related work on causal methods for protest impact analysis typically uses precipitation or rainfall, and in some cases additionally temperature and windspeed as instruments. I consider all available weather variables as potential instruments. Two systematic concerns have been raised about using weather variables as instruments:\n\n1. _Indirect paths._ @mellonRainRainGo2023 find 195 variables that have been linked to the weather in previous studies (ironically, many of them instrumental variable studies themselves), and that these undermine the exclusion criterion for instrumental variables, threatening the validity of the variables. The authors have constructed a comprehensive causal graph depicting the known effects of the weather. It shows that _protests_ as well as _violent protests_ are influenced by rainfall and temperature, and that protests have an influence on repression, voting behaviour, policy, and property values. There is no study confirming an influence of the weather on newspaper reporting, but possible indirect paths may include _mood_ and (for climate protests) _pollution_. Other variables such as _migration_ may also have an effect because attention to them might decrease attention to other topics in the news; however most of this kind of variables are only related to the weather in the long term and not in the short term.\n\n2. _Spatial interdependence._ @coopermanRandomizationInferenceRainfall2017 raise concern about spatial interdependence of rainfall across regions. This applies particularly when the effect of rainfall across regions _on a single date_ is investigated, for example in the context of an election. In my setting I investigate the individual effects of protest events that are spread across multiple years. The amount of protests that take place on the same date is therefore very small, and spatial interdependence of the _weather_ among temporally separated events is very low. Spatial interdependence of the _climate_ (thus also influencing the weather) is still a problem. When removing the climate influence from the weather and only using the (climate-independent) weather as instrumental variables, the spatial interdependence should be mostly removed from the intrumental variables.\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Pandemic restriction variables (1). The figure displays 6 different variables that show how often various place categories are visited.](report_files/figure-pdf/fig-covid-19-time-series-output-1.svg){#fig-covid-19-time-series}\n:::\n:::\n\n\n::: {.cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![Pandemic restriction variables (2). The figure gives the stringency index, an aggregated measure of expert estimates of the severity of restrictions along multiple dimensions.](report_files/figure-pdf/fig-covid-19-time-series-2-output-1.svg){#fig-covid-19-time-series-2}\n:::\n:::\n\n\n__Pandemic restrictions.__ The timespan covered by my dataset coincides with the Covid-19 pandemic, which has had very drastic impacts in 2020 and 2021, and still some in 2022. This may open up the possibility for exploiting a new kind of instrumental variable, because the pandemic comes with both legal restrictions and psychological aversion against large gatherings, including demonstrations. Available data includes the _stringency index_ calculated by the [Oxford Coronavirus Government Response Tracker](https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker) and provided by [Our World in Data](https://ourworldindata.org/covid-stringency-index) [@fig-covid-19-time-series-2]; and _Google Mobility Trends_ data, also provided by [Our World in Data](https://ourworldindata.org/covid-google-mobility-trends) [@fig-covid-19-time-series]. Both datasets are only on the national level for Germany. While the stringency index is rather static, the mobility trends data contains more randomness. The randomness may indirectly be influenced by the weather, which is neither a problem, nor an advantage, since I already use the weather variables directly. Two reasons may threaten the validity of the pandemic variables as an instrument.\n\n1. _Temporal correlation._ Unlike the weather, COVID-19 restrictions are temporally correlated over longer timespans, that is, they change more slowly. This introduces some chance that they may be accidentally or systematically correlated with political processes and with media attention cycles.\n2. _Direct media impact._ There is a potential direct impact of COVID-19 on media coverage: Stricter restrictions may correlate with a more intense media focus on the pandemic, decreasing attention on any other topic. Controlling for coverage levels before the protests can decrease this problem.\n\n### Data aggregation {#sec-agg}\n\nThe data is aggregated by region and date. For every day and region there is a row that contains information about all causal variables. In causal terms, days are the _treatment units_, and the treatment is whether or not a protest (by a certain group) takes place on a given day in a given region. Summarizing and categorizing the variables that are described in detail in the above sections, we have:\n\n- Treatment __W__:\n  - For each protest group, a dummy variable whether it organizes at least one protest event in the given region (that is, a _binary_ treatment).^[Alternatively, I could use for each protest group the number of protesters in the given region as a _continuous_ treatment; but this requires (a) slightly more complicated methods to deal with continuous treatments, and (b) difficult assumptions about scaling -- does the number of participants have a linear impact, or a logistic one, or is it more complicated?]\n- Outcome __Y__:\n  - Number of newspaper articles published that mention the climate crisis, across 5 dimensions (see @sec-data-discourse): overall mentions; mentioning protest activity; mentioning long-term goals; mentioning specific short-term goals; using a drastic or catastrophic framing. I also use multiple impact timespans, see below.\n- Instruments __Z__:\n  - Weather: min/max/avg temperature, air pressure, precipitation, snowfall, wind speed, and peak gust\n  - Covid restrictions: stringency index of the restrictions, and movement variables for 6 location types\n- Known confounders __X__:\n  - Day of the week, as dummy variables\n  - Holiday occurrence in the given region\n  - Region dummies\n  - Time-series lags of all variables (with variable number of lags, subject to hyperparameter optimization)\n  - Exponential moving averages of $W$ to account for the long-term impact of previous protests (with spans of 7, 28, 112, 224 days each)\n  - Time-series differences of $Y$ to account for trends in media coverage (with distances of 1, 7, 28, 91, 182, 364 days each)\n- Unknown confounders __U__.\n\n__Regional aggregation__. My setting throughout all methods is that I estimate models based on regional data. However, I do not fit separate models for each region, but always a single model on a dataset that includes all regions. This has the benefits that _(a)_ it leads to more generalizable results and _(b)_ it increases the size of the dataset by a factor of 14 (in comparison to using national data, or to estimating single regional models), and thereby increases statistical power. To integrate multiple time series from the various regions into a single dataset, I add static _dummy variables_ for each region. Limitations of this approach are:\n\n1. To capture the effect of regional differences properly, it would be necessary to also add _interaction terms_ of all 14 region dummies and all 5 treatment variables, as well as potentially some of the control variables. This would lead to at least 70 interaction terms, which would make the interpretation of the results much harder.\n\n2. The _differences_ between the regions -- especially in size, population size, and number of newspapers -- are potentially problematic for the estimation of a global model. I minimize this problem by (a) including previous amounts of coverage and (b) using absolute rather than relative coverage. While the relative coverage of a protest event will presumably be lower in larger regions (because a smaller proportion of the region is affected by any event), this will not be the case in absolute terms. However, it may be the case that there are major protest events with a strong relation to regional politics, and that they have an impact throughout the whole region, and in that case the size of the region might matter. This would not be captured by the model and could lead to a high variance the treatment effect estimates.\n\n3. On the other hand, the _national impact_ of protests is politically more interesting, so I also estimate a model on the national level, which has the structure as any of the regional models, but with aggregated treatment variables and newspaper coverage from national rather than regional newspapers.\n\n__Outcome time series.__ Protests may have an impact on newspaper converage not only on the day that they occur but also in the following days and weeks, so I estimate time series of causal impacts, as well as of cumulative impacts. For estimating the delayed impacts, I do _not_ extend the time series lags further into the future, because the amount of coverage on or after the protest date likely mediates the impact on future coverage. These mediated impacts are hard to isolate. By not including potential mediators in the predictors, I make sure that all indirect impacts are also clearly attributable to the treatment. I do _not_ extend the lags of the treatment further into the future either (mostly motivated by efficiency gains that are related to implementation details), so indirect impacts that are mediated by future protests (if they exist) are also included in the impact estimate.\n\n### Causal impact estimation\n\nFor the selection of suitable models, I specify the treatment as the occurrence of a protest event by any protest group, and the outcome as the one-week amount of total newspaper coverage mentioning the climate crisis. I then use these models to also estimate more specific impacts for events from specific groups; and for the coverage during single days, in order to build impact estimate time series.\n\nFor the main experiments I use the _ACLED_ dataset as source for protest events; and as source for media coverage I use the sum of both online and print newspaper articles. I also compute results for the _GPReg_ and _GPRep_ datasets and compare them, but I do not run hyperparameter optimization specific to these datasets.\n\n#### Regression {#sec-meth-reg}\n\nI estimate an OLS regression model, in order to interpret the coefficients for the treatments causally. This assumes the complete and correct specification of all confounding variables, and a linear model; see @sec-app2-reg for formal details.\n\nI perform hyperparameter optimization by 5-fold time-series cross-validation. Hyperparameters are: number of time series lags, inclusion of region dummies, inclusion of moving average features, and inclusion of time-series difference features (see @sec-agg).\n\nAn interesting question is what metric to optimize for. In predictive contexts this would typically be the (root) mean squared error ((R)MSE) or the mean average error (MAE); they minimize variance in the first place. For causal impact estimation, we want the estimates to be _unbiased_ much more than we want them to have a low variance. Therefore I minimize the bias, operationalized as the absolute value of the mean error (ME). Unlike the MAE, this takes the direction of the errors into account.\n\nOLS is unbiased for in-distribution data anyway. I want a model that also generalizes to out-of-distribution data -- this is what we generally want from causal models -- and OLS is not automatically unbiased for this. By using time-series cross-validation splits, I create a situation that is slightly out-of-distribution. Future work could also create situations that are more extremely out-of-distribution, for example by using large gaps for the time-series splits, or by using geographic splits.\n\nTo set the generalization capabilities of the OLS model into perspective, I also estimate similarly optimized Ridge and Lasso regression models. But I cannot use them for causal impact estimation because the coefficients are regularized and thus biased.\n\nI use the `OLS` implementation from the `statsmodels` package [@perktoldStatsmodelsStatsmodelsRelease2023] with `HC3` heteroskedacity-robust covariance estimation, and the `BayesianRidge` and `LassoLarsIC` implementations from `scikit-learn` [@pedregosaScikitlearnMachineLearning2011]. `statsmodels` does not support multivariate regression, so I run separate univariate models for each target variable.\n\n#### Instrumental variables {#sec-instrumental}\n\nI have 16 candidate variables for potential instruments. Their nature and validity is discussed in @sec-meth-data-instr. I procede in multiple exploratory steps.\n\n1. __Correlation.__ I compute correlations and Wald estimates (see @sec-app2-iv-ils) and compare them to each other. The Wald estimator is only valid for strong instruments.\n2. __Regression.__ I perform first-stage regression, that is, I regress protest occurrence on all instruments, controlling for the known confounders (time series data, in the same format of the hyperparameter optimization from @sec-res-reg). I adjust p-values for multiple testing via the Benjamini-Yekutieli procedure [@benjaminiControlFalseDiscovery2001a] because the variables are likely very correlated.\n3. __Deseasoning.__ Instrumental variables should be (almost) random, which is violated by seasonality, and most candidate variables have obvious seasonal patters.^[This problem is not present in most prior work, because it typically compares the impact during a single fixed timespan across geographical units (see @sec-weatherlit).] I compute seasonal components by taking 90-day rolling averages with a Gaussian window with a standard deviation of 30 days. I consider only the nonseasonal components, that is the residuals of the seasonal components, are potentially valid instruments. Again I perform first-stage regression on these residuals, controlling for the knwon confounders and the seasonal components. <!-- (The residual components seem much more meaningful when given the seasonal components.) -->\n4. __Principal components.__ Since there is probably a high correlation among the covid variables as well as among the weather variables, I compute principal components both for the seasonal and for the nonseasonal components, separately. The intent is (a) to potentially find components that have a higher impact than the individual instruments, because they may find and isolate patters, and (b) to account for the problem that regression may underestimate the impact of multicollinear variables.\n\nThen I use an alternative of two-stage least squares (see @sec-app2-2sls) that is more robust to weak instruments, namely _limited information maximum likelihood_ (LIML) to estimate the causal effect. I include the same confounders as from the optimized regression model (@sec-res-reg). I use the `IVLIML` implementation from the `linearmodels` library [@sheppardBashtageLinearmodelsRelease2023a].\n\n#### Synthetic control {#sec-synth}\n\nI fit a synthetic control for each protest event.[^global] Control regions are all regions that do not have a protest event on the given date. For all regions, outcome variables[^sociodemographic] of all coverage dimensions are considered during a specified pre-treatment period. Values of the different dimensions are stacked, resulting in one column per region. The columns for the control regions are scaled, where the scaling options are: demeaning (subtraction of the mean), as suggested by @fermanSyntheticControlsImperfect2021; subtraction of the values from the last date within the pre-treatment period; z-score standardization; mean normalization (division by the mean); and logarithmic scaling. Nonnegative least squares (NNLS) regression is performed to predict the treatment region values from the control region values; alternatively, interpolation is performed, which is similar to NNLS but demands that the coefficients for the regions um up to 1. The obtained weights are then used to predict the counterfactual for the post-treatment period from the control regions. The difference between actual values and counterfactual is the causal impact. (See @sec-app2-synth for mathematical model assumptions.)\n\n[^global]: Estimating region weights globally rather than for every single protest event is not possible because the available control regions vary between events.\n\n[^sociodemographic]: Alternatively to regressing on pre-treatment outcomes, weights can also be obtained by fitting on fundamental characteristics of the regions (such as sociodemographic or economic statistics) that are considered predictive of the outcome [@abadieSyntheticControlMethods2010]. I discard such an approach because the choice of variables biases the causal impact estimate, and I find it hard to justify any specific variables that would be predictive of climate change newspaper coverage.\n\nFor the synthetic control method, significance is typically evaluated by using permutation tests. In my setting I do not only have a single estimate, but rather a large number of estimates from fitting many synthetic controls, so I can compute confidence intervals based on the population variance of the estimates.\n\nI manually evaluate the suitability of the scaling and fitting methods by plotting the pre-treatment fit. The length of the pre-treatment period is chosen by hyperparameter optimization. The objective is an unbiased estimation of the counterfactual in the post-treatment period. Since the counterfactual is unknown, a workaround is to minimize the post-treatment bias in the general case. If the weights generally represent the \"true\" relationship between the regions, then they will also do so for the counterfactual, subject to the model assumptions from @sec-app2-synth. Therefore I perform hyperparameter optimization for minimizing the post-treatment error in synthetic control settings for randomly selected dates (rather than actual protest dates).[^pretreat] This is similar to having a large number of train-test splits, to which the synthetic control method is applied, and additional cross-validation is not necessary.\n\n[^pretreat]: An alternative is to focus on the pre-treatment fit. Theoretically both approaches are similarly justified. By referring to propensities, anticipation effects, or missing data, one may practically argue in favour of one approach or the other; see @sec-disc-synth for further discussion.\n\nI use a custom implementation that builds on @facurealvesCausalInferenceBrave2022 [ch. 15]. Future work may also use a _Bayesian structural time series_ model [@brodersenInferringCausalImpact2015a], which makes similar assumptions and is practically more flexible.\n\n#### Propensity scores\n\n_Propensity scores_ quantify the probability of the treatment, that is: _How likely is it on a given day in a given region that a protest takes place?_ (See @sec-app2-ps for mathematical details.)\n\nI obtain propensity scores by training probabilistic classifier models to predict the treatment (the occurrence of protests) from the known confounders (primarily past time-series values and features, see @sec-agg). I consider Naive Bayes and logistic regression models because they both produce well-calibrated probabilities. I optimize the following hyperparameters on a 5-fold time-series split: number of time series lags, inclusion of region dummies, inclusion of moving average features, inclusion of time-series difference features, and inclusion of log-scaled participant numbers (and corresponding moving averages) in the past time series (in addition to the binary protest occurrence variables). For logistic regression I also consider whether balanced class weights are used. Optimization objective is the F1 score.\n\nAs final propensity scores I use cross-predicted probabilities from a conventional 5-fold cross-validation split, because time-series splits would not yield predictions for the start of the time series.\n\nI use _inverse propensity weighting_ (IPW) as a pure propensity score model. IPW essentially calculates a weighted mean, where more weight is given to protest days with a low probability for a protest, and to non-protest days with a high probability for a protest (see @sec-app2-ipw for details). IPW can be combined with regression, which is called _doubly robust estimation_ (DRE), and which is theoretically valid if the assumptions of at least one of its parts hold (see @sec-app2-dre).\n\nI use the IPW implementation from the `DoWhy` Python package [@sharmaDoWhyEndtoEndLibrary2020], with a normalized weighting scheme (that is, the Hájek estimator, see @sec-app2-ps) for ATT estimation. As an implementation for DRE I use the `LinearDRLearner` from the `EconML` Python package [@econml] with their `StatsModelsLinearRegression` model as regression model. For the computation of propensity scores I use `LogisticRegressionCV` from `scikit-learn` [@pedregosaScikitlearnMachineLearning2011] with the `liblinear` solver.\n\n<!--\n\n##### Propensity scores from full texts\n\ncite Wager, and causal NLP overview\n\nPredicting propensity scores from text: cite causalNLP overviews\nFor example, @bundeskriminalamtbkaLagebildLetzteGeneration2023 hypothesize that \"Die Fallzahlen unterliegen einem „wellenartigen“ Verlauf, welcher sich vornehmlich durch (das Ausbleiben von) Großveranstaltungen im gleichen Kontext erklären lässt.\"\n\npossible models:\n\n- gelectra: 100-300M parameters https://huggingface.co/deepset/gelectra-base\n- igel: 6B parameters https://huggingface.co/philschmid/instruct-igel-001\n- llama 2 german https://huggingface.co/flozi00/Llama-2-7b-german-assistant-v2\n\nfaster finetuning: https://github.com/huggingface/peft -->\n\n#### Evaluation {#sec-meth-placebo}\n\nThere is no straightforward way to evaluate causal models, since the true causal impacts are unknown.\n\n__Subsidiary metrics.__ The sections above describe the optimization and evaluation of subsidiary metrics for the individual methods:\n\n- For the regression method I evaluate the predictive quality on time-series splits in terms of bias. The best model is also used for the parts of the other methods that use regression (the individual stages of the 2SLS instrumental variables estimator, and the second stage of the doubly robust estimaor).\n- Similarly for the synthetic control I evaluate bias on time-series splits, just that the underlying regression works differently.\n- For the propensity score methods I evaluate the classification quality in terms of the F1 score in time-series splits. (Conventional splits are used for prediction.)\n\n__Placebo tests.__ An evaluation method that is specifically suited to causal models are _placebo tests_. They cannot show that a model is correct, but they can make it much more plausible [@dingFirstCourseCausal2023, ch. 16]. I use two types of placebo tests:\n\n- _Negative outcome_ [see @dingFirstCourseCausal2023, ch. 16.2.1]. Here I compute the causal impacts of protest events on newspaper coverage before the occurrence of the events. These outcomes are very similar to the outcomes that I actually want to estimate, but we know that there is no causal impact, due to the order in time. (See @sec-disc-synth for discussion of anticipation effects.)\n- _Negative exposure_ [see @dingFirstCourseCausal2023, ch. 16.2.2]. Here I compute the impact of random days rather than days with protest events. I assign the random treatments by sampling without replacement from the actual treatments; so the distribution of protest and non-protest days remains the same. I perform two sampling procedures: (a) sampling within each region, so that the protest-day proportions among the regions remain intact and some bias is retained; and (b) sampling across regions, so that treatments are completely random.\n\nThe expectation for the placebo tests is that the models should estimate zero causal impacts for them. If they estimate clear non-zero impacts, then the models are shown to be incorrect.\n\n\n\n{{< pagebreak >}}\n\n---\nexecute:\n  freeze: true\n---\n\n\n\n<!--\n\nAnalysis of the results with graphics like bargraphs and boxplots has been made. Statistical methods have been employed to compare different results. AUCs have been obtained. Minimal verification.\n+ Attention has been paid to the distribution of the data. Verification has been carried out. Attention is paid to overfitting.\n+ Results have been analysed with proper statistics. Model assumptions of statistical methods are verified or methods that do not make assumptions were employed for non-Gaussian data. Checks were made to avoid hidden overfitting.\n+ Best approach for obtaining significant results was taken while refraining from p-value hacking.\n\n -->\n\n## Results\n\n### Evaluation of methods\n\n#### Regression {#sec-res-reg}\n\nThe best model uses only a single time-series lag, as well as moving averages and difference features. Metrics for the OLS and the regularized regression models are shown in @tbl-reg-hypopt. Even though the bias is minimized, it is still substantial at around -14 articles within a timespan of one week. (This is only for time-series splits; the bias for conventional shuffled cross-validation splits is very close to 0 for all models.) A regression table with coefficients is appended in @sec-app1-reg.\n\n| Model          | Hyp. opt. obj. | RMSE          | Bias         |\n| -------------- | -------------- | ------------- | ------------ |\n| OLS            | min RMSE       | 110.6 ± 24.2  | -18.8 ± 10.4 |\n| OLS            | min bias       | 130.9 ± 21.5  | -14.3 ± 10.1 |\n| BayesianRidge  | min bias       | 119.7 ± 23.4  | -3.85 ± 15.2 |\n| LassoLarsIC    | min bias       | 118.9 ± 24.5  | -2.89 ± 15.7 |\n\n: Bias (mean error) and root mean squared error (RMSE) as a measure for variance for the best models that result from hyperparameter optimization. {#tbl-reg-hypopt}\n\n\n\n#### Instrumental variables\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {.cell execution_count=11}\n\n::: {#fig-iv-wald .cell-output .cell-output-display execution_count=11}\n```{=tex}\n\\begin{tabular}{lrrr}\n\\toprule\n{} &  corr\\_w &  corr\\_y &      wald \\\\\n\\midrule\nweather\\_tavg                &  0.0202 &  0.0375 &    672.74 \\\\\nweather\\_tmin                &  0.0292 &  0.0651 &    808.17 \\\\\nweather\\_tmax                &  0.0132 &  0.0238 &    650.41 \\\\\nweather\\_prcp                &  0.0076 &  0.0174 &    831.90 \\\\\nweather\\_snow                & -0.0167 & -0.0588 &   1274.29 \\\\\nweather\\_wspd                & -0.0190 & -0.1192 &   2271.44 \\\\\nweather\\_wpgt                & -0.0139 & -0.1043 &   2715.87 \\\\\nweather\\_pres                & -0.0089 &  0.0195 &   -792.63 \\\\\nweather\\_tsun                & -0.0011 & -0.0402 &  12802.26 \\\\\ncovid\\_retail\\_and\\_recreation &  0.0376 &  0.2006 &   1932.76 \\\\\ncovid\\_grocery\\_and\\_pharmacy  &  0.0158 &  0.2205 &   5072.44 \\\\\ncovid\\_residential           & -0.0500 & -0.2058 &   1493.50 \\\\\ncovid\\_transit\\_stations      &  0.0380 &  0.2163 &   2065.30 \\\\\ncovid\\_parks                 &  0.0266 &  0.0837 &   1141.85 \\\\\ncovid\\_workplaces            &  0.0475 &  0.2055 &   1567.75 \\\\\ncovid\\_stringency\\_index      & -0.0191 & -0.1920 &   3642.73 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nCorrelations between the instruments and the treatment (corr_w) and between the instruments and the outcome (corr_y), and Wald estimator results.\n:::\n:::\n\n\n\\endgroup\n\nCorrelations and Wald estimator results of the original variable are shown in @fig-iv-wald. Note that the Wald estimator is not valid for weak instruments.\n\nAutomatically binarizing the variables based on an optimally chosen threshold does not generally increase the covariances, and decreases them slightly in most cases. This is also true for precipiation: The optimal threshold for maximizing the covariance with protest occurrence is at prcp > 0, which is consistent with the choice in most related work (see @sec-lit-causal), but the binarization does not change the covariance much. (TODO: give number.)\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-iv-basic .cell execution_count=12}\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=tex}\n\\begin{tabular}{lrrrrr}\n\\toprule\n{} &   coef\\_w &       p &    p\\_bh &    p\\_by &  fstat \\\\\n\\midrule\ncovid\\_parks                 &  0.01839 &  0.0036 &  0.0168 &  0.0902 &   9.96 \\\\\ncovid\\_grocery\\_and\\_pharmacy  & -0.01664 &  0.0044 &  0.0187 &  0.1002 &   3.50 \\\\\ncovid\\_workplaces            &  0.02328 &  0.0051 &  0.0209 &  0.1124 &  31.86 \\\\\nweather\\_wspd                & -0.00867 &  0.0811 &  0.2212 &  1.0000 &   5.10 \\\\\nweather\\_pres                & -0.00385 &  0.1100 &  0.2809 &  1.0000 &   1.12 \\\\\nweather\\_wpgt                &  0.00354 &  0.4623 &  0.7705 &  1.0000 &   2.73 \\\\\ncovid\\_stringency\\_index      & -0.00382 &  0.5435 &  0.8152 &  1.0000 &   5.14 \\\\\nweather\\_tmin                &  0.00802 &  0.5582 &  0.8270 &  1.0000 &  12.01 \\\\\ncovid\\_transit\\_stations      & -0.00670 &  0.5755 &  0.8321 &  1.0000 &  20.34 \\\\\nweather\\_tsun                &  0.00204 &  0.6046 &  0.8436 &  1.0000 &   0.02 \\\\\nweather\\_tmax                & -0.00770 &  0.6970 &  0.9191 &  1.0000 &   2.47 \\\\\ncovid\\_retail\\_and\\_recreation & -0.00288 &  0.7506 &  0.9306 &  1.0000 &  19.95 \\\\\nweather\\_tavg                & -0.00615 &  0.8321 &  0.9510 &  1.0000 &   5.76 \\\\\ncovid\\_residential           &  0.00099 &  0.9450 &  0.9807 &  1.0000 &  35.22 \\\\\nweather\\_snow                & -0.00005 &  0.9829 &  0.9911 &  1.0000 &   3.93 \\\\\nweather\\_prcp                &  0.00002 &  0.9941 &  0.9941 &  1.0000 &   0.81 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nFirst-stage impact of the original instruments. Regression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. Results are sorted by original p-values and adjusted p-values (p_bh = Benjamini-Hochberg, p_by=Benjamini-Yekutieli) and first-stage f-statistics for using each variable as an instrument on its own are displayed.\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-iv-deseason .cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=tex}\n\\begin{tabular}{lrrrrr}\n\\toprule\n{} &   coef\\_w &       p &    p\\_bh &    p\\_by &  fstat \\\\\n\\midrule\ncovid\\_workplaces\\_seasonal           &  0.06174 &  0.0006 &  0.0036 &  0.0200 &   8.58 \\\\\ncovid\\_stringency\\_index\\_seasonal     & -0.03709 &  0.0018 &  0.0104 &  0.0572 &   0.06 \\\\\ncovid\\_stringency\\_index\\_resid        &  0.00872 &  0.0073 &  0.0331 &  0.1816 &   2.56 \\\\\ncovid\\_transit\\_stations\\_seasonal     & -0.06763 &  0.0078 &  0.0343 &  0.1883 &   5.19 \\\\\ncovid\\_grocery\\_and\\_pharmacy\\_resid    & -0.01219 &  0.0081 &  0.0343 &  0.1883 &   0.77 \\\\\ncovid\\_parks\\_seasonal                &  0.05477 &  0.0102 &  0.0409 &  0.2248 &  21.75 \\\\\nweather\\_wspd\\_resid                  & -0.01074 &  0.0239 &  0.0774 &  0.4251 &   1.62 \\\\\nweather\\_pres\\_resid                  & -0.00420 &  0.0886 &  0.2511 &  1.0000 &   1.66 \\\\\ncovid\\_residential\\_resid             & -0.01348 &  0.1220 &  0.3131 &  1.0000 &  19.31 \\\\\ncovid\\_grocery\\_and\\_pharmacy\\_seasonal & -0.02819 &  0.1363 &  0.3432 &  1.0000 &   4.43 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nFirst-stage impact of the seasonal and residual parts of the instruments. Regression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. Results are sorted by original p-values and adjusted p-values (p_bh = Benjamini-Hochberg, p_by=Benjamini-Yekutieli) and first-stage f-statistics for using each variable as an instrument on its own are displayed. Only the 10 most significant variables are displayed.\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {#tbl-iv-deseason-pc .cell execution_count=14}\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=tex}\n\\begin{tabular}{lrrrrr}\n\\toprule\n{} &   coef\\_w &       p &    p\\_bh &    p\\_by &  fstat \\\\\n\\midrule\npc\\_seasonal\\_12 & -0.01009 &  0.0000 &  0.0002 &  0.0009 &  69.37 \\\\\npc\\_resid\\_9     & -0.00730 &  0.0005 &  0.0029 &  0.0162 &  28.31 \\\\\npc\\_seasonal\\_0  & -0.00598 &  0.0122 &  0.0520 &  0.2857 &  17.70 \\\\\npc\\_seasonal\\_9  & -0.00566 &  0.0291 &  0.1016 &  0.5583 &  16.76 \\\\\npc\\_seasonal\\_10 & -0.00452 &  0.0455 &  0.1477 &  0.8114 &   2.18 \\\\\npc\\_resid\\_8     & -0.00408 &  0.0504 &  0.1594 &  0.8757 &   2.21 \\\\\npc\\_seasonal\\_1  & -0.00434 &  0.0634 &  0.1920 &  1.0000 &   7.46 \\\\\npc\\_resid\\_11    &  0.00368 &  0.0673 &  0.1947 &  1.0000 &   2.16 \\\\\npc\\_seasonal\\_6  &  0.00450 &  0.0772 &  0.2187 &  1.0000 &   7.13 \\\\\npc\\_resid\\_7     &  0.00281 &  0.1618 &  0.4040 &  1.0000 &   0.23 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nFirst-stage impact of principal components calculated separately for the seasonal and residual parts of the instruments. Regression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. Results are sorted by original p-values and adjusted p-values (p_bh = Benjamini-Hochberg, p_by=Benjamini-Yekutieli) and first-stage f-statistics for using each variable as an instrument on its own are displayed. Only the 10 most significant variables are displayed.\n:::\n:::\n\n\n\\endgroup\n\n::: {.cell .column-page execution_count=15}\n\n::: {.cell-output .cell-output-display}\n![The three most important nonseasonal principal components in terms of the original nonseasonal (residual) instruments.](report_files/figure-pdf/fig-iv-pc-vis-output-1.svg){#fig-iv-pc-vis}\n:::\n:::\n\n\nMultiple steps are shown for the impact of the instruments on the treatment while controlling for known confounders and other instruments:\n\n1. @tbl-iv-basic shows the impact of the original instruments. Three of the covid variables are relatively significant, the weather variables less so, with _wind speed_ being most significant and precipitation least significant.\n2. @tbl-iv-deseason shows the impact for the variables after splitting them into seasonal and residual components. The most significant variables are seasonal ones derived from covid variables. Of the residuals, the _stringency index_, the movement data for \"grocery and pharmacy\", and _wind speed_ are most significant.\n3. @tbl-iv-deseason-pc shows the principal components for the seasonal and residual variables from the previous step. The top two variables are much more significant than without PC, and one of them is a residual variable. The meaning of the three most significant reidual variables is shown in @fig-iv-pc-vis. According to the \"rule of thumb\" (@InstrumentalVariablesEstimation2023) the threshold for weak instruments is around f=10, so pc_resid_9 would be a strong instrument but the other ones would all be weak.\n\nPlacebo tests for the first stage are given in @fig-iv-1-placebo. The instrument has a significant impact on protest occurrence for a few days around the date where the instrument was measured. For days that are further away there is less impact, but not exactly zero. Placebo tests for the second stage are shown together with the other methods in @sec-res-placebo.\n\n::: {.cell execution_count=16}\n\n::: {.cell-output .cell-output-display}\n![First stage placebo tests for using the principal component pc_resid_9 to instrument protest occurrence. Values for the instrument from after the protest date are used. These values cannot have an impact on protest occurrence if the instrument is valid.](report_files/figure-pdf/fig-iv-1-placebo-output-1.svg){#fig-iv-1-placebo}\n:::\n:::\n\n\n#### Synthetic control\n\n@fig-synth-hyperopt shows how the length of the pre-treatment period influences the bias of the causal estimate. Bias is most reduced at n=180, with a bias (mean error) of -0.330±1.13, and an RMSE of 65.8±2.40.\n\n::: {.cell execution_count=17}\n\n::: {.cell-output .cell-output-display}\n![Hyperparameter optimization: Influence of the pre-period length on bias (mean error).](report_files/figure-pdf/fig-synth-hyperopt-output-1.svg){#fig-synth-hyperopt}\n:::\n:::\n\n\n@fig-sc-long shows the fit for the optimized unbiased model (specifically: unbiased for estimating the -day cumulative coverage).\n\n::: {.cell execution_count=18}\n\n::: {.cell-output .cell-output-display}\n![Synthetic control fit around the treatment for a pre-treatment period of n=180. Values are aggregates from synthetic controls for all protest events. Weekly patterns are due to regularities in protest event timing (Fridays for Future) and weekly cycles in general newspaper coverage.](report_files/figure-pdf/fig-sc-long-output-1.svg){#fig-sc-long}\n:::\n:::\n\n\n@fig-sc-short shows the fit for a shorter pre-treatment period and with better pre-treatment fit.\n\n::: {.cell layout-nrow='2' execution_count=19}\n\n::: {.cell-output .cell-output-display}\n![Synthetic control fit around the treatment for a pre-treatment period of n=22. Values are aggregates from synthetic controls for all protest events. Weekly patterns are due to regularities in protest event timing (Fridays for Future) and weekly cycles in general newspaper coverage.](report_files/figure-pdf/fig-sc-short-output-1.svg){#fig-sc-short}\n:::\n:::\n\n\n@fig-sc-longterm gives an impression of the long-term impact estimate. Rolling averages are used for preprocessing, so the absolute impacts cannot directly be retrieved.\n\n::: {.cell execution_count=20}\n\n::: {.cell-output .cell-output-display}\n![Synthetic control with pre-treatment period of two years and longterm effects for half a year. Outcomes have been preprocessed with weekly rolling averages. No bias checks have been made for this model.](report_files/figure-pdf/fig-sc-longterm-output-1.svg){#fig-sc-longterm}\n:::\n:::\n\n\nIn the _ACLED_ dataset there is a protest in every single region on March 19, 2021, so no control region can be constructed. For the _GPRep_ dataset this also occurs on September 9, 2021 and on March 25, 2022.\n\n#### Propensity scores\n\nHyperparameter optimization shows that the best model is a logistic regression model without balanced class weights, using all available features (moving averages, differences, and log-scaled protest sizes), 4 days of time-series lags, and z-score standardization of all feature variables.\n\nThe baseline value for the F1 score can be calculated by setting all predictions positive. This results in F1=0.118 for my dataset.\n\nThe best logistic regression model achieves a 5-fold time-series cross-validated score of F1=0.233±0.044, while a similar model with balanced class weights achieves F1=0.213±0.017.\n\nBrief experiments with doubly robust estimation show that other than expected it gives estimates that are multiple orders of magnitudes higher than those of regression or inverse propensity weighting; it estimates chaotic time series; and it is overly sensitive to the hyperparameters that create the time series features (number of lags, inclusion of moving averages, etc.), much more than regression or IPW. I do not further investigate the problem and exclude the method from the analysis.\n\n### Placebo tests {#sec-res-placebo}\n\n@fig-placebo-outcome shows placebo tests for the outcome for all models. Further placebo tests concern the treatments: For @fig-placebo-treatment-regional, the treatments are randomized within each region, while for @fig-placebo-treatment-global they are randomized across region (see @sec-meth-placebo).\n\n::: {.cell .column-page execution_count=21}\n\n::: {.cell-output .cell-output-display}\n![Placebo tests for the outcome. The protests event date is at x=0. To the right of it are impact estimates for subsequent days, where it is possible that there actually is a causal impact. To the left of it are the days prior to the event data, where a causal impact is not possible. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-placebo-outcome-output-1.svg){#fig-placebo-outcome}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=22}\n\n::: {.cell-output .cell-output-display}\n![Placebo tests for the treatment, where treatments are randomized but the protest day proportions among regions are not, potentially causing some bias. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-placebo-treatment-regional-output-1.svg){#fig-placebo-treatment-regional}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=23}\n\n::: {.cell-output .cell-output-display}\n![Placebo tests for the treatment, with completely randomized treatments across regions. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-placebo-treatment-global-output-1.svg){#fig-placebo-treatment-global}\n:::\n:::\n\n\n### Causal impact estimates {#sec-res-est}\n\n@fig-impact-ts and @fig-impact-ts-cum show time series of the absolute and cumulative causal impact estimates, for protest-related and non-protest-related media coverage and for all causal methods. The order of magnitude of the causal effects differs substantially between some of the methods.\n\n::: {.cell .column-page execution_count=24}\n\n::: {.cell-output .cell-output-display}\n![Causal impact estimates by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-impact-ts-output-1.svg){#fig-impact-ts}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=25}\n\n::: {.cell-output .cell-output-display}\n![Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-impact-ts-cum-output-1.svg){#fig-impact-ts-cum}\n:::\n:::\n\n\n@fig-impact-dims summarizes the 7-day cumulative impacts by coverage dimension and includes the impact for three specific sub-topics (see @sec-data-discourse).\n\n::: {.cell .column-page execution_count=26}\n\n::: {.cell-output .cell-output-display execution_count=26}\n![7-day cumulative causal impact estimates by method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.](report_files/figure-pdf/fig-impact-dims-output-1.svg){#fig-impact-dims}\n:::\n:::\n\n\n@fig-impact-medium differentiates between the impact on online newspapers and on print newspapers, only for the synthetic control method. @fig-impact-groups-7 break down the 7-day cumulative impact for the different protest groups, as estimated by the synthetic control method.\n\n::: {.cell .column-page execution_count=27}\n\n::: {.cell-output .cell-output-display}\n![Causal impact estimates for online vs print newspapers, as estimated by the synthetic control method. The protest day is at x=0.](report_files/figure-pdf/fig-impact-medium-output-1.svg){#fig-impact-medium}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=28}\n\n::: {.cell-output .cell-output-display execution_count=28}\n![7-day cumulative causal impact estimates by protest group, as estimated by the synthetic control method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.](report_files/figure-pdf/fig-impact-groups-7-output-1.svg){#fig-impact-groups-7}\n:::\n:::\n\n\n@fig-impact-dataset and @fig-impact-groups-sources show how the impact estimates differ by dataset, for using the synthetic control method. Detailed results for the _GPReg_ and _GPRep_ datasets for all causal methods are in the appendix in @fig-impact-ts-gpreg and @fig-impact-ts-gprep, respectively.\n\n::: {.cell .column-page execution_count=29}\n\n::: {.cell-output .cell-output-display}\n![Causal impact estimates by dataset, as estimated by the synthetic control method. The protest day is at x=0.](report_files/figure-pdf/fig-impact-dataset-output-1.svg){#fig-impact-dataset}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=30}\n\n::: {.cell-output .cell-output-display execution_count=30}\n![7-day cumulative causal impact estimates by protest group, as estimated by the synthetic control method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.](report_files/figure-pdf/fig-impact-groups-sources-output-1.svg){#fig-impact-groups-sources}\n:::\n:::\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nDiscussion interprets the results and places them in terms of the state-of-the-art.\n\nInterpretation of findings (e.g. in terms of a) research ethics b) limitation of the research methodology):\nExcellent and critical discussion and or reflection on all findings vis-a-vis existing research. Attention for research limitations and concrete suggestions for further research. Conclusions have been based on results, and have been taken to a higher level.\n\n -->\n\n## Discussion\n\n### Regression\n\n__Bias.__ The results affirm that OLS is unbiased for in-distribution data, but they show that it is here substantially biased across time-series splits, where it underestimates the media coverage amount one week from a given date by 14 articles. This is likely due to a generally increasing trend in media coverage in my dataset. By minimizing for bias, I have already slightly decreased the bias from 18 to 14. Regularized models generalize much better and drive down the bias to 3 or 4 articles, so it would be desirable to use them; but their coefficients are biased, and the coefficient for the treatment is the estimator for the causal impact. Future work might explore (a) using regularized models that exclude the treatment coefficient from regularization or (b) debiased regularized models such as debiased Lasso [@vandegeerAsymptoticallyOptimalConfidence2014], which is also implemented in `EconML`. Still, it is plausible that the bias is caused by the trend throughout the time-series splits, and does thus not necessarily threaten the validity of the model.\n\n__Placebo behaviour.__ The estimated effects for the pre-treatment clearly differ from zero, and indicate bias. Bias may come from omitted variables, or from a misspecified model. The estimates exhibit weekly patterns during the placebo timespan. Weekdays are already controlled for, so this suggests a lack of interaction variables involving weekdays, or very nonlinear implications of weekdays. This could be cosmetically fixed by adding interaction terms for weekdays; but there may as well be other interactions that are not visible in the time series and also require modelling. Causal random forests [@wagerEstimationInferenceHeterogeneous2017] may provide a more systematic solution. The estimates for placebo treatments do not raise concerns.\n\n### Instrumental variables\n\n__Correlation and Wald estimate.__ The correlation between the instruments and the treatment is generally very low. Wald estimates are scaled inversely by this first-stage correlations, and measurement errors make them unreliable when they are close to zero. We can assume with certainty that the first-stage correlations are smaller than 1, so the correlation between the instruments and the outcome can be taken as a lower bound for the causal impact of the protests, but they are very low.\n\n__Original instruments.__ Irrespective of the adjustment method there are only three somewhat significant variables, and none of them is a weather variable. This is very surprising, because related work has consistently relied on weather variables, especially rainfall or precipitation (see @sec-weatherlit) -- whereas in my analysis precipitation is the single least significant instrument (with respect to impact on the treatment) at an adjusted p-value of p=0.99. Three systematic and one case-specific factor may explain this result, at least partially:\n\n- Unlike most of the literature, I measure the impact of single protest events rather than, for example the number of events over longer timespans. However, @huet-vaughnQuietRiotCausal2013 have had a similar setting and have found suitable weather instruments.\n- I only consider the impact on protest occurrence and not on the number of participants.^[This is left for future work. It is nontrivial because decisions need to be made about the scaling of both the weather variables and the protest size variable.]\n- I control for _movement_ variables that have been measured and published in the context of the covid-19 pandemic. Yet they do not only relate to the pandemic, but rather describe the general frequency of visits to certain locations, among them _parks_. It is plausible that the _parks_ movement variable largely or completely mediates the impact of the weather on protest occurrence, while additionally incorporating information from pandemic restrictions. Since this is also the most significant variable, it plausibly explains the low significance of _precipitation_ in the multiple regression analysis. Yet the _precipitation_ variable also has one of the lowest f-statistics, as measured by single regression.\n- The case study is concerned with environmental movements. One can speculate that perhaps this movement is less sensitive to bad weather conditions than other, previously studied protest movements.\n\n__Deseasoned instruments.__ De-seasoning is necessary because in contrast to prior work I look at dis-aggregated events. One could expect that this will be a methodical weakness, because deseasoning takes away some information from the instrumental variables. We can observe that, on the one hand, this is the case: Two of the three instruments that are most significant in the original analysis (@tbl-iv-basic) -- _parks_ and _workplaces_ -- do not have very significant deseasoned variables (@tbl-iv-deseason). On the other hand, the deseasoned _grocery and pharmacy_ variable is still almost as significant, and we have the _stringency index_ that is only significant after deseasoning. It must be noted that deseasoning was conceived primarily to be applied to the yearly-seasonal weather variables, and that it makes sense to also apply them to the covid variables, because they also have some yearly seasonality -- but unlike for the weather variables, we cannot assume that the covid variables are completely random after deseasoning; rather, there may still be problems due to the fact that they have little short-time variability.\n\n__Principal components.__ PCA successfully constructs a combined deseasoned variable -- _pc\\_resid\\_9_ -- that is more significant than the original deseasoned variables. From @fig-iv-pc-vis we can see that it is only related to the covid variables, and mostly to the previously also relatively significant variables _grocery and pharmacy_, _workplaces_, and also _residential_ and _retail and recreation_, but as well to all other covid variables. The other two somewhat significant variables are related to the weather and the stringency index. These are very weak instruments on their own, so they are unsuitable for my analysis. Other instrumental variable settings, where precipitation on its own is already a relevant instrument, may find that PCA may help them to construct even stronger instruments, perhaps even to overcome the weak variable threshold.\n\n__Placebo and causal estimates.__ The first-stage placebo test is ambiguous: The signal from the instruments to the treatment is strongest on the protest dates and surrounding days (explainable by slowly changing instruments), but not converging to zero for more distant dates. All placebo tests show a huge bias, and the impact estimates are implausibly high, one or two orders of magnitude higher than for the other methods. This disqualifies the instrumental variable method with this instrument as a plausible causal method. The applied _LIML_ method is already targeted at weak instruments, but there are alternative approaches to weak variables such as Fieller–Anderson–Rubin confidence intervals [@dingFirstCourseCausal2023, ch.21.4, ch. 23.6.3], to be explored in future work. According to the infamous \"rule of thumb\" [@InstrumentalVariablesEstimation2023] the used instrument is actually strong. If this were so, then the negative placebo tests would require that one of the other assumptions -- randomness or the _exclusion restriction_ are violated (see @sec-app2-iv). This may also have implications for the potential usage of these instruments in unrelated contexts.\n\n### Synthetic control {#sec-disc-synth}\n\n__Bias.__ The general prediction bias of the synthetic control method can be successfully reduced by hyperparameter optimization. The optimized hyperparameters are presumably only useful for this specific dataset. However a generally small bias does not necessarily mean a small bias for post-treatment counterfactuals, which is impossible to evaluate.\n\nAn alternative to my approach would be to minimize the bias in the pre-treatment period. Placebo tests indicate that the synthetic control method performs generally reasonably, except for the end of the pre-treatment period -- this favours the alternative approach. Minimizing bias in the pre-treatment period presumably leads to smaller fitting intervals and higher variance; this should be checked empirically in future work. The strength of the synthetic control method is to reduce bias by fitting control regions over long timespans, and this advantage would get lost by deliberately choosing shorter fitting intervals. This argument, if empirically underfed, would support my present approach.\n\n__Anticipation effects.__ @abadieSyntheticControlMethods2010 briefly discuss the presence of _anticipation effects_, and suggest to adjust the pre/post-treatment split such that the anticipation effects also lie in the post-treatment interval. This is reasonable -- but how do we know whether we actually observe anticipation effects, or rather confounders? If the increase in coverage before the protest occurrence really is a confounder, then the principle behind inverse propensity weighting (see @sec-app2-ipw) suggests that we should assign a smaller weight to the impacts of this protest, rather than adding additional anticipation effects.\n\n- An argument in favour of viewing the increased coverage as anticipation effects is that it mostly restricted to coverage that mentions protests. This suggests that the coverage may indeed be in anticipation of the protest, rather than that the protest is a reaction to the increase in coverage. Yet this cannot be said so clearly: For example, if a large protests receives a lot of previous coverage, it might attract even more participants.\n\n- I take the view that talk of \"anticipation effects\" is noncausal, since there is no physical pathway against the arrow of time. In more strictly causal terms, an increase in coverage, even if it is completely devoted to an anticipated protest, is due to factors that temporally precede the protest: The campaigning work and press relations of protest groups may play a role; journalists may deem a future large protest as more plausible when previous protests have already occurred, or when the protest organizers have a high reputation. Many of these factors may be influenced by the occurrence of previous protests, which attract more campaigners, create network effects, or bring the issue to attention in the first place. A causal analysis should then attribute the anticipation effects to the previous protests rather than the anticipcated one.\n\n- Theoretically problematic is that, of course, ultimately all protest activity is causally determined by some events that lead to the occurrence of the protest (neglecting quantum effects). Controlling for all these would yield a zero causal effect. The question is then which prior events should be included in the definition of a protest. The clear part of the answer is that the decisions of the participants to attend the protest should probably be seen as part of the protest, whereas clearly external factors such as the weather should probably not. Whether previous campaigning work and the credibility that the event is going to happen should be counted as part of the protest is, in my view, an open definitory question. If one answers it positively, then one could follow the anticipation effect theory, but only after verifying from the full texts that the increased coverage really only concerns the anticipated protest. If one answers it negatively, then one could experiment with decreasing the fitting interval until anticipation effects are removed (but this is problematic due to the incomplete data problem described below), or resort to propensity score methods.\n\n__Incomplete data.__ The synthetic control method suffers from missing data in two opposite ways:\n\n- _Large events_ may not have enough control regions to suitably model the treatment region. I have not set a threshold for the minimum number of control regions. One large event (21.03.2021) has happened in all regions, so that it had to be excluded from the analysis, leading to a slight underestimation of the average impact. It is also possible that synthetic controls based on very few control regions suffer from systematic bias.\n\n- _Small events_ may not always be present in the dataset. An unsystematic internet search for some protest dates with a predicted negative impact shows that some of them use control regions where actually some protest events took place and were just not in the dataset. Optimizing the fit in the anticipation effect timespan would weigh these \"false negative\" regions even higher, exacerbating the bias.\n\n__Weekly patterns.__ @fig-sc-long shows that the model has difficulty with modeling the weekly decrease of newspaper coverage on Sundays. Better fit can be achieved by using weekly moving averages (as done in @fig-sc-longterm). The fitted weights could be used for obtaining daily impact estimates. Future work could check whether such preprocessing actually makes a difference, and whether it is theoretically desirable.\n\n__Spillover effects.__ The synthetic control method assumes that there are no spillover effects. Their existence leads to an under-estimation of the causal effects. In principle one could also try to model these effects, but that would complicate the model a lot.\n\n### Propensity scores {#sec-disc-ps}\n\n__Bias.__ The placebo tests show that IPW consistently reduces the bias that pure correlation has, but not until zero. This is likely due to the rather low F1-score for the propensity scores. Future work may use dedicated time series forecasting or classification methods to improve performance; or may leverage text classification of prior discourse or of press releases about related events.\n\n__Extensions.__ IPW does not consider the effect of the confounders on the treatment. This is theoretically justified if the propensity scores are reliable (see @sec-app2-ipw). In the absence of good propensity scores, the model may benefit from combination with a model for the outcome. The _doubly robust estimator_ should be re-evaluated, and occcurring problems should be investigated in more depth. A nonparametric alternative would be _double machine learning_ [@chernozhukovDoubleDebiasedMachine2017]; it fits a regression model on the residuals of nonparametric propensity score and outcome models.\n\n### Impact estimates\n\n__Convergence.__ A plausible property of the causal impact is that the absolute impact converges to zero over time, and the cumulative impact thus converges to some total number of additional newspaper articles. This behaviour can be clearly seen for the protest-mentioning articles with regression, synthetic control, and to some extent with instrumental variables. Since the bias is minimized for the cumulative impact after 7 days, we need to be careful with interpreting the results for later impacts. It seems that even after 7 days there might still be some impact, so future work should minimize the bias for longer periods, for example, for 14 days rather than 7 days.\n\n__Comparisons between protest groups.__ The results are not very significant. FFF, ALG, and XR cause a statistically significant (at p<0.05) increase in protest-mentioning articles over the course of a week. The increase in other climate change articles is only significant for XR. A significant increase in more dramatic framing is seen for Fridays for Future. These observations are all without adjusting for multiple testing.\n\n__Different datasets.__ The estimates for both the _protest registrations_ dataset and the _protest reports_ dataset are similar to those for ACLED in the cumulative values (@fig-impact-groups-sources). They differ mainly in that they do not show the same salient spike in protest-related coverage on and close to the protest date that the ACLED estimates show (@fig-impact-dataset). ACLED is the only dataset to cover protests by _Letzte Generation_ (ALG) (because they take place only from 2022 and because they are overwhelmingly not registered), and the other datasets have a heavier focus on _Fridays for Future_ (FFF); this may or may not explain some of the differences.\n\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nConclusions answer the research questions and are sharply defined.\n\nArguing on societal implications and recommendations (if applicable):\nManagerial/societal recommendations are well-derived from findings, original and actionable.\n\n -->\n\n\n## Conclusion\n\nI find the following answers to my research questions:\n\n1. __How well do the methods work and how do they compare to each other?__\n   - The _instrumental variable_ method is not suitable for my setting of measuring the impact of single events because most instruments are very weak, and the only strong instrument clearly fails the placebo checks.\n   - The other three methods -- regression, inverse propensity weighting, and synthetic control -- all reduce bias in comparison to simple correlation.\n     - Based on __propensity scores__, IPW exhibits systematic bias in both types of placebo tests.\n     - __Regression__ shows bias in outcome placebo tests; the bias has weekly patterns, suggesting insufficient interaction modeling that may also involve other variables than only weekdays.\n     - The __synthetic control__ method is relatively unbiased in placebo tests but also shows some weekly bias in outcome placebo tests. It estimates an increase in coverage already before a protest event happens; this is acceptable only if (a) this coverage anticipates the event rather than triggers it, and (b) one accepts a definition of a protest event that includes certain pre-event activity.\n   - Under these conditions and under further limitations discussed in @sec-disc-synth, the synthetic control method gives plausible causal estimates. The other methods give clearly biased results in my setting, but this may be improved.\n\n2. __What is the general ATT and what are the ATTs for the protest groups?__ TODO: fill in the numbers\n<!-- According to the synthetic control method -- which is not clearly valid -- the ATT on cumulative regional newspaper converage in the first week after the protests is 7.XX±X.XX. The ATTs for the individual groups are ... (not significant?) TODO -->\n\n3. __Do protests distract from constructive discussion of the climate crisis?__\n   - According to the synthetic control method -- which is not clearly valid -- the ATT is positive (according to synthetic control) or close to zero (according to regression) for the number of articles that do not mention any protest activity. This suggests that there is no backfiring effect on constructive discussion, but the results are not statistically significant at p=0.05.\n   - This also holds specifically for _Fridays for Future_ and for _Greenpeace_. For _Letzte Generation_ and _Ende Gelände_ the results suggest a non-significant decrease in coverage that does not mention protest articles; further research, for example using full texts, would be necessary to determine whether this distracts from constructive discussion. For _Extinction Rebellion_ there is a significant increase in coverage that does not mention protest activity; if the synthetic control method is valid, this is strong evidence that their protests do not distract from constructive discussion.\n\n### Future work\n\n__Extending the scope of the content.__ The methods can be applied to national newspaper coverage, social media data, or parliamentary speech [see @sec-data-discourse]. Topic models [see @chenHowClimateMovement2023a] can be used to get finer insights into the impact on different topics.\n\n__Improving the causal methods:__\n\n- Causal random forests [@wagerEstimationInferenceHeterogeneous2017] can be used for flexibly modeling interactions.\n- Weak instrumental variable beyond maximum likelihood limited information (LIML) can be investigated, for example Fieller–Anderson–Rubin confidence intervals [@dingFirstCourseCausal2023, ch.21.4, ch. 23.6.3].\n- For the synthetic control method, rolling average estimation can be tried out, as well as fitting for the anticipation effect. The extent of bias from missing data can be estimated using simulations. (See @sec-disc-synth.)\n- The propensity score method can be improved by (a) using dedicated time-series models and (b) using small or large language models for the estimation of propensity scores (see @sec-disc-ps). Problems with the doubly robust method should be investigated in more depth.\n- Double machine learning [@chernozhukovDoubleDebiasedMachine2017] is a promising nonparametric method to improve on both regression and propensity score models, while using ideas from the two-stage least squares instrumental variable method.\n\n### Societal implications\n\nGiven my methods, it is not possible to obtain results that are clearly unbiased. The estimates by the synthetic control method are probably least biased. They weakly suggest that it is generally _not_ the case that protests backfire by distracting from the climate discourse and by instead focusing the discourse on the protests themselves. This implies that protests may indeed be a suitable tool for drawing attention to the topic matter of the concern -- at least in the case of climate protests in Germany from 2020-2022, with the possible exception of specific protest groups. The results also suggest that the various protest groups have very different effects on media coverage. Improving the causal methods may help to make less biased and more significant statements about these issues.\n\nIt should be noted that the results apply to _regional_ newspaper coverage due to methodical reasons, but the focus of many protest groups may be on _national_ newspaper coverage.\n\nA more concrete result is that naive media impact evaluation evaluation methods do not work:\n\n- Only counting the number of articles that explicitly mention a protest event or protest group ignores the impact on the articles that do not do so, and this impact may be substantial -- positively or negatively.\n- A correlation-based analysis is highly biased, and even an optimized regression analysis is somewhat biased. This applies to the absolute numbers as well as to comparisons between different topics, and potentially between different protest groups.\n- Even the best causal method used here exhibits many methodical flaws, but there is a lot of potential for improvement in future work.\n\nProtest groups and funding bodies that care about quantitative media impact evaluation should therefore invest into the advancement of causal methods and their application to protest events.\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n<!-- \\setcounter{section}{0}\n\\renewcommand{\\thesection}{\\Alph{section}}\n\n\\setcounter{table}{0}\n\\renewcommand{\\thetable}{A\\arabic{table}}\n\n\\setcounter{figure}{0}\n\\renewcommand{\\thefigure}{A\\arabic{figure}} -->\n\n\\appendix\n\n## Supplementary tables and figures\n\n### Data\n\n#### The German protest registrations dataset\n\n\n\n:::{.column-page}\n\\begingroup\n\\scriptsize\\selectfont\n\\csvautobooktabular[separator=semicolon,respect sharp=true]{/Users/david/Repositories/protest-impact/report/tables/gpreg-overview.csv}\n\\endgroup\n:::\n\nTable: Overview of the German Protest Registrations (GPReg) dataset. _kpop_ = population in 1000; _cap?_ = whether the city is the political capital of its region; _reg?_ = whether the number of registered protesters (as per the organizers) is available; _obs?_ = whether the number of observed protesters (as per the police) is available; _incl?_ = whether the data is used in this thesis.\n\n#### Queries for retrieving article counts {#sec-app-queries}\n\n\n\n:::{.column-page}\n\\begingroup\n\\footnotesize\\selectfont\n\\csvautobooktabular[separator=comma,respect all]{/Users/david/Repositories/protest-impact/report/tables/queries.csv}\n\\endgroup\n:::\n\nTable: Queries for retrieving article counts from online and print newspapers. The words for each category are joined by `OR` operators, and the resulting sub-queries are further combined as described in @sec-data-discourse. The query for the protest events is adapted from @wiedemannGeneralizedApproachProtest2022.\n\n### Results\n\n#### Regression {#sec-app1-reg}\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=33}\n\n::: {#fig-reg-details .cell-output .cell-output-display}\n```{=html}\n<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>    <td>media_combined_all</td> <th>  R-squared:         </th> <td>   0.858</td> \n</tr>\n<tr>\n  <th>Model:</th>                    <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.857</td> \n</tr>\n<tr>\n  <th>Method:</th>              <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   378.8</td> \n</tr>\n<tr>\n  <th>Date:</th>              <td>Sat, 26 Aug 2023</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n</tr>\n<tr>\n  <th>Time:</th>                  <td>09:15:28</td>      <th>  Log-Likelihood:    </th> <td> -72467.</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>       <td> 14196</td>       <th>  AIC:               </th> <td>1.451e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>           <td> 14127</td>       <th>  BIC:               </th> <td>1.456e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>               <td>    68</td>       <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>          <td>HC3</td>        <th>                     </th>     <td> </td>    \n</tr>\n</table>\n```\n\nDetailed results for the best regression model from @sec-res-reg. Dependent variable is the absolute number of articles mentioning climate change from the treatment date and the following day. Due to including time series lags there are overall 140 parameters plus a constant term, so only the 20 parameters with lowest p-values are displayed. Note that for the weekday dummies the first value (Friday) is dropped and the other dummies are to be interpreted in relation to it.\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=34}\n\n::: {.cell-output .cell-output-display}\n```{=tex}\n\\begin{tabular}{lrrrrrr}\n\\toprule\n{} &     coef &  std err &       z &  P>|z| &  [0.025 &  0.975] \\\\\n\\midrule\nconst                    &  -7.1477 &    0.921 &  -7.762 &  0.000 &  -8.952 &  -5.343 \\\\\nholiday\\_lag-1            &   9.2647 &    2.058 &   4.502 &  0.000 &   5.232 &  13.298 \\\\\nholiday\\_lag-2            &  11.5218 &    2.245 &   5.133 &  0.000 &   7.122 &  15.921 \\\\\nholiday\\_lag-3            &  14.5905 &    1.906 &   7.656 &  0.000 &  10.855 &  18.326 \\\\\nholiday\\_lag0             & -17.4703 &    1.698 & -10.287 &  0.000 & -20.799 & -14.142 \\\\\nmedia\\_combined\\_all\\_lag-1 &   0.4508 &    0.078 &   5.800 &  0.000 &   0.298 &   0.603 \\\\\nmedia\\_combined\\_all\\_lag-2 &   0.6454 &    0.076 &   8.534 &  0.000 &   0.497 &   0.794 \\\\\nmedia\\_combined\\_all\\_lag-3 &   0.8136 &    0.076 &  10.748 &  0.000 &   0.665 &   0.962 \\\\\nmedia\\_online\\_all\\_lag-1   &   1.0335 &    0.110 &   9.429 &  0.000 &   0.819 &   1.248 \\\\\nmedia\\_online\\_all\\_lag-2   &  -0.3820 &    0.113 &  -3.373 &  0.001 &  -0.604 &  -0.160 \\\\\nmedia\\_online\\_all\\_lag-3   &  -0.6009 &    0.112 &  -5.389 &  0.000 &  -0.819 &  -0.382 \\\\\nocc\\_ALG\\_lag-3            & -14.9030 &    4.989 &  -2.987 &  0.003 & -24.681 &  -5.125 \\\\\nocc\\_FFF\\_lag-1            & -14.2897 &    3.331 &  -4.289 &  0.000 & -20.819 &  -7.760 \\\\\nocc\\_FFF\\_lag-3            &  10.7736 &    2.962 &   3.637 &  0.000 &   4.968 &  16.579 \\\\\nocc\\_GP\\_lag-3             &  22.6397 &    8.171 &   2.771 &  0.006 &   6.625 &  38.655 \\\\\nweekday\\_Monday\\_lag0      &  33.5883 &    1.337 &  25.113 &  0.000 &  30.967 &  36.210 \\\\\nweekday\\_Saturday\\_lag0    & -22.8429 &    1.266 & -18.037 &  0.000 & -25.325 & -20.361 \\\\\nweekday\\_Thursday\\_lag0    &  12.2038 &    1.127 &  10.830 &  0.000 &   9.995 &  14.412 \\\\\nweekday\\_Tuesday\\_lag0     &  31.0531 &    1.313 &  23.659 &  0.000 &  28.481 &  33.626 \\\\\nweekday\\_Wednesday\\_lag0   &  33.2546 &    1.322 &  25.162 &  0.000 &  30.664 &  35.845 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nPart 2 of the previous figure (some rendering issue TODO)\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=35}\n\n::: {#fig-reg-details-occ .cell-output .cell-output-display}\n```{=tex}\n\\begin{tabular}{lrrrrrr}\n\\toprule\n{} &     coef &  std err &      z &  P>|z| &  [0.025 &  0.975] \\\\\n\\midrule\nocc\\_ALG\\_lag0               &  12.1733 &    5.532 &  2.200 &  0.028 &   1.330 &  23.016 \\\\\nocc\\_EG\\_lag0                &  -7.5632 &    7.796 & -0.970 &  0.332 & -22.844 &   7.717 \\\\\nocc\\_FFFX\\_lag0              & -13.0696 &    7.516 & -1.739 &  0.082 & -27.801 &   1.662 \\\\\nocc\\_FFF\\_lag0               &   4.2447 &    2.710 &  1.566 &  0.117 &  -1.066 &   9.556 \\\\\nocc\\_GP\\_lag0                &   2.8624 &    8.803 &  0.325 &  0.745 & -14.391 &  20.116 \\\\\nocc\\_OTHER\\_CLIMATE\\_ORG\\_lag0 &  10.7346 &    5.373 &  1.998 &  0.046 &   0.203 &  21.266 \\\\\nocc\\_XR\\_lag0                &   3.5265 &    4.240 &  0.832 &  0.406 &  -4.784 &  11.836 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nDetailed results for the best regression model from @sec-res-reg: Coefficients for the occurrence of a protest.\n:::\n:::\n\n\n\\endgroup\n\n#### Impact estimates for the other datasets\n\n::: {.cell .column-page execution_count=36}\n\n::: {.cell-output .cell-output-display}\n![Causal impact estimates on the _German protest registrations_ dataset by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-impact-ts-gpreg-output-1.svg){#fig-impact-ts-gpreg}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=37}\n\n::: {.cell-output .cell-output-display}\n![Causal impact estimates on the _German protest reports_ dataset by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-impact-ts-gprep-output-1.svg){#fig-impact-ts-gprep}\n:::\n:::\n\n\n{{< pagebreak >}}\n\n\n\n## Theory {#sec-app2}\n\nI want to determine the _Average Treatment Effect on the Treated (ATT)_ $\\tau_T$ for different protest groups[^CATT], and along multiple dimensions of newspaper coverage. I am not interested in the _Average Treatment Effect_ [on the whole population] that is often denoted by $\\tau$, so I write $\\tau:=\\tau_T$.\n\n[^CATT]: This could also be framed as the _Conditional ATT_ (CATT), because the treatment effect is conditional on which group has protested on the day. I prefer to frame it as multiple separate ATTs. This has the benefit that I can control (where the methods allows for it) for the occurrence of other treatments on the same day, and thus better isolate the effects of single protest groups.\n\nThe ATT is generally defined as follows [@dingFirstCourseCausal2023, ch. 13]:\n\n$$\n\\tau = E(Y|W=1) - E(Y(0) | W=1)\n$$\n\nThe treatment units are _days_, with a treatment vector $W = [W_1, ..., W_m], m = |G|$ containing the treatments for each group (that is, whether the given group has protested on that day), and an outcome vector $Y = [Y_1, ..., Y_n], n=|Y|$ containing the number of articles published on that day for each dimension of coverage. We can write this as follows:\n\n$$\n\\tau_{g,d} = E(Y_d|W_g=1) - E(Y_d(0) | W_g=1)\n$$\n\n### Regression {#sec-app2-reg}\n\nThe following assumptions allow us to use regression to determine the ATT:\n\n- __Unconfoundedness__, $W \\perp\\!\\!\\!\\perp Y(0) | X$: The counterfactual outcome if there was no treatment is independent from the actual treatment. It is not plausible that this assumption actually holds, but regression will just serve as a baseline model. This is also known as _ignorability_, _selection on observables_, or _conditional independence_.\n- __Overlap__, $e(X) < 1$ for the propensity score $e(X) = P(W=1|X)$: The treatment assignment is not deterministic.\n\nUnder these assumptions, we can identify $\\tau$ as follows [see @dingFirstCourseCausal2023, ch. 13 for proof]:\n\n$$\n\\begin{aligned}\n\\tau &= E(Y|W=1) - E(Y(0)|W=1) \\\\\n&= E(Y|W=1) - E(E(Y|W=0,X) | W=1)\n\\end{aligned}\n$$ {#eq-reg-indent}\n\nWe can specify a linear model for the expected outcome:\n\n$$\nE(Y|W,X) = \\beta + \\beta_W W + \\beta_X X\n$$ {#eq-reg-lin-model}\n\nWe can use @eq-reg-lin-model in @eq-reg-indent:\n\n$$\n\\begin{aligned}\n\\tau &= E(Y|W=1) - E(E(Y|W=0,X) | W=1) \\\\\n&= E(E(Y|W,X)|W=1) - E(E(Y|W=0,X) | W=1) \\\\\n&= E(\\beta + \\beta_W + \\beta_X X |W=1) - E(\\beta + \\beta_X X | W=1) \\\\\n&= \\beta_W\n\\end{aligned}\n$$ {#eq-reg-beta}\n\nThe coefficient $\\beta_W$ can be estimated via _Ordinary Least Squares_ (OLS) regression, and then serve as estimate for the ATT. Specifically, the linear regression model\n\n$$\nE(Y_d|W_g,X) = \\beta + \\beta_W W_g + \\beta_X X\n$$\n\nallows for the estimation of the ATT $\\hat\\tau_{g,d}=\\hat\\beta_W$ for all protest groups $g \\in G$ and outcome dimensions $d \\in D$. Standard errors and confidence intervals can also be obtained from the OLS procedure. The ATT is here identical to the ATE, because \"the linear model assumes constant causal effects across units\" [@dingFirstCourseCausal2023, p. 165].\n\n### Instrumental variables {#sec-app2-iv}\n\nThere are three conditions that make a variable $Z$ a valid instrument [@dingFirstCourseCausal2023, p. 279]:\n\n1. $Z$ is a random or almost random.\n2. $Z$ changes the distribution of the treatment $W$.\n3. $Z$ does not directly influence $Y$, but only indirectly via $W$ (_exclusion restriction_).\n\n#### Indirect least squares {#sec-app2-iv-ils}\n\nIn the case of a single instrument and a single treatment, we can use indirect least squares [@dingFirstCourseCausal2023, ch. 23.6.2; @pischkeLabourEconomicsPhD2019, slides on instrumental variables; @facurealvesCausalInferenceBrave2022, ch. 8]. It is also known simply as _instrumental variable_ method, and -- modified for the special case of a binary instrument -- as _Wald estimator_ [@dingFirstCourseCausal2023, ch. 21].\n\nTo estimate the ATT, we can set up the following linear model (sometimes designated as _structural equation_):\n\n\\begin{align}\nE(Y|W,U) &= \\beta + \\beta_W W + \\beta_U U && \\text{Structural equation} \\label{eqstruct}\n\\end{align}\n\nThis is very similar to @eq-reg-lin-model, only that now the unmeasured confounders are included rather than the known covariates. (We can leave out the known confounders X from the model without loss of generality, because when we do not include them they will also be unknown confounders, and can thus be treated as pasrt of the unknown confounders U.)\n\n@eq-reg-beta identifies the ATT as $\\tau=\\beta_W$ and is also applicable here. The assumptions are unconfoundedness and overlap (see @sec-app2-reg). In the context of regression, we have dealt with unconfoundedness given the known confounders $W \\perp\\!\\!\\!\\perp Y(0) | X$ which is implausible due to potential hidden confounders; but the equation here is not about $X$ but about $U$, so the analogous assumption is $W \\perp\\!\\!\\!\\perp Y(0) | U$, that is, unconfoundedness _given the unknown confounders_, which trivially applies.\n\nIn addition to the structural equation, we can set up two further equations that describe the impact of the instrument Z on both W and Y:\n\n\\begin{align}\nE(W|Z,U) &= \\alpha + \\alpha_Z Z + \\alpha_U U && \\text{First stage} \\\\\nE(Y|Z,U) &= \\gamma + \\gamma_Z Z + \\gamma_U U && \\text{Reduced form}\n\\end{align}\n\nThe randomization assumption implies that the instrument is not correlated with any variables that are not causally affected by the instrument. The exclusion restriction formulates that there is no path from $Z$ to $Y$ other than through $W$. Together, they imply that $Z$ is independent from $U$ in both equations. Since $Z$ is independent from the other predictor variables, the calculation of the coefficients $\\alpha_Z$ and $\\gamma_Z$ resolves to the simpler case of univariate OLS, where we have $\\alpha_Z=\\frac{Cov(W,Z)}{Var(Z)}$ and $\\gamma_Z=\\frac{Cov(Y,Z)}{Var(Z)}$:\n\n\\begin{align}\nE(W|Z,U) &= \\alpha + \\frac{Cov(W,Z)}{Var(Z)} Z + \\alpha_U U && \\text{First stage} \\\\\nE(Y|Z,U) &= \\gamma + \\frac{Cov(Y,Z)}{Var(Z)} Z + \\gamma_U U && \\text{Reduced form} \\label{eqreduced}\n\\end{align}\n\nSubstitution and reordering shows how $\\beta_W$ can be calculated from the covariances:\n\n\\begin{align}\nE(Y|Z,U) &= \\gamma + \\frac{Cov(Z,\\beta + \\beta_W W + \\beta_U U)}{Var(Z)} Z + \\gamma_U U && \\text{Substitute \\eqref{eqstruct} into \\eqref{eqreduced}} \\\\\n&= \\gamma + \\beta_W \\frac{Cov(Z, W)}{Var(Z)} Z + \\gamma_U U \\label{eqresult} \\\\\n0 &= \\beta_W \\frac{Cov(W,Z)}{Var(Z)} Z - \\frac{Cov(Y,Z)}{Var(Z)} Z && \\text{Subtract \\eqref{eqresult} from \\eqref{eqreduced}} \\\\\n&= (\\beta_W Cov(Z,W) - Cov(Y,Z)) \\frac{Z}{Var{Z}} \\\\\n&= (\\beta_W Cov(Z,W) - Cov(Y,Z)) \\\\\n\\beta_W &= \\frac{Cov(Y,Z)}{Cov(Z,W)}\n\\end{align}\n\nIn @eq-reg-beta we had a regression model of the same structure, and showed that the ATT can be estimated by the coefficient for the treatment, so we have:\n\n\\begin{align}\n\\tau_{g,d}=\\frac{Cov(Y_d,Z)}{Cov(Z,W_g)}\n\\end{align}\n\nA corresponding estimator is given using the sample covariances. Estimators for the variance are deduced in @dingFirstCourseCausal2023 [ch. 21].\n\nImpressively, the instrument allows us to control for confounders without needing to specify them -- if the strong assumptions of randomization and exclusion actually hold.\n\n#### Two-stage least squares {#sec-app2-2sls}\n\nAn alternative to indirect least squares that extends to multiple instruments and treatments is the _two-stage least squares_ (TSLS) estimator. It involves two OLS regression steps:\n\n1. Estimate $E(W|Z) = \\alpha + \\alpha_Z Z$ and obtain predictions $\\hat W$. These are the \"random components\" of $W$.\n2. Estimate $E(Y,\\hat W) = \\beta + \\beta_W \\hat W$, and obtain the causal estimate $\\hat\\tau = \\hat\\beta_W$.\n\nIn the case of a single instrument and a single treatment, two-stage least squares is identical to indirect least squares [@dingFirstCourseCausal2023, ch. 23].\n\n__Including covariates:__ Instrumental variable methods do not generally require the specification of any covariates or confounders. In the case that randomization holds only conditionally, we need to control for all covariates conditional to which the instrument is random. Besides this, adding covariates may also be useful for reducing variance and increasing statistical power. @torgovitskyWhenTSLSActually point out that adding covariates causes the estimate to differ from the LATE, which poses a problem that has often been ignored in practice.\n\n__Weak instrumental variables:__ When the instruments are weak, indirect and two-stage least squares become biased. There are adaptations specifically for weak instruments. Instead of indirect least squares, the _Weak IV_ estimator can be used [@dingFirstCourseCausal2023, ch. 21 & 23]; and an alternative to two-stage least squares is _limited information maximum likelihood_ [LIML; see @pischkeLabourEconomicsPhD2019, slides on weak instruments].\n\n#### Local treatment effects\n\nA subtlety is that all of the above methods do not actually give us the ATT or ATE, but rather the _Local_ Average Treatment Effect LATE, that is, the effect of those days where the instrument actually had an impact on the outcome. This can be intuitively explained by deducing the estimator from the notions of _compliers_, _defiers_, _always-takers_, and _never-takers_: Using the example of rainfall as a binary instrument for protest days, we have\n\n- _always-takers_: days where there would be a protest, regardless of rainfall;\n- _never-takers_: days where there would be no protest, regardless of rainfall;\n- _compliers_: days where the rainfall _positively_ determines whether there is a protest:\n  - non-rainy days with protests that would not have occurred if there had been rainfall and\n  - rainy days without protests where without rainfall there would have been protests;\n- _defiers_: days where the rainfall _negatively_ determines whether there is a protest. This is often implausible (also in our context) and therefore it is assumed that there are no defiers.\n\nIt can be proven that indirect least squares and other instrumental variable methods only estimate the treatment effect for the group of compliers [@dingFirstCourseCausal2023, ch. 21; @pischkeLabourEconomicsPhD2019, slides on the LATE theorem; @facurealvesCausalInferenceBrave2022, ch. 9].\n<!-- In the deduction above, this assumption is implicit in the form of the regression model (TODO: is it?), where $Z$ is assumed to have a constant effect on $Y$. -->\n\nIn the case of protests, an instrumental variable approach would ignore the effect of protests where the organizers and participants are very weather-resistant. If such protests are systematically more or less effective than the weather-complying protests, this will introduce bias. For Covid restrictions as an instrument, the instrumental variable approach would ignore the effect of protests that violate the restrictions.\n\n<!-- this is reasonably negligible because the climate protest movement is not known to have committed such violations. -->\n\n<!-- manually or https://www.pywhy.org/dowhy/v0.10/dowhy.causal_estimators.html#module-dowhy.causal_estimators.instrumental_variable_estimator -->\n\n### Synthetic control {#sec-app2-synth}\n\nI assume that the outcome of each region $r \\in R$ is given by a _factor model_ [inspired by @abadieSyntheticControlMethods2010]:\n\n$$\nE(Y_r|X_r,W_r,U) = \\beta + \\beta_X X_r + \\beta_W W_r + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_r U^T)_{ij}\n$$\n\nwhere $Y_r$ is the outcome for region $r$, $X_r$ is a vector of known covariates of region $r$, $U$ is a vector of unknown global confounders, and $X_r U^T$ is a $|X_r|\\times |U|$ matrix of interactions between the regional covariates and the unknown global confounders; $\\beta, \\beta_X, \\beta_W, \\beta_U, \\beta_{UX}$ are global parameters of the model (with sizes that correspond to the respective variables) that specify the impact of the variables on the outcome variable; and $\\epsilon_r$ an error term with mean $0$.\n\nThe model allows for time-variant hidden confounders $U$ that are the same across all regions. And through the term $X_r U^T$ it also allows for interactions of the confounders with the regional covariates, including static ones as well as time-variant ones.\n\nThe counterfactual is given by omitting the impact of the treatment:\n\n$$\nE(Y_r(0)|X_r,W_r,U) = \\beta + \\beta_X X_r + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_r U^T)_{ij}\n$$\n\nLet $R_0 = \\{r \\in R|W_r=0\\}$ be the set of control regions. Assume the existence of scalar weights $\\gamma_s$ for all $s \\in R_0$ that allow the interpolation of the covariates of the treatment region from the covariates of the control region:\n\n\\begin{align}\n\\sum_{s \\in R_0} \\gamma_s = 1 \\text{ and } \\gamma_s \\geq 0\\: \\forall s \\in R_0 && \\text{Convexity} \\label{eq-convex} \\\\\nE\\left(\\sum_{s \\in R_0} \\gamma_s X_s\\right) = E(X_r) && \\text{Interpolation} \\label{eq-interpol}\n\\end{align}\n\nThen by interpolating the counterfactual from the control regions we obtain the estimator $\\hat Y_r(0) = \\sum_{s \\in R_0} \\gamma_s Y_s$:\n\n::: {.column-page}\n\\begin{align}\nE(\\hat Y_r(0)) &= E\\left\\{ \\sum_{s \\in R_0} \\gamma_s Y_s \\right\\} \\\\\n&= E\\left\\{ \\sum_{s \\in R_0} \\gamma_s E(Y_s|X_s,W_s,U) \\right\\} \\\\\n&= E\\left\\{ \\sum_{s \\in R_0} \\gamma_s E\\left[\\beta + \\beta_X X_s + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_s U^T)_{ij} \\right] \\right\\} \\\\\n&= E\\left\\{ \\beta + \\beta_X E\\left(\\sum_{s \\in R_0} \\gamma_s  X_s\\right) + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} \\left[E\\left(\\sum_{s \\in R_0} \\gamma_s  X_s\\right) U^T\\right]_{ij} \\right\\} && \\text{by assumption \\eqref{eq-convex}} \\\\\n&= E\\left\\{ \\beta + \\beta_X X_r + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_r U^T)_{ij} \\right\\} && \\text{by assumption \\eqref{eq-interpol}} \\\\\n&= E\\left\\{ Y_r(0) \\right\\}\n\\end{align}\n:::\n\nThe ATT can thus be estimated by:\n\n\\begin{align}\n\\tau_r &= E(Y_r|W=1) - E(Y_r(0)|W=1) \\\\\n&= E(Y|W=1) - E(\\sum_{s \\in R_0} \\gamma_s Y_s|W=1) \\\\\n&= E(Y|W=1) - \\sum_{s \\in R_0} \\gamma_s E(Y_s|W=1)\n\\end{align}\n\nIn this setting it is not straightforward to single out the effect of different protest groups because there is no way to directly control for co-occurring protest events; therefore I only compute the average effect for all groups.\n\nWeights $\\gamma$ can be obtained by \"upside down regression\" [@facurealvesCausalInferenceBrave2022, ch. 15] to estimate $E(X_r)=\\gamma_1 X_1 + ... + \\gamma_n X_n$ for the control regions $1...n=R_0$. In principle, we can use OLS or nonnegative least squares (NLS) for the estimation. However, this allows the model to _extrapolate_ rather than _interpolate_ between the control regions. To estimate weights that interpolate (that is, they are positive and sum up to 1), we can define a loss function $\\left|X_r - \\sum_{s \\in R_0} \\gamma_s X_s\\right|$ and minimize it subject to the positivity and sum constraints on the weights, for example by using quadratic programming as minimization technique [@facurealvesCausalInferenceBrave2022, ch. 15; @abadieSyntheticControlMethods2010].\n\nSince the available control regions vary from day to day, many regressions have to be run. $X_r$ may be chosen to either represent (static) fundamental data about the regions that is suspected to be predictive of treatment or outcome [@abadieSyntheticControlMethods2010]; or it can just be previous time-series information about the outcome and other variables [@facurealvesCausalInferenceBrave2022, ch. 15].\n\n@fermanSyntheticControlsImperfect2021 suggest that demeaning the data based on the pre-treatment period makes the synthetic control method more robust.\n\n### Propensity scores {#sec-app2-ps}\n\nThe propensity score $e(X) = P(W=1|X)$ is the probability of the treatment given the confounding variables. It is often computed using logistic regression, but any machine learning model that produces reasonable probability estimates can be used; this makes it more flexible than linear models.\n\nVarious methods make use of propensity scores, mainly: _Propensity stratification, inverse propensity weighting, and propensity matching_. Propensity stratification requires the specification of a hyperparameter $k$ for the number of strata, with no reliable methods available for making a suitable choice [@dingFirstCourseCausal2023, ch. 11]. Propensity matching is very intuitive but also very problematic because it is usually not possible to establish a perfect matching between treated and control units, and any matching method introduces imbalance, so that the imbalance may even be increased rather than reduced [@kingWhyPropensityScores2019]. Therefore I focus on inverse propensity weighting.\n\n#### Inverse propensity weighting {#sec-app2-ipw}\n\nInverse propensity weighting (IPW) gives every sample a weight that is inverse to the propensity score: $\\frac{1}{e(X)}$ for treated units and $\\frac{1}{1-e(X)}$ for control units. We use the same assumptions as for regression (@sec-app2-reg):\n\n- __Unconfoundedness__, $W \\perp\\!\\!\\!\\perp Y(0) | X$: The counterfactual outcome if there was no treatment is independent from the actual treatment. (For @eq-prop we need the same not only for $Y(0)$ but also for $Y(1)$; but the calculation of the _ATT_ does not require this.)\n- __Overlap__, $e(X) < 1$: The treatment assignment is not deterministic.\n\nThen we can see that propensity weighting reveals the counterfactual outcome [@barterRebeccaBarterIntuition2017; @dingFirstCourseCausal2023, ch. 11]:\n\n$$\n\\begin{aligned}\nE\\left(\\frac{WY}{e(X)}\\right) &= E\\left[E\\left(\\frac{WY}{e(X)}|X\\right)\\right] \\\\\n&= E\\left[E\\left(\\frac{WY(1)}{e(X)}|X\\right)\\right] \\\\\n&= E\\left[\\frac{E(W|X)E(Y(1)|X)}{e(X)}\\right] && \\text{due to unconfoundedness} \\\\\n&= E\\left[\\frac{P(W=1|X)E(Y(1)|X)}{e(X)}\\right] && \\text{because W is binary} \\\\\n&= E\\left[\\frac{e(X)Y(1)}{e(X)}\\right] \\\\\n&= E(Y(1))\n\\end{aligned}\n$$ {#eq-prop}\n\nAnalogously we have $E(\\frac{(1-W)Y}{1-e(X)}) = E(Y(0))$. We can extend this for the counterfactual of the treated units $E(Y(0)|W=1) = E\\left(\\frac{e(X)}{P(W=1)}\\frac{(1-W)Y}{1-e(X)}\\right)$, see @dingFirstCourseCausal2023 [p. 166] for the proof.\n\nThis gives us an estimator for the ATT:\n\n$$\n\\begin{aligned}\n\\tau &= E(Y|W=1) - E(Y(0)|W=1) \\\\\n&= \\hat{\\bar{Y}}(1) - \\frac{1}{n} \\sum_{i=1}^{n} \\frac{e(X_i)}{P(W_i=1)}\\frac{(1-W_i)Y_i}{1-e(X_i)}\n\\end{aligned}\n$$ {#eq-prop-est}\n\nThe estimator from @eq-prop-est is reported to have various problems in practice, therefore I use the alternative _Hájek estimator_, which is empirically more stable [@dingFirstCourseCausal2023, pp. 146, 166; @abdiaPropensityScoresBased2017]:\n\n$$\n\\tau^{\\text{Hájek}} = \\hat{\\bar{Y}}(1) - \\frac{1}{n} \\frac{\\sum_{i=1}^{n}\\frac{e(X_i)}{P(W_i=1)}\\frac{(1-W_i)Y_i}{1-e(X_i)}}{\\sum_{i=1}^{n}\\frac{e(X_i)}{P(W_i=1)}\\frac{(1-W_i)}{1-e(X_i)}}\n$$\n\n#### Doubly robust estimation {#sec-app2-dre}\n\nBoth regression (@sec-app2-reg) and IPW rely on the same assumptions of overlap and conditional unconfoundedness. They can be combined into a single estimator known as _augmented inverse propensity weighting_ or as the _doubly robust estimator_. It is consistent if at least one of the models is correctly specified -- that is, if either the treatment or the outcome is consistently estimated. If both models are correct, then it helps reducing the bias of the regression estimator, and reducing the variance of the propensity score estimator.\n\nDoubly robust estimation is defined, motivated, and proven in @dingFirstCourseCausal2023 [ch. 12, ch. 13.2].\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n\\renewcommand{\\thesection}{}\n\n## References\n\n<!--\n\nReferences and bibliography cover all relevant publications and state-of-the-art. Citing is done at appropriate points in the text.\n\n -->\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "report_files"
    ],
    "filters": []
  }
}
