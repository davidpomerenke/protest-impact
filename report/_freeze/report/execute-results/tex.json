{
  "hash": "7cb776fb973a121ac06e4ce8cac8cbd1",
  "result": {
    "markdown": "---\nsubtitle: Investigating the causal impact of protest events on newspaper coverage of the protest concern\nauthor: David Pomerenke\ntoc: true\ntoc-depth: 3\ntitle: Do climate protests lead to more attention to the climate crisis?\n---\n\n\n\n\n\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nThe difference between the goals and/or context of the thesis with existing solutions (e.g. found in literature) were studied and clearly described to support the problem definition, clearly indicating the innovative part of the thesis task.\n\nthe introduction defines the problem, sets it in terms of the state-of-the-art and clearly indicates what the contribution of the thesis is\n\n -->\n\n## Introduction\n\n### Problem statement\n\n__Research questions.__ ... lack of structured data (timewise and detailwise and biaswise) ... following research questions:\n\n<!--\n\nAt least three research questions are present and relevant.\n+ research questions are well-positioned in the research context.\n+ research questions are well-positioned in the literature.\n\n -->\n\n- q1\n- q2\n- q3\n\n\n---\n\nThis master thesis aims to find out whether, and to what extent, climate protests succeed in bringing more attention to the climate crisis, as measured by the amount of newspaper coverage that they and their topic receive. While I focus on climate protests in Germany, the methods that I use, and also a large part of the data sources that I use, are also transferable to other protest movements, not only those concerning the climate.\n\nSince this is a thesis in artificial intelligence, I focus on applying, evaluating, and comparing multiple causal inference methods, that all try to answer the research question from different assumptions and methodical perspectives.\n\n---\n\nThis poses the problem of confounding, that is, common causes of both newspaper attention and protest events: If, for example, extreme weather leads to more newspaper coverage on the one hand, and makes people more prone to protest, then it may seem as if the protest leads to more newspaper coverage, but it may not actually be the case. Other candidates for confounders include prior newspaper coverage and prior protest events themselves, as well as external events such as climate conferences, or the passing of laws. Due to these confounders, naively looking at the relationship between protests and discourse may give a biased impression, and causal inference techniques are required.\n\nI want to compare multiple causal methods and see what they can tell us about the impact of protests. My research questions are:\n\n1. Can the causal methods -- instrumental variable, synthetic control, and propensity score methods -- be applied to study the impact of protest events on newspaper attention? What limitations apply, and what problems occur? Are the estimates consistent, and how do they differ from each other and from simple regression estimates?\n\n2. What is the _Average Treatment Effect on the Treated_[^ATT] (ATT) of protest events on newspaper coverage, for climate protests in general, and with respect to the protest group that organizes the protest?\n\n3. What can we say about the hypothesis that climate protests _distract_ from discussing solutions to the climate crisis constructively?\n\n[^ATT]: The _Average Treatment Effect on the Treated_ (ATT) is the effect that the protests that took place have actually caused, on average, in comparison to the case that they had not taken place. It differs from the _Average Treatment Effect_ (ATE) by focusing on the treated units rather than the whole population.\n\n---\n\n<!-- Citizens in democracies have an interest in understanding the effectiveness of protest movements, and which factors make them effective.\n\nProtests play a _crucial role_ in democracies, complementing the sometimes insufficient institutional participation. Large protest movements are known to have brought about progress that we nowadays take as indispensable, especially in the areas of civil rights and women's rights.\n\nYet, the different forms of protest have always caused and do still cause _controversy_: Are they an appropriate means to achieve their respective goal? Should they be less radical, or perhaps more so, in order to effectively achieve that goal? There are three levels on which such questions may be of interest.\n\n1.  The __general public__ wants to know what to think of protests. Especially persons who support the goal of the protest may wish to know whether they should endorse the protest; or oppose it and advocate for alternative means to achieve that goal. Opponents of the goal may wish to denounce the protest not only on the content-level, but also by claiming that the protest is an inappropriate way to achieve that goal. Supporters may then wish to prove them wrong by referring to evidence that proves the potential effectiveness of protesting.\n\n    Making a scientific investigation in this context is a bit weird, because the result may just perpetuate existing beliefs. If one finds that protests are effective, this may increase their support and thereby make them more effective; while a negative statement may weaken their result and their effectiveness. At the same time, any scientific result may be impacted in large part by the prevailing beliefs about the effectiveness of protest. Research on this topic should therefore at least make sure that it does not implicitly aim to increase or decrease the support for protests, and should keep in mind that existing beliefs may be an important factor impacting the effectiveness of protests.\n\n2.  __Protest supporters__ want to know which organizations they should support. Grassroots movements depend on funding, be it from individuals, from intermediary funds, or from philanthropists. These parties want to invest their donations efficiently, and can often choose from a pool of organizations that aim at similar goals with differing methods. The question of cost-effectiveness arises, and while cost is easy to count, effectiveness is very hard to estimate. Existing organizations use proxy measures including the number of press articles about the protest movement, which may not be ideal. Besides comparing different organizations, donors may also wish to compare protests with alternative methods such as lobbyism or individual action.\n\ndeeply strategic: [@englerThisUprisingHow2016]\n\n@knuthFinanzierungKlimaaktivismusAm2023\n\n1.  __Protest organizations__ themselves want to know how they can best achieve their goals. They regularly plan new activities and need to decide on strategical points, such as:\n    -  Who do they want to address? (e. g., politicians, businesses, or the media)\n    -  How radical should they be? (e. g., whether they should respect the boundaries of public goodwill, of the law, or of nonviolence)\n    -  How much time should they invest into recruiting and marketing activities?\n    -  How much attention should they pay to symbolicism, and to an integral appearance?\n    -  What time periods should they choose? (e. g., whether to go along with external events and media attention waves, or to complement them)\n    -  What places and what timing works best?\n\nAnswering these questions involves looking not only at the _impact_ of protests, but also at the _impact factors_. Here I do not study impact factors in detail, but I do compare the impacts of various climate protest movements, which may allow some inferences about strategy; and may enable further research about impact factors. -->\n\n__Protest event analysis.__\n\n<!-- Copy from below: Newspaper articles are primarily used in the existing literature. [@hutterProtestEventAnalysis2014] give a historical and systematic overview and highlight the problem that this source is biased. They describe how several definitions for protest event analysis (PEA) and the broader political claim analysis (PCA), as well as associated coding practices have helped to formalize the (manual) data extraction process, such that results have become more valid and comparable. -->\n\n__Protest impact.__\n\nResearch into the impact of protest movements has recently been spearheaded by a series of literature reviews and expert interviews by Ozden and Glover. In the context of effective altruism, they aim to assess how effective protest movements are as a means for political change, and what factors determine their success. In their literature review on protest outcomes @jamesozdenLiteratureReviewProtest2022, they conclude that _causal inferences on protest outcomes are generally challenging to draw due to confounding, and it is even harder to determine the long-term effect_. They warn that the average effect size of protests is likely over-estimated in the existing literature, due to selection bias on the level of media coverage, researcher interest, and statistical significance (publication bias). Based on their review, they estimate that protest movements (consisting of many single protest events) may raise salience and support for the issue by 2-10%, and may influence voting behavior by 1-6 percentage points. The influence on public discourse may be high in certain cases, and in the case of the Black Lives Matter movement may have amplified coverage by a factor of 10.\n\nIn interviews with researchers, @jamesozdenExpertInterviewsProtest2022 establish that while there is much research on protest outcomes, the causal connections between protests and their outcomes are an underexplored research area (interview with Robyn Gulliver in the cited report); that a causal link between protests and certain outcomes is plausible, but hard to attribute to any specific protest group (interview with Ruud Wouters in the cited report); and that causal effects are typically only measurable only on a local level due to the lack of a control group at the national level. More generally, protest outcomes may be subject to confounding, and the causal arrow between protests and increased concern may point in either direction. The interviews with researchers, as well as interviews with UK policymakers [@jamesozdenPolicymakerInterviewsProtest2022], suggest that the causal effect of protest on policy is strongly if not completely mediated by public opinion.\n\nIn a follow-up, [@samgloverLiteratureReviewProtest2022; @jamesozdenWhatMakesProtest2023] review the factors that causally affect the success of protest movements. They attribute a high importance to the number of participants, and to the nonviolent nature of the protest, as well as a favourable sociopolitical context, including media coverage. A moderate effect is attributed to the diversity and the unity of the movement. They also look at the so-called _radical flank effect_, a theory that moderate movements benefit from the simultaneous presence of a more radical movement for the same issue. Their review finds moderate effects from a radical flank, but only if the radical flank is also nonviolent.\n\n__Relevance of newspaper coverage__ as an impact proxy\n\nThere are multiple potential proxies for policy decisions: Election outcomes, public opinion measured by polling, and features of various levels of public discourse.\n\nWithin public discourse, there is a gradual tradeoff of media that is close to the legislative process, and media that is close to current affairs such as protest events. Parliamentary debate accompanies legislation. Parliamentary questions have fewer impact on policy, but may reveal what politicians are concerned about. Political debates outside the parliament, such as talk shows on television, may be even more responsive to current affairs. National newspapers and magazines drive political discourse forward in smaller steps, and are in turn influenced by the reports and discussions emerging from local newspapers. They report on real-world events, and on press agency releases, and on issues that are reported and discussed by Twitter users.\n\n![Observable layers of public discourse. Adapted from a graphic from Stewart Brand [via @branderLayeredProtocols2022].](figures/discourse-layering.png){.column-margin #fig-wheel}\n\nThe end of this ladder of discourse -- compare @fig-wheel -- is very remote from having influence on policy; but it has the benefit that data is available on a much grander scale and frequency, which facilitates big data analyses (see @fig-lamppost).\n\n![\"Looking under the lamppost\" by [Sketchplanations](https://sketchplanations.com/) (CC-BY-NC)](figures/lamppost.png){.column-margin #fig-lamppost}\n\n__Causal impact evaluation.__\n\n<!--\n\nResearch has advanced state of the art. Described thesis research would lead to a publication in an international peer-reviewed journal or an international peer-reviewed conference.\n\n -->\n\n__Contribution.__\n\n<!--\n\nThe research itself is very theoretical or highly interdisciplinary requiring the student to read into both challenging and theoretical material well beyond the scope of the programme.\n+ this attitude is constructive and well-balanced.\n\n -->\n\n- IV for single events\n- SC for many single events\n- PS for texts\n- automated dataset\n- complete dataset\n\n### Literature review\n\n#### Impact of protests on newspaper coverage\n\n<!--\nThe \"protest paradigm\" [@mcleodManufacturePublicOpinion1992] theorizes that news coverage of protesters tends to be a double-edged sword, because the coverage of protests that challenge the status quo is usually negative. This paradigm is recently being challenged, and the formation of amore nuanced theory is underway that considers under what conditions the protest paradigm does or does not hold [see @harlowNewProtestParadigm2023].\n\n@schwartzParadoxConfrontationExperimental2016: protests themselves have a negative impact on public support, but media coverage has a positive impact\n\n@cristanchoProtestersNewsGates2022 investigate experimentally how different features of protests as well as of journalists have an impact on the prominence of the protests in the news (measured by front-page placement), finding that protest size is the most important feature\n\n@hellmeierSpotlightAnalyzingSequential2018 find support for their hypothesis that salient protest events that receive a lot of media coverage lead to a higher coverage of subsequent protest events, and that the effect decreases with spatial and temporal distance.\n\ncite Teune, Wasow, maybe Repke\n\n@barrieDoesProtestInfluence: time series effects on tweets by uk mps, recent and very nice (not strictly causal, but really plausible; or could perhaps consider it a discontinuity design)\n\n@chenHowClimateMovement2023a analyze the coverage of the climate movement on Twitter as well as in online newspapers. They use topic modelling to find major themes in discourse, and plot the quantitative evolution of these themes over time from 2018 to 2021, overlaying it with information about the occurrence of the semi-annual global climate strikes.\n\n@AttentionClimateChange2023 find that the Covid-19 pandemic has led to a fewer discussion of climate protests on Twitter, albeit not to fewer discussion of the climate crisis itself.\n-->\n\n#### Causal approaches to protest event analysis {#sec-weatherlit}\n\nIn the context of protest event analysis, the most commonly used methods are: regression with an extensive set of control variables; and the instrumental variable method using rainfall as an instrument.\n<!-- and _difference in differences_, which is conceptually similar to the synthetic control method. -->\nTo my best knowledge, the synthetic control method and propensity score methods with text have not previously been applied to protest event analysis.\n\n---\n\nAmong the protest effects literature that employs causal methods, the instrumental variable method is the most commonly used method. Usually, rainfall over a period ranging from one day up to one month is used to estimate the effect of protests during that timeframe on a later outcome, where a direct influence of the weather is very unlikely. With the exception of @huet-vaughnQuietRiotCausal2013, all previous literature has a setting where they look at a fixed timeframe and compare effects across regional units. Only Huet-Vaughn (2013) have a methodical approach that is more similar to mine, looking at a larger dataset where events are scattered across regions and also across time.\n\n- @collinsEconomicAftermath1960s2007 use rainfall and local political structure as instruments to investigate the effect of riot severity on the later development of property values. They use rainfall in the month following the assassination of Martin Luther King, during which many protests occurred across the US, as an instrumental variable.\n\n- @madestamPoliticalProtestsMatter2013 use rainfall as an instrumental variable to measure the effect of Tea Party rallies on votes for the Republican Party in the US. They use rainfall on a single important day of Tea Party rallies across counties in the US to measure the effect of additional protesters on Republican Party vote share half a year later, finding that an additional protester leads to way more additional votes than just a single one. They also measure the effect on newspaper coverage of the Tea Party, and find increased attention especially during later important Tea Party events. They operationalize rainfall as a dummy variable of whether there were at least 0.1 inches (2.5 mm) of rainfall.\n\n- @huet-vaughnQuietRiotCausal2013 investigate the effect of protest violence on protest \"success\" across 15 years of single (potentially multi-day) protest events in France, using precipitation and temperature as instrumental variables. They operationalize precipitation as a dummy variable representing whether there was some precipitation during any day of a series of protest days, and temperature as a dummy variable about whether the maximum temperature during these days falls in the range of 60-75° Fahrenheit (16-24° Celsius), which is derived from studies about the effect of temperature on disorderly conduct.\n\n- @negroWhichSideAre2019 are interested in the effect of the size of LGBTQ protests on the presence of \"movement-affiliated organizations\". They use two instrumental variables, the first one measuring whether the precipitation on the protest date exceeds 2.5 mm (as per @madestamPoliticalProtestsMatter2013), and the second one being the average rainfall in the last 10 years on the $\\pm3$-day window around the protest date.^[In my opinion this is a good idea but it should be labeled as a control, not as an instrument. See the next section for discussion.] They find the first instrument to have a statistically significant effect on the protest size ($p<0.01$), but not the second one ($p\\geq 0.05$).\n\n- @wasowAgendaSeedingHow2020 use rainfall in the month following the murder of Martin Luther King to estimate the effect of violent protests on the vote share of the Democratic Party in the US in the elections half a year later. They operationalize rainfall as \"average rainfall in millimeters from weather stations within a 50 mile radius of the county center.\" Using two-stage least-squares regression, they find a significant shift in vote share in predominantly white counties due to protests in the first week after the assassination. They also apply placebo tests using rainfall from the week before the assassination, and from the remainder of the month after the assassination (containing only 5% of the protests from that month), and do not find significant effects for either of them, which strengthens their result.\n\n- @kleinteeselinkWeatherProtestEffect2021 use rainfall as an instrument to determine the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They use rainfall from the two weeks following the murder of George Floyd by the police to measure the effect of the per-county number of total protest attendees during this time window on the election half a year later. (A very similar setting as above.) They use a linear variable to operationalize rainfall. They use the \"probability of rain\" to control for \"general climatic conditions that may correlate with voting-relevant characteristics such as the average age, income, and ethnic composition of a county.\" The operationalization and motivation for this are a bit unclear.^[I find it plausible that the rain forecast may be relevant because the organizers may decide already a few days in advance of the protest whether or not it should take place, and for this decision they cannot rely on the actual weather but merely on the forecast.] Moreover they stress the importance of taking spatial depencies into account, and solve the problem using a spatial weighting matrix. They use demographic control variables (racial composition and median age) as well as economic control variables (median income and unemployment rate) for all regression steps. Placebo tests for first-stage linear regression show that the coefficients for the effect of weather on protest attendance is much lower for time windows before the protests took place, but still highly statistically significant.\n\n- @carenBlackLivesMatter2023 use multiple weather variables, also to estimate the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They operationalize days with _bad weather_ as days with either a maximum temperature above 90° Fahrenheit (32° Celsius), more than 0.1 inches (2.5 mm) of precipitation, or a wind speed of more than 10 mph (16 km/h). As their instrument they use the number of days with bad weather during the month that followed the murder of George Floyd by the police. Their treatment is _protest intensity_, which they define as the inverse hyperbolic sine (which behaves similarly to the logarithm) of the cumulative protest size, divided by the population size of the county. They use a large list of sociodemographic and political variables on the county level as control variables for all regression steps.\n\nTODO: make a neat overview table of the different methodologies.\n\nOther literature uses instruments that are less clearly random, such as whether the protest took place on a Friday, its distance to focal points, the commute time in the city where the protest takes place, or even sociological variables concerning the political structure and efficiency. Arguing that such instruments are valid requires solid expert knowledge (and perhaps insider knowledge), and such instruments are therefore less suitable for a data-driven analysis as I envision it here. (Even the weather variable is not completely free from such problems, unfortunately, as is discussed in the next section.)\n\n__Causes of protests__\n\ncite Seitz\n\n### Causal impact estimation {#intro-causal}\n\nCausality[^invented by Spohn xxxx]\n\nHere I give an overview of the causal model that I generally assume. Then I give an overview of the different causal methods used in this project, how they exploit the causal model, and what additional assumptions they make. Since _time series methods_ may be used in various contexts, I also briefly introduce their structure and show how they can be applied to various machine learning problems that arise as part of the causal methods.\n\n\n\n@fig-causal-graph-simple shows the causal relations between the 5 categories graphically.\n\n\n```{dot}\n// | label: fig-causal-graph-simple\n// | fig-cap: Simple causal graph showing the structure of the research problem, ignoring the time-series aspect. I want to determine the effect of the treatment __W__ on the outcome __Y__, and there are known confounders __X__, but also unknown confounders __U__ that influence both treatment and outcome and thus complicate the matter. Instrumental variables __Z__ may help, because they only affect the outcome via their effect on the treatment.\n// | fig-width: 180px\n// | fig-height: 120px\n// | column: body\n// | fig-pos: 'H'\ndigraph D {\n  rankdir=LR\n  {X, U} -> {W, Y}\n  {Z} -> {W}\n  {W} -> {Y} [color=green]\n}\n```\n\n\nThe core of the model is the relation $W \\rightarrow Y$ that I want to investigate. However, there are multiple problems of increasing difficulty:\n\n1. The outcome __Y__ is affected not only by the treatment but also by the covariates __X__. This is a pretty common situation, even in experiments that are randomized, and we can approach it, for example, by using regression to control for the covariates.\n2. Not only the outcome __Y__, but also the treatment __W__ is affected by the covariates __X__, which makes them _confounders_. This is a common feature of observational studies. We can use methods based on the _propensity score_ (the probability of receiving the treatment) to approach this problem, as long as we know all relevant confounders.\n3. There are likely unknown confounders __U__. We are dealing with a sociological situation where a lot of variables could potentially be relevant. For example, external events like elections, legislative processes, or conferences could play a big role. Or the current mindset and stress level of journalists could play a role. Or many other things, that we may not even think of. Even though we cannot list all of these variables, there are alternative approaches:\n   1. Assuming that the unknown confounders affect all regions similarly, we can make cross-region comparisons, for example, by using the __*synthetic control*__ method.\n   2. We can leverage __*instrumental variables*__ __Z__, for which we assume that they do not affect the outcome __Y__ directly, and trace their effect on __Y__ via the treatment __W__.\n   3. We can assume that certain texts such as press releases may cover many relevant unknown confounders, and learn __*propensity scores from texts*__, without needing to specify the confounders explicitly.\n\nAll three methods can be combined with controlling for known confounders. The following table gives an overview over the methods, which causal inference principles they use, what data they rely on, and whether they are useful for dealing with know and unknown confounders:\n\n:::{.column-body}\n\n\\begin{tabular}{l| c c c c}\n& Regression & Instr. var. & Synth. contr. & Prop. score \\\\\n\\hline\nInstrumenting & & \\bullet &  &  \\\\\nControlling & \\bullet & (\\bullet) & (\\bullet) & (\\bullet) \\\\\nBalancing &  &  & \\bullet & \\bullet \\\\\n\\hline\nTime series & \\bullet & (\\bullet) & (\\bullet) & \\bullet \\\\\nRegions &  &  & \\bullet &  \\\\\nWeather &  & \\bullet &  &  \\\\\nTexts &  &  &  & (\\bullet) \\\\\n\\hline\nConfounders? & $\\checkmark^1$ & $\\checkmark^2$ & $\\checkmark^3$ & $\\checkmark^4$ \\\\\nHidden conf.? &  & $\\checkmark^2$ & $\\checkmark^3$ & $\\checkmark^{4,5}$ \\\\\n\\end{tabular}\n\nCore assumptions:$^1$ Linearity;$^2$ Valid instrument;$^3$ No regional confounding;$^4$ Overlap;$^5$ Hidden confounding is captured by text.\n\n:::\n\nHere I give a conceptual overview of the 3 mentioned methods that are potentially suitable for dealing with unknown confounders. Their exact assumptions and limitations will be discussed in their respective chapters.\n\n__Regression__\n\n\n```{dot}\n// | label: fig-causal-graph-reg\n// | fig-cap: Causal graph for naive analysis.\n// | fig-width: 100px\n// | fig-height: 100px\n// | column: margin\ndigraph D {\n  {W, X} -> {Y} [color=blue]\n}\n```\n\n\nNaive regression is not a causal method, but is used for comparison with the causal methods. It neglects most of the causal model and only regards the direct relationship between treatment and outcome, possibly controlling for covariates, but neglecting their role as confounders. The result is known as the _prima facie_ causal effect. It suffers from _selection bias_, because the model does not take the treatment assignment process into account -- but it should, because the treatment is not randomized.\n\nControlling for the known confounders can already help to substantially reduce the bias, especially if the relationships are linear, and may as well be considered a causal method.\n\n__Instrumental variables__\n\n\n```{dot}\n// | label: fig-causal-graph-iv\n// | fig-cap: Causal graph for the instrumental variable method.\n// | fig-width: 150px\n// | fig-height: 150px\n// | column: margin\ndigraph D {\n  {W} -> {Y}\n  {Z} -> {W} [color=blue]\n  {X} -> {W, Y}\n}\n```\n\n\n<!-- The _instrumental variable_ approach leverages _natural experiments_, where a random variable (or an almost random variable) influences the treatment. The _exclusion restriction_ (see @sec-app2-iv) assumes that the instrument does not have a direct impact on the outcome, but only via the treatment. We can then trace how the instrument affects the outcome via the treatment, and thereby establish the causal impact of the treatment on the outcome. -->\n\nThis method utilizes one or more instrumental variables. Valid isntruments affect the treatment but do not directly affect the outcome -- not via other paths and not even via confounding. This is especially true for approximately random variables, such as the weather. (The weather is not purely random but also contains regional and seasonal components; but we can try to isolate them or work around the problem.)\n\nIn the simplest case, we can compare the effect of __Z__ on __W__ with the effect of __Z__ on __Y__ to obtain the desired estimate for the effect of __W__ on __Y__. We can also apply _two-stage_ approaches to first isolate the part of __W__ that is caused by __Z__, and then estimate its impact on __Y__.\n\nThanks to instrumental variables, we can legitimately ignore the unknown confounders, which is really nice. A requirement is always that the instrument is valid and sufficiently strong, that is, that it has a strong effect on the treatment __W__.\n\n__Synthetic control__\n\n\n```{dot}\n// | label: fig-causal-graph-synth\n// | fig-cap: Causal graph for the synthetic control method.\n// | fig-width: 180px\n// | fig-height: 220px\n// | column: margin\ndigraph D {\n  {X, U} -> {W} -> {Y}\n  {X, U} -> {Y}\n  {region} -> {U} [style=dotted, color=blue, label=\"determine\"]\n  {date} -> {U} [style=dotted, color=blue]\n}\n```\n\n\n<!-- The synthetic control method [@abadieSyntheticControlMethods2010; @cunninghamCausalInferenceMixtape2021, ch. 10] leverages the idea of comparing a region where a protest happens with other regions where no protest happens on the same day. However it goes beyond a simple comparison. Instead it constructs a _synthetic region_ from all the control regions that is as close as possible to the treatment region. The synthetic region can then be used to model the counterfactual of no protest for the treatment region. -->\n\nThe underlying assumption for the synthetic control method is that the unknown confounders affect the different regions uniformly: On any given day, the impact of the confounders is the same for all regions. This assumption is plausible especially for confounders coming from global and national politics and events; it is violated by regional confounders, but maybe they are not so important and we can live with it.\n\nUnder this assumption, we can perform matching based on the date: To estimate the impact of a protest group in one region on a given date, we find other regions where no such event has taken place, and compare the effect.\n\nThe synthetic control method goes a bit further and also takes the effect of known differences between the regions into account. From all the available control regions, it constructs a _synthetic region_. The synthetic region interpolates between the control regions such that the interpolated region is as close as possible to the treatment region in some respect. This interpolation can be performed in terms of sociodemographic similarity, or in terms of maximizing the predictive accuracy of the outcome variable, based on past observations. (This is a bit of a simplification, the details are explained in @sec-synth.)\n\n__Propensity scores__\n\n\n```{dot}\n// | label: fig-causal-graph-prop\n// | fig-cap: Causal graph for propensity score methods.\n// | fig-width: 100px\n// | fig-height: 150px\n// | column: margin\ndigraph D {\n  {W} -> {Y}\n  {X} -> {W} [color=blue]\n  {X} -> {Y}\n}\n```\n\n\n<!-- Propensity score methods help to remove the impact of _known_ confounders. They rely on the propensity score that specifies how likely it is that a protest occurs on a given date and in a given region. They can be computed from knowledge about the region and the date, and from lagged treatment and outcome data from the previous days. To account to some extent for the impact of _unknown_ confounders, I also obtain propensity scores from press releases about climate-related events. -->\n\nPropensity score methods estimate the probability (propensity) of receiving the treatment. There are various strategies for eliminating selection bias with the use of propensity scores: notably propensity score matching, propensity score stratification, inverse propensity weighting. Double machine learning estimators such as causal forests help with estimating heterogenous treatment effects.\n\nPropensity score methods still suffer from _omitted variable bias_ if there are unknown confounders. This can be mitigated by learning propensity scores from less structured big data such as texts, using classification models from natural language processing. The advantage of doing so is that the unknown confounders need not be pre-specified. The assumption is that the texts need to contain all of the unknown confounders, and in some detectable form. While this will never completely be the case (and cannot be verified anyway), I can hope that it at least substantially reduces the bias.\n\n__Time-series modelling__ {#sec-time-series}\n\nThe variables on one day may also be influenced by the same set of variables from the previous day. On the one hand, this makes modeling more complicated. On the other hand, it is an advantage, because we have the data from the previous days already in the dataset, and using them can help reduce the amount of unknown confounding. Specifically, I consider all variables from the previous day as potential confounders for the current day. Variables from multiple days earlier may still be relevant, but less so, so it will be acceptable to make a cutoff at some point. We can restrict the previous variables to those from the same region, or we can also include previous variables from other regions where it seems useful.\n\n\n```{dot}\n// | label: fig-causal-graph-time-series\n// | fig-cap: Version of the causal graph (@fig-causal-graph-simple) from a time series perspective. The variables of each day are influenced by the variables from the previous days in the same region. We can model that by including all variables from one day as potential confounders for the following day.\n// | fig-width: 200px\n// | fig-height: 400px\n// | column: margin\n\ndigraph D {\n  rankdir=LR\n  compound=true\n\n  U0 [label=\"U\"]\n  W0 [label=\"W\"]\n  X0 [label=\"X\"]\n  Y0 [label=\"Y\"]\n  Z0 [label=\"Z\"]\n\n  U1 [label=\"U\"]\n  W1 [label=\"W\"]\n  X1 [label=\"X\"]\n  Y1 [label=\"Y\"]\n  Z1 [label=\"Z\"]\n\n  U2 [label=\"U\"]\n  W2 [label=\"W\"]\n  X2 [label=\"X\"]\n  Y2 [label=\"Y\"]\n  Z2 [label=\"Z\"]\n\n  subgraph cluster_0 {\n    label=\"Day -2\"\n    {X0, U0} -> {W0} -> {Y0}\n    {X0, U0} -> {Y0}\n    {Z0} -> {W0}\n    dummy_0 [shape=point style=invis constraint=false]\n  }\n  subgraph cluster_1 {\n    label=\"Day -1\"\n    {X1, U1} -> {W1} -> {Y1}\n    {X1, U1} -> {Y1}\n    {Z1} -> {W1}\n    dummy_1 [shape=point style=invis constraint=false]\n  }\n  subgraph cluster_2 {\n    label=\"Day 0\"\n    {X2, U2} -> {W2} -> {Y2}\n    {X2, U2} -> {Y2}\n    {Z2} -> {W2}\n    dummy_2 [shape=point style=invis constraint=false]\n  }\n  dummy_0 -> X1 [ltail=cluster_0 style=dotted label=\"include\\nvariables\" constraint=false]\n  dummy_1 -> X2 [ltail=cluster_1 style=dotted label=\"include\\nvariables\" constraint=False]\n}\n```\n\n\n<!--\nIn time-series models, be it for forecasting or classification, the predictor variables usually fall into 3 categories:\n\n- __Historic variables:__ Variables that are only available for past dates but not for the date of the prediction. This is especially true for the target variable^[The lags of the target variable are more specifically called an __autoregressive__ variable.]; since its future value should be predicted, it should not be present as a predictor.\n- __Future variables:__ Variables whose values are available for past dates as well as the date of the prediction.\n- __Static variables:__ These are time-independent.\n\n@tbl-time-series gives an overview how these categories are applicable within the different causal methods.\n\n::: {#tbl-time-series}\n\n| Target | Predictors | Method |\n| ------ | ---------- | ------ |\n| __Y__ | \\boldmath$X_{f,s}, Y_h, W_f$ | Regression |\n| __Y__ | \\boldmath$X_{f,s}, Y_h, W_f, Z_f$ | IV stage 1 |\n| __W__ | \\boldmath$X_{f,s}, Y_h, W_h, Z_f$ | IV stage 1 |\n| __Y__ | \\boldmath$X_{f,s}, Y_h, W_h, \\hat W_f$ | IV stage 2 |\n| __Y__ | \\boldmath$X_{f,s}, Y_h, Y_{R_0f}$ | Synthetic control |\n| __W__ | \\boldmath$X_{f,s}, Y_h, W_h$ | Propensity score |\n\n: Subscripts $\\scriptsize f, h, s$ denote future, historic and static variables.\n\n:::\n\n\\begingroup\n\\color{Blue} -->\n\n\n### Case study\n\nThe climate protest movement in Germany has only stepped into existence toward the end of the 2010's. Before then, climate activism was mostly associated with established environmental NGOs such as Greenpeace, which did not play a major role in the media. In 2015 the activist formation _Ende Gelände_ (EG) was established, and began organizing occupations, blockades, and demonstrations directly in coal mining areas [@EndeGelaende2023]. In late 2018 _Extinction Rebellion_ (XR) was established in Germany to protest the biodiversity crisis that comes along with the climate crisis, through demonstrations as well as blockades [@ExtinctionRebellion2023].\n\nAround the same time, the global _Fridays for Future_ (FFF) movement gained traction in Germany, accumulating a huge momentum -- more than a million protesters --, especially among high school and university students, and later also among other social groups with sub-movements such as _Scientists for Future_, _Parents for Future_, and _Grandparents for Future_ [@FridaysFuture2023]. They emphasize constructive discourse and inclusivity, organize exclusively pre-registered demonstrations, and often collaborate with other protest groups. However, they mostly protest on Fridays, that is, during school time, which has caused outrage from conservative politicians and media. As part of this outrage, the argument was first raised that the protests may run counter to their goals by stirring discussions about the appropriateness of their methods, and thereby divert attention from climate policy issues themselves.^[Supporters of the movement may claim that the argument is hypocritical and is mostly used by persons who are actually opposed to climate policy.]\n\nA contrary (or complimentary) strategy is taken by _Letzte Generation_ (originally _Aufstand der Letzten Generation_, ALG), which was founded by the participants of a hunger strike during the pre-election phase in 2021 [@LetzteGeneration2023]. Since 2021 the group -- consisting only of dozens or hundreds of members -- employs highly disruptive tactics: most prominently unregistered sit-ins on car highways, as well as supplementary action forms including throwing soup at paintings (which are protected by glass sheets), turning off oil pipelines, or vandalizing symbols of climate-afflicting luxury. The group has concrete demands including a citizen's assembly on climate policy, a ban on food waste, a speed limit for cars, and heavily subsidized public transport tickets. The protesters face a vast backlash, are criticized by politicians from across the poltical spectrum as well as by many media formats, and are pursued under terrorism laws by public prosecutors (who in Germany report to the regional governments); at the same time they have successfully negotiated with multiple mayors to support their concern, have held talks with the chancellor and the minister for traffic, and have been endorsed by the UN general secretary and by some religious organizations. Again, and this time perhaps with even more plausibility, the argument has been raised that the caused disruption runs counter to the goals of the group by diverting attention from climate change policy issues themselves, and by annoying the public.^[A version of this argument is presented by @jansteckelKlimaprotestAufAbwegen2022, and not without [controversy](https://twitter.com/jan_c_steckel/status/1601048858129477632).]\n\n@moreincommonWieSchautDeutsche2023 survey support for the German climate protest movement in 2021 and 2023 and see an roughly 50% decline in support across the sociopolitical spectrum, which is accompanied by widespread disapproval of street blockades (mostly associated with ALG). @gonzattiAnalyseberichtZurStudie2023 use an \"experimental\" setting where participants are told about a fictitious climate protest in Germany, and also find low approval for street blockades and soup throwing, but do not find a positive or negative impact on support for climate policy for any protest form.\n\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nResearch methods and justification:\nExcellent description of data or methods, excellent methodological understanding, research is reproducible.\n\n -->\n\n## Methods\n\n### Data sources and preprocessing {#sec-data}\n\nAll data is retrieved for the timespan from 2020 to 2022. This is because the _ACLED_ data is not available earlier, and the _DeReKo_ data is only released yearly with some delay, and not yet available for 2023 at the time of writing. All data sources are expected to be available for the next years, with the exception of data related to the COVID-19 pandemic.\n\n\n\n#### Protest events {#sec-acled}\n\nThere are generally two source types for protest events:\n\n1. __Newspaper articles__ are primarily used in the existing literature. [@hutterProtestEventAnalysis2014] give a historical and systematic overview and highlight the problem that this source is biased. They describe how several definitions for protest event analysis (PEA) and the broader political claim analysis (PCA), as well as associated coding practices have helped to formalize the (manual) data extraction process, such that results have become more valid and comparable.\n\n2. __Police archives.__ The literature dismisses this source type as \"biased\", uninformative about the motives and organizers, uncomparable across regions, often unavailable or unobtainable, and because it is restricted to only registered demonstrations (Hutter 2014; @ProtestlandschaftDeutschland; @wiedemannGeneralizedApproachProtest2022). This criticism appears to me valid but overgeneralized, and there may well be regions where the advantages prevail over the problems. Especially for the goal of impact estimation, the avoidance of selection biases that are associated with newspaper articles [Hutter 2014; @jamesozdenLiteratureReviewProtest2022] is a strong argument for using data from police and demonstration authorities.\n\n::: {.cell .column-page execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![History of the number of protest events in Germany per week.](report_files/figure-pdf/fig-protest-history-output-1.svg){#fig-protest-history}\n:::\n:::\n\n\n__ACLED.__ My main data source for protest events is the [_Armed Conflict Location and Event Dataset_](https://acleddata.com/) (ACLED; @raleighIntroducingACLEDArmed2010a). ACLED is a grand effort that keeps track not only of violent conflicts and riots, but also of ordinary protest events. The data is human-curated based on newspaper reports, and contains coded information on dates, locations, actor groups, police interventions, and more, as well as a short free-text summary for each event, containing an estimate of the size as per the newspaper data source. Data for Germany is available starting from 2020 and is continuously updated. For the period from 2020-2022, it contains 13235 protest events, 1314 of which are organized by climate protest groups or mention the climate in their description.\n\n<!-- For the period from 2020-2022, it contains 13235 protest events, 1543 of which are organized by climate protest groups or mention the climate in their description. -->\n\n__Other existing protest datasets.__ Alternative existing sources of German or international protest data comprise [ProDat](https://www.wzb.eu/de/forschung/beendete-forschungsprogramme/zivilgesellschaft-und-politische-mobilisierung/projekte/prodat-dokumentation-und-analyse-von-protestereignissen-in-der-bundesrepublik)^[See also [Protestlandschaft Deutschland](https://protestdata.eu/methods). for additional data and interactive visualizations], [PolDem](https://poldem.eui.eu/download/protest-events/), the [Mass Mobilization Project](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HTTWYL), and the event database [GDELT](https://www.gdeltproject.org/). They do not cover recent years or are not very complete, and therefore inferior to ACLED for my purposes.\n\n#### The German Protest Registrations dataset\n\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-protest-groups .cell .column-margin tbl-cap='Number of protest events 2020-2022 by protest group in the different data sources.' execution_count=3}\n\n::: {.cell-output .cell-output-display execution_count=3}\n|                        |   ACLED |   GPReg | GPRep   |\n|:-----------------------|--------:|--------:|:--------|\n| Ende Gelände           |      46 |       0 | ?       |\n| Extinction Rebellion   |     171 |      57 | ?       |\n| Fridays for Future     |     801 |     803 | ?       |\n| Fridays for Future + X |      81 |       1 | ?       |\n| Greenpeace             |      74 |      83 | ?       |\n| Letzte Generation      |     145 |      26 | ?       |\n| Other                  |     225 |    1089 | ?       |\n:::\n:::\n\n\n\\endgroup\n\nProtest statistics are often recorded by public authorities, either when organizers register a future demonstrations, or when the police reports about a past demonstration. Registering a demonstration is a common requirement for exercising the right to protest in European countries, however this requirement is only fulfilled by moderate protests, while more radical protests may purposefully ignore it and are thus not listed in such records. Often the estimated number of expected protesters is also recorded, but it is of course not reliable, and reliability may vary between different protest organizers. Police estimates of past demonstrations should be more reliable and consistent, however with the possibility for systematic bias, such as generally downplaying the number of participants, or specifically downplaying the number of participants for protests that are critical of the government or the police themselves.\n\n\\begingroup\n\\scriptsize\\selectfont\n\n::: {#tbl-protest-most-common .cell .column-margin tbl-cap='Number of protest events for the five most busy climate protest days 2020-2022; they are concentrated around the spring and autumn equinoxes. (More esoteric future work might explore the astrological determinants of protest activity.)' execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n|            |   ACLED |   GPReg | GPRep   |\n|:-----------|--------:|--------:|:--------|\n| 2020-09-25 |      97 |      17 | ?       |\n| 2021-03-19 |      65 |      40 | ?       |\n| 2021-09-24 |     105 |      35 | ?       |\n| 2022-03-25 |      59 |      21 | ?       |\n| 2022-09-23 |      30 |      25 | ?       |\n:::\n:::\n\n\n\\endgroup\n\nOfficial documents, including protest statistics, can be obtained via _Freedom of Information_ laws. These exist in more than 100 countries and allow anyone to obtain public documents [@FreedomInformationLaws2023]. The specific requirements, exceptions, and costs vary greatly. In Germany, freedom of information exists on the federal level; but many authorities belong to the regional level, where the extent of freedom of information rights varies greatly [@InformationsfreiheitDeutschlandTransparenzranking]; and municipal authorities are not always covered by regional freedom of information laws, sometimes filling the gap with their own legislation.\n\nAccess to public documents has been democratized via platforms that streamline the process of sending requests, escalating the process to oversight authorities or courts if necessary, and making communication and obtained documents available to the public. The [Alaveteli](http://alaveteli.org/) network provides software and hosts such platforms in more than 30 countries across the world. Some independent platforms also exist, such as [Öffentlichkeitsgestz.ch](https://www.oeffentlichkeitsgesetz.ch/) in Switzerland, and _FragDenStaat_ [in Austria](https://fragdenstaat.at/) and [in Germany](https://fragdenstaat.de/). These open the possibility of obtaining official protest data at scale.\n\n__Collection.__ I send 40 freedom of information requests to German demonstration authorities (depending on the region these are either part of the municipal administrations or of the police) and their supervisory bodies concerning protest data in 31 cities. These cities comprise the political capitals of all 16 regions in Germany, the 17 largest cities by population size, as well as some smaller cities for regions where the request in the regional capital is unsuccessful. 4 requests are not answered, 3 are rejected, 11 state that they do not possess such data, 2 have to be withdrawn due to demanded payments of multiple hundreds of euros, and 20 are been partially or completely successful. This yields 17 table documents with various amounts of information. The requests and responses including the original data files can be found at [FragDenStaat](https://fragdenstaat.de/anfragen/?q=demonstration+csv&first_after=2022-12-01&first_before=2023-07-31).\n\n__Cleaning.__ I ignore one of the datasets (Augsburg) because I cannot convert the delivered PDF back to a table, two of them (Saarbrücken and Freiburg) because the data is too unstructured or requires too much cleaning, and one (Duisburg) because the data is delivered very late. The remaining 13 data tables are cleaned manually. One common problem is that the tables specify events that have a duration of multiple days, in some cases even multiple months. Out of concern for a simple data structure, as well as doubt whether these demonstrations really lasted so long, I reduce their duration to the single day when they start.\n\n__Dataset__. The resulting dataset contains 49,800 events from 13 cities. For 11 cities the ex-ante number of expected participants are given, and for 2 of them (Berlin and Magdeburg) the ex-post extimates by the police are also included. For all cities the topic of the protest is given in, presumably as specified by the organizers themselves; and for 4 cities the name of the organizing group is also known. Various additional details such as exact specifications of location, time and duration, and distinctions between protest marches and pickets are available for some of the cities but not in any systematic manner. Further statistics about the dataset can be seen in table tbl-official-overview.\n\n\n{{< embed ../src/data/protests/german_protest_registrations/data_map.ipynb#data-official-map >}}\n\n\n\n\n#### The German Protest Reports dataset\n\n@wiedemannGeneralizedApproachProtest2022 show how to detect protest events in newspaper articles. They employ the [`gelectra-large`](https://huggingface.co/deepset/gelectra-large) model, a transformer model that is fine-tuned on German texts of various genres. Their dataset consists of almost 4000 newspaper articles from 4 German cities, namely Leipzig, Dresden, Stuttgart, and Bremen, from between 2009 and 2016.\n\n__Replication and experiments:__ I replicate their results and obtain F1-scores of 0.93 for in-distribution and 0.76 for out-of-distribution classification, which is almost identical to the authors' results. I try out some alternative approaches on their data: Simple machine learning models based on TFIDF-features; finetuning the more recent multilingual FlanT5 model; and using GPT 3.0 in a zero-shot setting. None of the alternatives perform closely to the `gelectra-large` model (see @tbl-glpn-alternative-methods for metrics).\n\n\\begingroup\n\\small\\selectfont\n\n| Model    | id F1 | ood F1 |\n|----------|------:|-------:|\n| XG-Boost | 0.87  | 0.60   |\n| FlanT5   | 0.75  | 0.30   |\n| GPT3     | 0.81  | 0.65   |\n| gElectra | 0.93  | 0.76   |\n\n: Results for using alternative classification methods on the GLPN dataset, for in-distribution (id) and out-of-distribution (ood) prediction. {#tbl-glpn-alternative-methods .column-margin}\n\n\\endgroup\n\nIn order to obtain protest events from a broader geographic spectrum, I retrieve metadata of online newspaper articles from MediaCloud (see @sec-mediacloud) for a query containing protest-related keywords.^[The query is based on the query used by Wiedemann, and reads: _'protest* OR demo OR demonstr* OR kundgebung OR versamm* OR \"soziale bewegung\" OR hausbesetz* OR streik* OR unterschriften* OR petition OR hasskriminalität OR unruhen OR aufruhr OR aufstand OR rebell* OR blockade OR blockier* OR sitzblock* OR boykott* OR riot OR aktivis* OR bürgerinitiative OR bürgerbegehren OR marsch OR aufmarsch OR parade OR mahnwache OR hungerstreik OR \"ziviler ungehorsam\"'_] From the obtained metadata, I scrape full-texts where possible. Special care is taken of website that appear scrapeable but contain only gibberish, by observing the distribution of letters.\n\n\n{{< embed ../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-ts >}}\n\n\n\nI label the texts myself using [Prodigy](https://prodi.gy/). For the positive class, I require that the article is a report about (potentially among other topics) a recent past protest event, and that basic details including the place and the protest concern are given. The other articles are mostly about completely different topics (such as \"protest\" but not in the political sense, or \"demonstration\" in the sense of showing something, \"blockade\" in a physical context, or the \"protest-ant\" church); or they mention protests in the context of an op-ed or an interview, where the concreteness and recency of the events is often not given.\n\n\n{{< embed ../src/data/protests/german_protest_reports/03_dataset_stats.ipynb#aglpn-sources >}}\n\n\n\nIn a first labeling phase, I annotate 650 random articles for training and 500 random articles for evaluation. I train the model and use 500 articles that are predicted positive and label them as well and add them to the training data, in order to combat class imbalance. Training the `gelectra-large` model with the overall 1150 training samples and according to the hyperparameters suggested by Wiedemann, I finally obtain an in-distribution F1-score of 0.78 (precision=0.81, recall=0.75). Then, I use this model to predict the relevance of all the other scraped articles that contain protest-related keywords. Only 11% are relevant, resulting in 20,879 articles of which the (relatively good) model believes that they describe protest events.\n\n\\begingroup\n\\color{Red}TODO: Extraction of dates, locations, protest groups.\n\\endgroup\n\n#### Newspaper coverage {#sec-data-discourse}\n\n::: {.cell .column-page execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![Number of daily online newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display. The effects of an outage of the collection system in January 2022 are visible.](report_files/figure-pdf/fig-mediacloud-history-output-1.svg){#fig-mediacloud-history}\n:::\n:::\n\n\n__Online newspapers.__ [Media Cloud](https://www.mediacloud.org/) is an open data platform that continuously crawls newspaper websites around the world and stores article metadata and word counts in a database. Full texts are in principle available by following the links and scraping the websites oneself, but this is very slow and often hampered by anti-scraping measures of the websites. I use the [`api/v2/stories_public/count`](https://github.com/mediacloud/backend/blob/master/doc/api_2_0_spec/api_2_0_spec.md#apiv2stories_publiccount) endpoint of their API. I query for tags from the [regional and national collections about Germany](https://search.mediacloud.org/collections/news/geographic). Baden-Württemberg and Mecklenburg-Vorpommern are missing from the collection. There has been a (partial) outage in January 2022 resulting in (near-)zero counts for that timespan. I do not exclude this timespan because it would be complicated and error-prone with respect to time-series analysis. This may lead to an under-estimation of eventual causal effect sizes of up to $\\frac{1}{36}\\approx 0.028$, but I do not expect it to influence my results in any other systematic way. {#sec-mediacloud}\n\n::: {.cell .column-page execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![Number of daily print newspaper articles published in the region of Bavaria falling under 5 different queries relating to climate change. A rolling mean with a 7-day window has been applied for smoother display.](report_files/figure-pdf/fig-dereko-history-output-1.svg){#fig-dereko-history}\n:::\n:::\n\n\n__Print newspapers.__ The [German reference corpus](https://www.ids-mannheim.de/digspra/kl/projekte/korpora/) (_Deutsches Referenzkorpus_, DeReKo) archives the full texts of most German-language print newspapers and magazines in an online database for the purpose of linguistic research. An API contains access to a selected corpus, and by (automatically) navigating the user interface, an extended corpus can be searched. The content is renewed on an annual basis and with a delay of a few months, so no data for 2023 is available. Full texts cannot be retrieved from DeReKo, but large context windows for search results are available, which could be used for more nuanced further research. Here, I only use the functionality of obtaining daily article counts for a given query.\n\nI extract an overview table of all newspapers from the corpora W1-W4, remove newspapers that are not available until 2022, remove newspapers that are about niche topics such as cars, beauty, or history, or that are published with less than weekly frequency. I annotate the remaining 154 newspapers on whether they have a national or regional scope, and retrieve the applicable regions for the regional ones, drawing from information on Wikipedia and the newspaper websites. 121 are from Germany, and 15 of these have a (primarily) national scope, while 106 have a regional scope. All regions are represented with at least one newspaper, except the city state of Bremen. Among the 4 (or more) German \"newspapers of record\" [see @NewspaperRecord2023], the conservative _Frankfurter Allgemeine Zeitung_ is missing, and the very popular tabloid _Bild_ is also missing. I retrieve daily article counts for all queries and all thus filtered newspapers, and aggregate them by day on the regional level as well as into a category of national newspapers. {#sec-dereko}\n\n__Topic queries.__ I use queries that allow to examine how many mentions of climate change occur in newspaper articles overall, and how this is further subdivided. I formulate 5 sub-queries (the full word lists are found in @sec-app-queries):\n\n- _Topic:_ Whether an article mentions climate change or climate policy.\n- _Protest:_ Whether an article mentions protest activity (including both general terms, and terms and organization names that are specific to the climate movement).\n- _Framing:_ Whether more dramatic words than \"climate change\" are used, such as \"climate crisis\", \"climate catastrophy\", etc.\n- _Goals_: Whether long-term goals of the climate movement such as carbon neutrality are mentioned.\n- _Subsidiary goals:_ Whether more concrete measures such as a speed limit for cars, or a citizen's assembly on climate change are mentioned.\n\nFrom these sub-queries, I use the _topic_ query as a standalone query, and combine each of the other queries with the _topic_ query to make sure that the terms are actually used in the context of climate change. (Many of the terms have an unambiguous relation to climate change anyway, but some, such as the protest forms or specific solutions, could also appear in other contexts.) I retrieve absolute article counts for each query, aggregated daily on the regional or on the national level.\n\nThe queries allow me to study not only research question 2 (how much overall coverage of climate change is affected); but also (to some extent) to investigate research question 3 (whether this does not backfire by focusing the discussion on the protests rather than the policy issues):\n\n- If the article counts for the _topic `and not` protest_^[This query can be derived from the other queries logically.] query remain constant or even increase due to protests, then this is strong evidence that the protests do not backfire; and if it increases, then their effect is very strong such that they cause more discussion even when the protests are not themselves a topic. A decrease of the article count for this query does not tell us much, since it could still be, or not be, that relevant contents are transported as part of he articles that also mention protests.\n\n- The other queries (_topic `and` framing_, _topic `and` goal_, _topic `and` subisidiary goal_) aim to look at topics where it would be a success for the protests if they occur more in public discourse. If their article counts increase due to protests, then backfiring is unlikely (but still possible in other topic niches that I am not querying for); and if they decrease, it is strong evidence that the protests are indeed backfiring. A result where the counts for some of these queries increase, while they decrease for others may indicate more complicated effects of protests that warrant further research.\n\n- The _topic `and` protest_ query can serve as a sanity check: It would be very surprising if protest events did not cause the counts for this query to markedly increase. This is even more true for the _ACLED_ and _GPRep_ datasets, where the events are (manually or automatically) extracted from newspaper articles.\n\n![The queries produce different lenses on the mass of articles about climate change. The left lens has the disadvantage that we do not know how much the articles that also mention the protests contribute to the discourse about the topic. The right lens has the disadvantage that it ignores aspects that we do not explicitly query for.](figures/queries.svg){.column-margin}\n\n__Alternative topic representations.__ The querying approach that I employ for this study is very coarse, and will deliver clear conclusions only in some cases. It would also be very interesting to see how much room is typically given to the discussion of climate policy in an article that also mentions protests. Moreover, one could measure how prominent the various keywords are within each article, and what other words they cooccur with most, and what sentiments they are accompanied by. Another approach would use topic models to create topics in an unsupervised manner, and observe how their prevalence shifts in the face of protests; this has already been done by @chenHowClimateMovement2023a for the climate protest movement. All of these techniques require full-text data. For newspaper articles, full-text data is in principle available, but relatively hard to obtain (see the notes on fulltext availability in @sec-mediacloud, @sec-dereko); so I have not used full-texts here, in order to focus more on the causal aspect.\n\n__Alternative soruces of public discourse.__ Future work could also explore Twitter data (@kratzkeMonthlySamplesGerman2023: a sample of full texts from Germany on a daily basis 2019-2022), [Google Trends](https://trends.google.com/) data (search query counts on a weekly and regional basis starting from 2005), or parliamentary speech (@abramiGermanParliamentaryCorpus2022: speeches from regional German parliaments from the nineties until 2021). Twitter data does not come with geographical annotations, and Google Trends and parliamentary speech are not available on a continuous daily basis, so I focus on newspaper articles here.\n\n#### Instruments\n\n\n{{< embed ../src/models/instrumental_variable/notebooks/05-31-instrumental-again.ipynb#fig-weather-time-series >}}\n\n::: {.cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![Pandemic restriction variables. The top figure displays 6 different variables that show how often various place categories are visited. The bottom figure gives the stringency index, an aggregated measure of expert estimates of the severity of restrictions along multiple dimensions.](report_files/figure-pdf/cell-8-output-1.svg){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](report_files/figure-pdf/cell-8-output-2.svg){}\n:::\n:::\n\n\n__Weather.__ Weather data is obtained via the [Meteostat](https://meteostat.net/en/about) project from _Deutscher Wetterdienst_, containing the 8 variables displayed in @fig-weather-time-series. Related work on causal methods for protest impact analysis typically uses precipitation or rainfall, and in some cases additionally temperature and windspeed as instruments. I consider all available weather variables as potential instruments. Two systematic concerns have been raised about using weather variables as instruments:\n\n1. _Indirect paths._ @mellonRainRainGo2023 find 195 variables that have been linked to the weather in previous studies (ironically, many of them instrumental variable studies themselves), and that these undermine the exclusion criterion for instrumental variables, threatening the validity of the variables. The authors have constructed a comprehensive causal graph depicting the known effects of the weather. It shows that _protests_ as well as _violent protests_ are influenced by rainfall and temperature, and that protests have an influence on repression, voting behaviour, policy, and property values. There is no study confirming an influence of the weather on newspaper reporting, but possible indirect paths may include _mood_ and (for climate protests) _pollution_. Other variables such as _migration_ may also have an effect because attention to them might decrease attention to other topics in the news; however most of this kind of variables are only related to the weather in the long term and not in the short term.\n\n2. _Spatial interdependence.__ @coopermanRandomizationInferenceRainfall2017 raise concern about spatial interdependence of rainfall across regions. This applies particularly when the effect of rainfall across regions _on a single date_ is investigated, for example in the context of an election. In my setting I investigate the individual effects of protest events that are spread across multiple years. The amount of protests that take place on the same date is therefore very small, and spatial interdependence of the _weather_ among temporally separated events is very low. Spatial interdependence of the _climate_ (thus also influencing the weather) is still a problem. When removing the climate influence from the weather and only using the (climate-independent) weather as instrumental variables, the spatial interdependence should be mostly removed from the intrumental variables.\n\n__Pandemic restrictions.__ The timespan covered by my dataset coincides with the Covid-19 pandemic, which has had very drastic impacts in 2020 and 2021, and still some in 2022. This may open up the possibility for exploiting a new kind of instrumental variable, because the pandemic comes with both legal restrictions and psychological aversion against large gatherings, including demonstrations. Available data includes the _stringency index_ calculated by the [Oxford Coronavirus Government Response Tracker](https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker) and provided by [Our World in Data](https://ourworldindata.org/covid-stringency-index)^[TODO: Plot this as well.]; and _Google Mobility Trends_ data, also provided by [Our World in Data](https://ourworldindata.org/covid-google-mobility-trends) [@fig-covid-19-time-series]. Both datasets are only on the national level for Germany. While the stringency index is rather static, the mobility trends data contains more randomness. The randomness may indirectly be influenced by the weather, which is neither a problem, nor an advantage, since I already use the weather variables directly. Two reasons may threaten the validity of the pandemic variables as an instrument.\n\n1. _Temporal correlation._ Unlike the weather, COVID-19 restrictions are temporally correlated over longer timespans, that is, they change more slowly. This introduces some chance that they may be accidentally or systematically correlated with political processes and with media attention cycles.\n2. _Direct media impact._ There is a potential direct impact of COVID-19 on media coverage: Stricter restrictions may correlate with a more intense media focus on the pandemic, decreasing attention on any other topic. Controlling for coverage levels before the protests can decrease this problem.\n\n### Data aggregation {#sec-agg}\n\nThe data is aggregated by region and date. For every day and region there is a row that contains information about all causal variables. In causal terms, days are the _treatment units_, and the treatment is whether or not a protest (by a certain group) takes place on a given day in a given region. Summarizing and categorizing the variables that are described in detail in the above sections, we have:\n\n- Treatment __W__:\n  - For each protest group, a dummy variable whether it organizes at least one protest event in the given region (that is, a _binary_ treatment).^[Alternatively, I could use for each protest group the number of protesters in the given region as a _continuous_ treatment; but this requires (a) slightly more complicated methods to deal with continuous treatments, and (b) difficult assumptions about scaling -- does the number of participants have a linear impact, or a logistic one, or is it more complicated?]\n- Outcome __Y__:\n  - Number of newspaper articles published that mention the climate crisis, across 5 dimensions (see @sec-data-discourse): overall mentions; mentioning protest activity; mentioning long-term goals; mentioning specific short-term goals; using a drastic or catastrophic framing. I also use multiple impact timespans, see below.\n- Instruments __Z__:\n  - Weather: min/max/avg temperature, air pressure, precipitation, snowfall, wind speed, and peak gust\n  - Covid restrictions: stringency index of the restrictions, and movement variables for 6 location types\n- Known confounders __X__:\n  - Day of the week, as dummy variables\n  - Holiday occurrence in the given region\n  - Region dummies\n  - Time-series lags of all variables (with variable number of lags, subject to hyperparameter optimization)\n  - Exponential moving averages of $W$ to account for the long-term impact of previous protests (with spans of 7, 28, 112, 224 days each)\n  - Time-series differences of $Y$ to account for trends in media coverage (with distances of 1, 7, 28, 91, 182, 364 days each)\n- Unknown confounders __U__:\n  - __*?*__\n\n__Regional aggregation__. My setting throughout all methods is that I estimate models based on regional data. However, I do not fit separate models for each region, but always a single model on a dataset that includes all regions. This has the benefits that _(a)_ it leads to more generalizable results and _(b)_ it increases the size of the dataset by a factor of 14 (in comparison to using national data, or to estimating single regional models), and thereby increases statistical power. To integrate multiple time series from the various regions into a single dataset, I add static _dummy variables_ for each region. Limitations of this approach are:\n\n1. To capture the effect of regional differences properly, it would be necessary to also add _interaction terms_ of all 14 region dummies and all 5 treatment variables, as well as potentially some of the control variables. This would lead to at least 70 interaction terms, which would make the interpretation of the results much harder.\n\n2. The _differences_ between the regions -- especially in size, population size, and number of newspapers -- are potentially problematic for the estimation of a global model. I minimize this problem by (a) including previous amounts of coverage and (b) using absolute rather than relative coverage. While the relative coverage of a protest event will presumably be lower in larger regions (because a smaller proportion of the region is affected by any event), this will not be the case in absolute terms. However, it may be the case that there are major protest events with a strong relation to regional politics, and that they have an impact throughout the whole region, and in that case the size of the region might matter. This would not be captured by the model and could lead to a high variance the treatment effect estimates.\n\n3. On the other hand, the _national impact_ of protests is politically more interesting, so I also estimate a model on the national level, which has the structure as any of the regional models, but with aggregated treatment variables and newspaper coverage from national rather than regional newspapers.\n\n__Outcome time series.__ Protests may have an impact on newspaper converage not only on the day that they occur but also in the following days and weeks, so I estimate time series of causal impacts, as well as of cumulative impacts. For estimating the delayed impacts, I do _not_ extend the time series lags further into the future, because the amount of coverage on or after the protest date likely mediates the impact on future coverage. These mediated impacts are hard to isolate. By not including potential mediators in the predictors, I make sure that all indirect impacts are also clearly attributable to the treatment. I do _not_ extend the lags of the treatment further into the future either (mostly motivated by efficiency gains that are related to implementation details), so indirect impacts that are mediated by future protests (if they exist) are also included in the impact estimate.\n\n### Causal impact estimation\n\nFor the selection of suitable models, I specify the treatment as the occurrence of a protest event by any protest group, and the outcome as the one-week amount of total newspaper coverage mentioning the climate crisis. I then use these models to also estimate more specific impacts for events from specific groups; and for the coverage during single days, in order to build impact estimate time series.\n\nFor the main experiments I use the ACLED dataset as source for protest events; and as source for media coverage I use the sum of both online and print newspaper articles.\n\n#### Regression\n\nI estimate an OLS regression model, in order to interpret the coefficients for the treatments causally. This assumes the complete and correct specification of all confounding variables, and a linear model; see @sec-app2-reg for formal details.\n\nI perform hyperparameter optimization by 5-fold time-series cross-validation. Hyperparameters are: number of time series lags, inclusion of region dummies, inclusion of moving average features, and inclusion of time-series difference features (see @sec-agg).\n\nAn interesting question is what metric to optimize for. In predictive contexts this would typically be the (root) mean squared error ((R)MSE) or the mean average error (MAE); they minimize variance in the first place. For causal impact estimation, we want the estimates to be _unbiased_ much more than we want them to have a low variance. Therefore I minimize the bias, defined as the absolute value of the mean error (ME). Unlike the MAE, this takes the direction of the errors into account.\n\nOLS is unbiased for in-distribution data anyway. I want a model that also generalizes to out-of-distribution data -- this is what we generally want from causal models -- and OLS is not automatically unbiased for this. By using time-series cross-validation splits, I create a situation that is slightly out-of-distribution. Future work could also create situations that are more extremely out-of-distribution, for example by using large gaps for the time-series splits, or by using geographic splits.\n\nTo set the generalization capabilities of the OLS model into perspective, I also estimate similarly optimized Ridge and Lasso regression models. But I cannot use them for causal impact estimation because the coefficients are regularized and thus biased.\n\nI use the `OLS` implementation from the `statsmodels` package [@perktoldStatsmodelsStatsmodelsRelease2023] with `HC3` heteroskedacity-robust covariance estimation, and the `BayesianRidge` and `LassoLarsIC` implementations from `scikit-learn` [@pedregosaScikitlearnMachineLearning2011]. `statsmodels` does not support multivariate regression, so I run separate univariate models for each target variable.\n\n#### Instrumental variables {#sec-instrumental}\n\nI consider\n\nIn order\nI estimate a _limited information maximum likelihood_\n\n\nWhile the previous literature has mostly focused on rainfall, I consider all weather variables to be potentially useful and analyze all of them for suitability, addressing the concern of multiple testing. Since the protest events in the main data set are aggregated daily on a regional level, I use regional weather data. For each region I determine the 10 cities with the most protests and average their weather data, weighted by the number of protests in each city.\n\nI follow @negroWhichSideAre2019 in using 10-year averages for each day of the year, additionally smoothing them. I find a $\\pm 14$-day window using Bayesian smoothing to deliver more satisfactory results, that is, smoother climate variables, than the $\\pm 3$-day moving average applied by the authors. Using this as a long-term variable, I construct the short-term variable by subtracting the long-term variable from the original weather weather variable.\n\n<!--\n- https://bashtage.github.io/linearmodels/iv/index.html\n- https://www.pywhy.org/dowhy/v0.10/dowhy.causal_estimators.html#module-dowhy.causal_estimators.two_stage_regression_estimator\n-->\n\n##### Precipitation\n\nI make two separate regressions, one with protest occurrence, and one with protest size as dependent variables. All potential instrumental variables are used as independent variables, and the long-term weather components are used as control variables. Both regressions use linear regression (and _not_ logistic regression, even though the target is binary) due to consistency with the second stage. For the protest size variable, only days with protest occurrence are included in the data. To adjust for multiple testing, I use the Benjamini-Yekutieli procedure. It has less power than the Benjamini-Hochberg procedure, but accounts for potential correlations among the independent variables, which seem very likely here. I include regional dummies as control variables but do not include them in the adjustment procedure because I am not interested in their significance.\n\nFirst-stage placebo.\n\n#### Synthetic control {#sec-synth}\n\nI fit a synthetic control for each protest event.[^global] Control regions are all regions that do not have a protest event on the given date. For all regions, outcome variables[^global] of all coverage dimensions are considered during a specified pre-treatment period. Values of the different dimensions are stacked, resulting in one column per region. The columns for the control regions are scaled, where the scaling options are: demeaning (subtraction of the mean), as suggested by @fermanSyntheticControlsImperfect2021; subtraction of the values from the last date within the pre-treatment period; z-score standardization; mean normalization (division by the mean); and logarithmic scaling. Nonnegative least squares (NNLS) regression is performed to predict the treatment region values from the control region values; alternatively, interpolation is performed, which is similar to NNLS but demands that the coefficients for the regions um up to 1. The obtained weights are then used to predict the counterfactual for the post-treatment period from the control regions, and the difference is the causal impact.\n\n[^global]: Estimating region weights globally rather than for every single protest event is unfortunately not possible because the available control regions varies between events.\n\n[^sociodemographic]: Alternatively to regressing on pre-treatment outcomes, weights can also be obtained by fitting on fundamental characteristics of the regions (such as sociodemographic or economic statistics) that are considered predictive of the outcome [@abadieSyntheticControlMethods2010]. I discard such an approach because the choice of variables biases the causal impact estimate, and I find it hard to justify any specific variables that would be predictive of climate change newspaper coverage.\n\nFor the synthetic control method, significance is typically evaluated by using permutation tests. In my setting I do not only have a single estimate, but rather a large number of estimates from fitting many synthetic controls, so I can compute confidence intervals based on the population variance of the estimates.\n\nI manually evaluate the suitability of the scaling and fitting methods by plotting the pre-treatment fit. The length of the pre-treatment period is chosen by hyperparameter optimization. The objective is an unbiased estimation of the counterfactual in the post-treatment period. Since the counterfactual is unknown, a workaround is to minimize the post-treatment bias in the general case. If the weights generally represent the \"true\" relationship between the regions, then they will also do so for the counterfactual, subject to the model assumptions from @sec-app2-synth. Therefore I perform hyperparameter optimization for minimizing the post-treatment bias in synthetic control settings for randomly selected dates (rather than actual protest dates).[^pretreat] This is similar to having a large number of train-test splits, to which the synthetic control method is applied, and additional cross-validation is not necessary.\n\n[^pretreat]: An alternative is to focus on the pre-treatment fit. Theoretically both approaches are similarly justified. By referring to propensities, anticipation effects, or missing data, one may practically argue in favour of one approach or the other; see discussion for related thoughts.\n\nI use a custom implementation that builds on @facurealvesCausalInferenceBrave2022 [ch. 15]. Future work may also use a _Bayesian structural time series_ model [@brodersenInferringCausalImpact2015a], which makes similar assumptions and is practically more flexible.\n\n#### Propensity scores\n\n_Propensity scores_ quantify the probability of the treatment, that is: how likely is it on a given day in a given region that a protest takes place? (See @sec-app2-ps for details.)\n\nI obtain propensity scores by training probabilistic classifier models to predict the treatment (the occurrence of protests) from the known confounders (primarily past time-series values and features, see @sec-agg). I consider Naive Bayes and logistic regression models because they both produce well-calibrated probabilities. I optimize the following hyperparameters on a 5-fold time-series split: number of time series lags, inclusion of region dummies, inclusion of moving average features, inclusion of time-series difference features, and inclusion of log-scaled participant numbers (and corresponding moving averages) in the past time series (in addition to the binary protest occurrence variables). For logistic regression I also consider whether balanced class weights are used. Optimization objective is the F1 score.\n\nAs final propensity scores I use cross-predicted probabilities from a conventional 5-fold cross-validation split, because time-series splits would not yield predictions for the start of the time series.\n\nI use _inverse propensity weighting_ (IPW) as a pure propensity score model. IPW essentially calculates a weighted mean, where more weight is given to protest days with a low probability for a protest, and to non-protest days with a high probability for a protest (see @sec-app2-ipw for details). IPW can be combined with regression, which is called _doubly robust estimation_ (DRE) and is theoretically valid if the assumptions of at least one of its parts hold (see @sec-app2-dre).\n\nI use the IPW implementation from the `DoWhy` Python package [@sharmaDoWhyEndtoEndLibrary2020], with a normalized weighting scheme (that is, the Hájek estimator) for ATT estimation. As an implementation for DRE I use the `LinearDRLearner` from the `EconML` Python package (@econml) with their `StatsModelsLinearRegression` model as regression model. For the computation of propensity scores I use `LogisticRegressionCV` from `scikit-learn` (@pedregosaScikitlearnMachineLearning2011) with the `liblinear` solver.\n\n<!--\n\n##### Propensity scores from full texts\n\ncite Wager, and causal NLP overview\n\nPredicting propensity scores from text: cite causalNLP overviews\nFor example, @bundeskriminalamtbkaLagebildLetzteGeneration2023 hypothesize that \"Die Fallzahlen unterliegen einem „wellenartigen“ Verlauf, welcher sich vornehmlich durch (das Ausbleiben von) Großveranstaltungen im gleichen Kontext erklären lässt.\"\n\npossible models:\n\n- gelectra: 100-300M parameters https://huggingface.co/deepset/gelectra-base\n- igel: 6B parameters https://huggingface.co/philschmid/instruct-igel-001\n- llama 2 german https://huggingface.co/flozi00/Llama-2-7b-german-assistant-v2\n\nfaster finetuning: https://github.com/huggingface/peft -->\n\n#### Evaluation {#sec-meth-placebo}\n\nThere is no straightforward way to evaluate causal models, since the true causal impacts are unknown.\n\n__Subsidiary metrics.__ The sections above describe the optimization and evaluation of subsidiary metrics for the individual methods:\n\n- For the regression method I evaluate the predictive quality on time-series splits in terms of bias. The best model is also used for the parts of the other methods that use regression (the individual stages of the 2SLS instrumental variables estimator, and the second stage of the doubly robust estimaor).\n- Similarly for the synthetic control I evaluate bias on time-series splits, just that the underlying regression works differently.\n- For the propensity score methods I evaluate the classification quality in terms of the F1 score in time-series splits. (But conventional splits are used for prediction.)\n\n__Placebo tests.__ An evaluation method that is specifically suited to causal models is given by placebo tests. They cannot show that a model is correct, but they can make it much more plausible [@dingFirstCourseCausal2023, ch. 16]. I use two types of placebo tests:\n\n- _Negative outcome_ [see @dingFirstCourseCausal2023, ch. 16.2.1]. Here I compute the causal impacts of protest events on newspaper coverage before the occurrence of the events. These outcomes are very similar to the outcomes that I actually want to estimate, but we know that there is no causal impact, due to the order in time. (See @sec-anticip for discussion of anticipation effects.)\n- _Negative exposure_ [see @dingFirstCourseCausal2023, ch. 16.2.2]. Here I compute the impact of random days rather than days with protest events. I assign the random treatments by sampling without replacement from the actual treatments; so the distribution of protest and non-protest days remains the same. I perform two sampling procedures: (a) sampling within each region, so that the protest-day proportions among the regions remain intact and some bias is retained; and (b) sampling across regions, so that treatments are completely random.\n\nThe expectation for the placebo tests is that the models should estimate zero causal impacts for them. If they estimate clear non-zero impacts, then the models are shown to be incorrect.\n\n\n\n{{< pagebreak >}}\n\n\n---\nexecute:\n  freeze: true\n---\n\n\n\n<!--\n\nAnalysis of the results with graphics like bargraphs and boxplots has been made. Statistical methods have been employed to compare different results. AUCs have been obtained. Minimal verification.\n+ Attention has been paid to the distribution of the data. Verification has been carried out. Attention is paid to overfitting.\n+ Results have been analysed with proper statistics. Model assumptions of statistical methods are verified or methods that do not make assumptions were employed for non-Gaussian data. Checks were made to avoid hidden overfitting.\n+ Best approach for obtaining significant results was taken while refraining from p-value hacking.\n\n -->\n\n## Results\n\n### Evaluation of methods\n\n#### Regression {#sec-res-reg}\n\nThe best model uses only a single time-series lag, as well as moving averages and difference features. Metrics for the OLS and the regularized regression models are shown in @tbl-reg-hypopt. Even though the bias is minimized, it is still substantial at around -14 articles within a timespan of one week. (This is only for time-series splits; the bias for conventional shuffled cross-validation splits is very close to 0 for all models.) A regression table with coefficients is appended in @sec-app1-reg.\n\n| Model          | Hyp. opt. obj. | RMSE          | Bias         |\n| -------------- | -------------- | ------------- | ------------ |\n| OLS            | min RMSE       | 110.6 ± 24.2  | -18.8 ± 10.4 |\n| OLS            | min bias       | 130.9 ± 21.5  | -14.3 ± 10.1 |\n| BayesianRidge  | min bias       | 119.7 ± 23.4  | -3.85 ± 15.2 |\n| LassoLarsIC    | min bias       | 118.9 ± 24.5  | -2.89 ± 15.7 |\n\n: Bias (mean error) and root mean squared error (RMSE) as a measure for variance for the best models that result from hyperparameter optimization. {#tbl-reg-hypopt}\n\n\n\n#### Instrumental variables\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=10}\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=tex}\n\\begin{tabular}{lrrrr}\n\\toprule\n{} &     cov\\_w &      cov\\_y &          wald &    corr\\_y \\\\\n\\midrule\ncovid\\_residential\\_lag0           & -0.012150 & -18.146569 &   1493.499309 & -0.205774 \\\\\ncovid\\_workplaces\\_lag0            &  0.011558 &  18.120331 &   1567.749666 &  0.205477 \\\\\ncovid\\_transit\\_stations\\_lag0      &  0.009238 &  19.079105 &   2065.295528 &  0.216349 \\\\\ncovid\\_retail\\_and\\_recreation\\_lag0 &  0.009151 &  17.686456 &   1932.761684 &  0.200557 \\\\\nweather\\_tmin\\_lag0                &  0.007102 &   5.738176 &    807.946903 &  0.065068 \\\\\ncovid\\_parks\\_lag0                 &  0.006466 &   7.383465 &   1141.847278 &  0.083725 \\\\\nweather\\_tavg\\_lag0                &  0.004919 &   3.309023 &    672.703296 &  0.037523 \\\\\ncovid\\_stringency\\_index\\_lag0      & -0.004649 & -16.934497 &   3642.728007 & -0.192030 \\\\\nweather\\_wspd\\_lag0                & -0.004630 & -10.515759 &   2271.452276 & -0.119244 \\\\\nweather\\_snow\\_lag0                & -0.004074 &  -5.183670 &   1272.279137 & -0.058781 \\\\\ncovid\\_grocery\\_and\\_pharmacy\\_lag0  &  0.003833 &  19.442073 &   5072.437659 &  0.220465 \\\\\nweather\\_wpgt\\_lag0                & -0.003388 &  -9.200765 &   2715.868619 & -0.104333 \\\\\nweather\\_tmax\\_lag0                &  0.003221 &   2.093490 &    650.008209 &  0.023739 \\\\\nweather\\_pres\\_lag0                & -0.002164 &   1.717007 &   -793.284370 &  0.019470 \\\\\nweather\\_prcp\\_lag0                &  0.001849 &   1.537868 &    831.906303 &  0.017439 \\\\\nweather\\_tsun\\_lag0                & -0.000209 &  -3.537210 &  16894.947751 & -0.040110 \\\\\n\\bottomrule\n\\end{tabular}\n```\n:::\n:::\n\n\n\\endgroup\n\nOut of the 15 potential instrumental variables, 5 pandemic instruments and 4 weather instruments have a statistically significant impact on protest occurrence (see @fig-iv-basic), but when using them in a combined regression the coefficients are much less significant. Precipitation is not among the significant variables.\n\nAutomatically binarizing the variables based on an optimally chosen threshold does not generally increase the coefficients and siginificances, and decreases them slightly in most cases. This is also true for precipiation: The optimal threshold for maximizing the covariance with protest occurrence is at prcp > 0, which is consistent with the choice in most related work (see @sec-weatherlit). I find that such binarization is not systematically better or worse than using the continuous value. (For the single regression, it slightly decreases the coefficient, and for the combined regression with other variables it slightly increases the coefficient.)\n\n::: {.cell .column-page execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![Principal components of the](report_files/figure-pdf/fig-iv-pc-output-1.svg){#fig-iv-pc}\n:::\n:::\n\n\n<!-- pc_0 at p=0.0005, pc_7 at p=0.007, and pc_11 at p=0.008 -->\n\nPrincipal component decomposition isolates three very significant components with p<0.01, while the other components have p>0.05.^[This is without adjusting for multiple testing since no hypothesis tests or thresholds are used, but the analysis is rather exploratory.] The three components are displayed in terms of the original variables in @fig-iv-pc.\n\n::: {.cell .column-page execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![Principal components of the](report_files/figure-pdf/fig-iv-pc-deseasoned-output-1.svg){#fig-iv-pc-deseasoned}\n:::\n:::\n\n\nDeseasoning the original variables and then performing separate principle component analyses on seasonal and residual parts shows that most of the significant variables are seasonal in nature; but there is also one very significant residual variable pc_resid_9 at p=0.0005 and two somewhat significant residual variables pc_resid_8 at p=0.05 and pc_resid_11 at p=0.07, while all other residual components have p>0.15 (without adjusting for multiple testing). The more significant components are broken down in @fig-iv-pc-deseasoned. The first-stage f-statistic for pc_resid_9 is f=33.82; f=2.08 for pc_resid_8; and f=2.02. According to the \"rule of thumb\" (@InstrumentalVariablesEstimation2023) the threshold for weak instruments is around f=10, so pc_resid_9 would be a strong instrument but the other ones would all be weak. The combined f-statistic of the three mentioned components is f=38.74.\n\nPlacebo tests for the first stage (the impact of the instrument on the treatment) are given in @fig-iv-1-placebo. From day 3 after the protest date there is no longer a significant impact of the instrument on the treatment\n\n::: {.cell execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![First stage placebo tests for using the principal component pc_resid_9 to instrument protest occurrence. Values for the instrument from after the protest date are used. These values cannot have an impact on protest occurrence if the instrument is valid.](report_files/figure-pdf/fig-iv-1-placebo-output-1.svg){#fig-iv-1-placebo}\n:::\n:::\n\n\n#### Synthetic control\n\n@fig-synth-hyperopt shows how the length of the pre-treatment period influences the bias of the causal estimate. Bias is most reduced at n=180, with a bias (mean error) of -0.330±1.13, and an RMSE of 65.8±2.40.\n\n::: {.cell execution_count=14}\n\n::: {.cell-output .cell-output-display}\n![Hyperparameter optimization: Influence of the pre-period length on bias (mean error).](report_files/figure-pdf/fig-synth-hyperopt-output-1.svg){#fig-synth-hyperopt}\n:::\n:::\n\n\n@fig-sc-long shows the fit for the optimized unbiased model (specifically: unbiased for estimating the -day cumulative coverage).\n\n\n\n@fig-sc-short shows the fit for a shorter pre-treatment period and with better pre-treatment fit.\n\n\n\n@fig-sc-longterm gives an impression of the long-term impact. Rolling averages are used for preprocessing, so the absolute impacts cannot directly be retrieved.\n\n::: {#fig-sc-longterm .cell execution_count=17}\n\n::: {.cell-output .cell-output-stdout}\n```\ntest\n```\n:::\n:::\n\n\n#### Propensity scores\n\nHyperparameter optimization shows that the best model is a logistic regression model without balanced class weights, using all available features (moving averages, differences, and log-scaled protest sizes), 4 days of time-series lags, and z-score standardization of all feature variables.\n\nThe baseline value for the F1 score can be calculated by setting all predictions positive. This results in F1=0.118 for my dataset.\n\nThe best logistic regression model achieves a 5-fold time-series cross-validated score of F1=0.233±0.044, while a similar model with balanced class weights achieves F1=0.213±0.017.\n\nBrief experiments with doubly robust estimation show that other than expected it gives estimates that are multiple orders of magnitudes higher than those of regression or inverse propensity weighting; it estimates chaotic time series; and it is overly sensitive to the hyperparameters that create the time series features (number of lags, inclusion of moving averages, etc.), much more than regression or IPW. I do not further investigate the problem and exclude the method from the analysis.\n\n### Placebo tests\n\n@fig-placebo-outcome shows placebo tests for the outcome for all models. Further placebo tests concern the treatments: For @fig-placebo-treatment-regional, the treatments are randomized within each region, while for @fig-placebo-treatment-global they are randomized across region (see @sec-meth-placebo).\n\n::: {.cell .column-page execution_count=18}\n\n::: {.cell-output .cell-output-display}\n![Placebo tests for the outcome. The protests event date is at x=0. To the right of it are impact estimates for subsequent days, where it is possible that there actually is a causal impact. To the left of it are the days prior to the event data, where a causal impact is not possible. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-placebo-outcome-output-1.svg){#fig-placebo-outcome}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=19}\n\n::: {.cell-output .cell-output-display}\n![Placebo tests for the treatment, where treatments are randomized but the protest day proportions among regions are not, potentially causing some bias. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-placebo-treatment-regional-output-1.svg){#fig-placebo-treatment-regional}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=20}\n\n::: {.cell-output .cell-output-display}\n![Placebo tests for the treatment, with completely randomized treatments across regions. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-placebo-treatment-global-output-1.svg){#fig-placebo-treatment-global}\n:::\n:::\n\n\n### Causal impact estimates {#sec-res-est}\n\n@fig-impact-ts and @fig-impact-ts-cum show time series of the absolute and cumulative causal impact estimates, for protest-related and non-protest-related media coverage and for all causal methods. The order of magnitude of the causal effects differs substantially between some of the methods.\n\n::: {.cell .column-page execution_count=21}\n\n::: {.cell-output .cell-output-display}\n![Causal impact estimates by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-impact-ts-output-1.svg){#fig-impact-ts}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=22}\n\n::: {.cell-output .cell-output-display}\n![Pay attention to the differences in the y-axis scale.](report_files/figure-pdf/fig-impact-ts-cum-output-1.svg){#fig-impact-ts-cum}\n:::\n:::\n\n\n@fig-impact-dims summarizes the 7-day cumulative impacts by coverage dimension and includes the impact for three specific sub-topics (see @sec-data-discourse).\n\n::: {.cell .column-page execution_count=23}\n\n::: {.cell-output .cell-output-display execution_count=23}\n![7-day cumulative causal impact estimates by method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.](report_files/figure-pdf/fig-impact-dims-output-1.svg){#fig-impact-dims}\n:::\n:::\n\n\n@fig-impact-groups-2 and @fig-impact-groups-7 break down the 2-day and 7-day cumulative impacts for the different protest groups, as estimated by the synthetic control method.\n\n::: {.cell .column-page execution_count=24}\n\n::: {.cell-output .cell-output-display execution_count=24}\n![2-day cumulative causal impact estimates by protest group, as estimated by the synthetic control method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.](report_files/figure-pdf/fig-impact-groups-2-output-1.svg){#fig-impact-groups-2}\n:::\n:::\n\n\n::: {.cell .column-page execution_count=25}\n\n::: {.cell-output .cell-output-display execution_count=25}\n![7-day cumulative causal impact estimates by protest group, as estimated by the synthetic control method. Error bars are 95% confidence intervals. Pay attention to differing y-axis scaling.](report_files/figure-pdf/fig-impact-groups-7-output-1.svg){#fig-impact-groups-7}\n:::\n:::\n\n\nTo do: Impact by online vs print newspapers; impact by dataset.\n\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nDiscussion interprets the results and places them in terms of the state-of-the-art.\n\nInterpretation of findings (e.g. in terms of a) research ethics b) limitation of the research methodology):\nExcellent and critical discussion and or reflection on all findings vis-a-vis existing research. Attention for research limitations and concrete suggestions for further research. Conclusions have been based on results, and have been taken to a higher level.\n\n -->\n\n## Discussion\n\n### Regression\n\n__Bias.__ The results affirm that OLS is unbiased for in-distribution data, but they show that it is here substantially biased across time-series splits, where it underestimates the media coverage amount one week from a given date by 14 articles. This is likely due to a generally increasing trend in media coverage in my dataset. By minimizing for bias, I have already slightly decreased the bias from 18 to 14. Regularized models generalize much better and drive down the bias to 3 or 4 articles, so it would be desirable to use them; but their coefficients are biased, and the coefficient for the treatment is the estimator for the causal impact. Future work might explore (a) using regularized models that exclude the treatment coefficient from regularization or (b) debiased regularized models such as debiased Lasso [@vandegeerAsymptoticallyOptimalConfidence2014], which is also implemented in `EconML`. Still, it is plausible that the bias is caused by the trend throughout the time-series splits, and does thus not necessarily threaten the validity of the model.\n\n__Placebo behaviour.__ The estimated effects for the pre-treatment clearly differ from zero, and indicate bias. Bias may come from omitted variables, or from a misspecified model. The estimates exhibit weekly patterns during the placebo timespan. Weekdays are already controlled for, so this suggests a lack of interaction variables involving weekdays, or very nonlinear implications of weekdays. This could be cosmetically fixed by adding interaction terms for weekdays; but there may as well be other interactions that are not visible in the time series and also require modelling. Causal random forests [@wagerEstimationInferenceHeterogeneous2017] may provide a more systematic solution. The estimates for placebo treatments do not raise concerns.\n\n### Instrumental variables\n\n__Correlation and Wald estimate.__ The correlation between the instruments and the treatment is generally very low. Wald estimates are scaled inversely by this first-stage correlations, and measurement errors make them unreliable when they are close to zero. We can assume with certainty that the first-stage correlations are smaller than 1, so the correlation between the instruments and the outcome can be taken as a lower bound for the causal impact of the protests, but they are low and we have no confidence intervals. We could compute confidence intervals for them, but they are implausibly low anyway.\n\n<!-- __Principal component analysis.__ P-values for multiple regression with all instruments are generally low, and PCA successfully helps to recover  -->\n\n- interpret principal components: weather, especially seasonal one; unclear, movement?\n- interpret deseasoned principal components: movement?; weather and stringency -> going outside?; weather\n- problem: how to argue for not really interpretable components?\n- first stage: plausible\n- order of magnitude completely unreasonable\n- placebo tests seem roughly reasonable for the protest articles but not others -- this might be a weak instrument issue\n- future work: use other weak variable methods such as Ding, that are only implemented in r\n- related work probably relies on seasonal effect, which may be legitimate with controlling, whcih they do! alternative in the absence of clear instruments might also be double machine learning\n\n__Significance of precipitation.__- weird finding that the weather is not relevant, compare with literature\n\n\n### Synthetic control {#sec-disc-synth}\n\n__Bias.__ The general prediction bias of the synthetic control method can be successfully reduced by hyperparameter optimization. The optimized hyperparameters are presumably only useful for this specific dataset. However a generally small bias does not necessarily mean a small bias for post-treatment counterfactuals, which is impossible to evaluate.\n\nAn alternative to my approach would be to minimize the bias in the pre-treatment period. Placebo tests indicate that the synthetic control method performs generally reasonably, except for the end of the pre-treatment period -- this favours the alternative approach. Minimizing bias in the pre-treatment period presumably leads to smaller fitting intervals and higher variance; this should be checked empirically in future work. The strength of the synthetic control method is to reduce bias by fitting control regions over long timespans, and this advantage would get lost by deliberately choosing shorter fitting intervals. This argument, if empirically underfed, would support my present approach.\n\n__Anticipation effects.__ @abadieSyntheticControlMethods2010 briefly discuss the presence of _anticipation effects_, and suggest to adjust the pre/post-treatment split such that the anticipation effects also lie in the post-treatment interval. This is reasonable -- but how do we know whether we actually observe anticipation effects, or rather confounders? If the increase in coverage before the protest occurrence really is a confounder, then the principle behind inverse propensity weighting (see @sec-app2-ipw) suggests that we should assign a smaller weight to the impacts of this protest, rather than adding additional anticipation effects.\n\n- An argument in favour of viewing the increased coverage as anticipation effects is that it mostly restricted to coverage that mentions protests. This suggests that the coverage may indeed be in anticipation of the protest, rather than that the protest is a reaction to the increase in coverage. Yet this cannot be said so clearly: For example, if a large protests receives a lot of previous coverage, it might attract even more participants.\n\n- I take the view that talk of \"anticipation effects\" is noncausal, since there is no physical pathway against the arrow of time. In more strictly causal terms, an increase in coverage, even if it is completely devoted to an anticipated protest, is due to factors that temporally precede the protest: The campaigning work and press relations of protest groups may play a role; journalists may deem a future large protest as more plausible when previous protests have already occurred, or when the protest organizers have a high reputation. Many of these factors may be influenced by the occurrence of previous protests, which attract more campaigners, create network effects, or bring the issue to attention in the first place. A causal analysis should then attribute the anticipation effects to the previous protests rather than the anticipcated one.\n\n- Theoretically problematic is that, of course, ultimately all protest activity is causally determined by some events that lead to the occurrence of the protest (neglecting quantum effects). Controlling for all these would yield a zero causal effect. The question is then which prior events should be included in the definition of a protest. The clear part of the answer is that the decisions of the participants to attend the protest should probably be seen as part of the protest, whereas clearly external factors such as the weather should probably not. Whether previous campaigning work and the credibility that the event is going to happen should be counted as part of the protest is, in my view, an open definitory question. If one answers it positively, then one could follow the anticipation effect theory, but only after verifying from the full texts that the increased coverage really only concerns the anticipated protest. If one answers it negatively, then one could experiment with decreasing the fitting interval until anticipation effects are removed (but this is problematic due to the incomplete data problem described below), or resort to propensity score methods.\n\n__Incomplete data.__ The synthetic control method suffers from missing data in two opposite ways:\n\n- _Large events_ may not have enough control regions to suitably model the treatment region. I have not set a threshold for the minimum number of control regions. One large event (21.03.2021) has happened in all regions, so that it had to be excluded from the analysis, leading to a slight underestimation of the average impact. It is also possible that synthetic controls based on very few control regions suffer from systematic bias.\n\n- _Small events_ may not always be present in the dataset. An unsystematic internet search for some protest dates with a predicted negative impact shows that some of them use control regions where actually some protest events took place and were just not in the dataset. Optimizing the fit in the anticipation effect timespan would weigh these \"false negative\" regions even higher, exacerbating the bias.\n\n__Weekly patterns.__ @fig-sc-long shows that the model has difficulty with modeling the weekly decrease of newspaper coverage on Sundays. Better fit can be achieved by using weekly moving averages (as done in @fig-sc-longterm). The fitted weights could be used for obtaining daily impact estimates. Future work could check whether such preprocessing actually makes a difference, and whether it is theoretically desirable.\n\n__Spillover effects.__ The synthetic control method assumes that there are no spillover effects. Their existence leads to an under-estimation of the causal effects. In principle one could also try to model these effects, but that would complicate the model a lot.\n\n### Propensity scores {#sec-disc-ps}\n\n__Bias.__ The placebo tests show that IPW consistently reduces the bias that pure correlation has, but not until zero. This is likely due to the rather low F1-score for the propensity scores. Future work may use dedicated time series forecasting or classification methods to improve performance; or may leverage text classification of prior discourse or of press releases about related events.\n\n__Extensions.__ IPW does not consider the effect of the confounders on the treatment. This is theoretically justified if the propensity scores are reliable (see @sec-app2-ipw). In the absence of good propensity scores, the model may benefit from combination with a model for the outcome. The _doubly robust estimator_ should be re-evaluated, and occcurring problems should be investigated in more depth. A nonparametric alternative would be _double machine learning_ [@chernozhukovDoubleDebiasedMachine2017]; it fits a regression model on the residuals of nonparametric propensity score and outcome models.\n\n### Impact estimates\n\n__Convergence.__ A plausible property of the causal impact is that the absolute impact converges to zero over time, and the cumulative impact thus converges to some total number of additional newspaper articles. This behaviour can be clearly seen for the protest-mentioning articles with regression, synthetic control, and to some extent with instrumental variables.\n\n__Comparisons between protest groups.__ The results are not very significant. FFF, ALG, and XR cause a statistically significant (at p<0.05) increase in protest-mentioning articles over the course of a week. The increase in other climate change articles is only significant for XR, making a backfiring effect for them very unlikely. A significant increase in more dramatic framing is seen for Fridays for Future. These are all without adjusting for multiple testing.\n\n\n\n{{< pagebreak >}}\n\n\n\n<!--\n\nConclusions answer the research questions and are sharply defined.\n\nArguing on societal implications and recommendations (if applicable):\nManagerial/societal recommendations are well-derived from findings, original and actionable.\n\n -->\n\n\n## Conclusion\n\nI find the following answers to my research questions:\n\n__How well do the methods work and how do they compare to each other?__ The instrumental variable method is not suitable for my setting of measuring the impact of single events because most instruments are very weak, and the only strong instrument clearly fails the placebo checks. The other three methods -- regression, inverse propensity weighting, and synthetic control -- all reduce bias in comparison to simple correlation. IPW exhibits consistent bias in both types of placebo tests. Regression shows bias in outcome placebo tests; the bias has weekly patterns, suggesting insufficient interaction modeling that may also involve other variables than only weekdays. The synthetic control method is relatively unbiased in placebo tests but also shows some weekly bias in outcome placebo tests. It estimates an increase in coverage already before a protest event happens; this is acceptable only if (a) this coverage anticipates the event rather than triggers it, and (b) one accepts a definition of a protest event that includes certain pre-event activity. Under these conditions and under further limitations discussed in @sec-disc-synth, the synthetic control method gives plausible causal estimates. The other methods give clearly biased results in my setting, but this may be improved.\n\n__What is the general ATT and what are the ATTs for the protest groups?__ According to the synthetic control method -- which is not clearly valid -- the ATT on cumulative regional newspaper converage in the first week after the protests is 7.XX±X.XX. The ATTs for the individual groups are ... (not significant?) TODO\n\n__Do protests distract from constructive discussion of the climate crisis?__ According to the synthetic control method -- which is not clearly valid -- the ATT is positive (according to synthetic control) or close to zero (according to regression) for the number of articles that do not mention any protest activity. This suggests that there is no backfiring effect on constructive discussion, but the results are not statistically significant at p=0.05. This also holds specifically for _Fridays for Future_ and for _Greenpeace_. For _Letzte Generation_ and _Ende Gelände_ the results suggest a non-significant decrease in coverage that does not mention protest articles; further research, for example using full texts, would be necessary to determine whether this distracts from constructive discussion. For _Extinction Rebellion_ there is a significant increase in coverage that does not mention protest activity; if the synthetic control method is valid, this is strong evidence that they do not distract from constructive discussion. (However, not adjusted for multiple testing so far TODO)\n\n### Future work\n\n__Extending the scope of the content.__ The methods can be applied to national newspaper coverage, social media data, or parliamentary speech [see @sec-data-discourse]. Topic models (see @chenHowClimateMovement2023a) can be used to get finer insights into the impact on different topics.\n\n__Improving the causal methods:__\n\n- Causal random forests [@wagerEstimationInferenceHeterogeneous2017] can be used for flexibly modeling interactions.\n- Weak instrumental variable beyond maximum likelihood limited information (LIML) can be investigated, for example Fieller–Anderson–Rubin confidence intervals [@dingFirstCourseCausal2023, ch.21.4, ch. 23.6.3]\n- For the synthetic control method, rolling average estimation can be tried out, as well as fitting for the anticipation effect. The extent of bias from missing data can be estimated using simulations. (See @sec-disc-synth.)\n- The propensity score method can be improved by (a) using dedicated time-series models and (b) using small or large language models for the estimation of propensity scores (see @sec-disc-ps). Problems with the doubly robust method should be investigated in more depth.\n- Double machine learning [@chernozhukovDoubleDebiasedMachine2017] is a promising nonparametric method to improve on both regression and propensity score models, using ideas from the two-stage least squares instrumental variable method.\n\n### Societal implications\n\nGiven my methods, it is not possible to obtain clearly unbiased results. The estimates by the synthetic control method are probably least biased. They weakly suggest that protests generally do _not_ backfire by distracting from the general discourse on climate policy and the climate crisis. This implies that protests may indeed be a suitable tool for drawing attention to their concern, at least in the case of climate protests in Germany from 2020-2022, with the possible exception of specific protest groups. The results also suggest that the various protest groups have very different effects on media coverage. Improving the causal methods may help to make less biased and more significant statements about these issues. It must also be noted that the results apply to regional newspaper coverage due to methodical reasons, but the focus of many protest groups may be on national newspaper coverage.\n\nA more actionable result is that naive media impact evaluation evaluation methods do not work:\n\n- Only counting the number of articles that explicitly mention a protest event or protest group ignores the impact on the articles that do not do so, and this impact may be substantial -- positively or negatively.\n- A correlation-based analysis is highly biased, and even an optimized regression analysis is somewhat biased. This applies to the absolute numbers as well as to comparisons between different topics, and potentially between different protest groups.\n- Even the best causal method used here exhibits many methodical flaws, but there is a lot of potential for improvement in future work.\n\nProtest groups and funding bodies that care about quantitative media impact evaluation should therefore invest into the advancement of causal methods and their application to protest events.\n\n\n\n{{< pagebreak >}}\n\n\n\n## Appendix 1: Supplementary tables and figures\n\n### Data\n\n#### The German protest registrations dataset\n\n\n\n:::{.column-page}\n\\begingroup\n\\scriptsize\\selectfont\n\\csvautobooktabular[separator=semicolon,respect sharp=true]{/Users/david/Repositories/protest-impact/report/tables/gpreg-overview.csv}\n\\endgroup\n:::\n\nTable: Overview of the German Protest Registrations (GPReg) dataset. _kpop_ = population in 1000; _cap?_ = whether the city is the political capital of its region; _reg?_ = whether the number of registered protesters (as per the organizers) is available; _obs?_ = whether the number of observed protesters (as per the police) is available; _incl?_ = whether the data is used in this thesis.\n\n\n#### Sociodemographic variables {#sec-app-sociodem}\n\n::: {.cell execution_count=27}\n\n::: {.cell-output .cell-output-display execution_count=27}\n - Anteil Personen mit MHG 0 bis 19 Jahre (%)\n - Anteil Personen mit MHG 60 Jahre und älter (%)\n - Erwerbstätigenquote Frauen (%)\n - Erwerbstätigenquote Männer (%)\n - Anteil Einpersonenhaushalte (%)\n - Haushalte mit Kindern (%)\n - Elterngeldbezug Vater (%)\n - Wahlbeteiligung, Europawahl (%)\n - Verfügbares Einkommen je EW (EUR)\n - BIP je Erwerbstätigen (EUR)\n - Armutsgefährdungsquote (Bundesmedian) (%)\n - Bevölkerungsdichte (EW je qkm)\n - Anteil der ausländischen Bevölkerung  an der Gesamtbevölkerung (%)\n - Wanderungssaldo je 10.000 EW\n - Bevölkerung 0 bis 17 Jahre (%)\n - Bevölkerung 65 Jahre und älter (%)\n - Durchschnittsalter der Bevölkerung\n - Anteil Schulabgänger/-innen mit allgem. Hochschulreife (%)\n - Anteil Schulabgänger/-innen ohne Hauptschulabschluss (%)\n - Gewerbeanmeldungen je 10.000 EW\n - Zweitstimmenanteil CDU/CSU, Bundestagswahl (%)\n - Zweitstimmenanteil SPD, Bundestagswahl (%)\n - Zweitstimmenanteil FDP, Bundestagswahl (%)\n - Zweitstimmenanteil GRÜNE, Bundestagswahl (%)\n - Zweitstimmenanteil DIE LINKE, Bundestagswahl (%)\n - Wahlbeteiligung, Bundestagswahl (%)\n - Zweitstimmenanteil AfD, Bundestagswahl (%)\n - Arbeitslosenquote (%)\n - Pkw-Bestand je 1.000 EW am 01.01.\n:::\n:::\n\n\n#### Queries for retrieving article counts {#sec-app-queries}\n\n\n\n:::{.column-page}\n\\begingroup\n\\footnotesize\\selectfont\n\\csvautobooktabular[separator=comma,respect all]{/Users/david/Repositories/protest-impact/report/tables/queries.csv}\n\\endgroup\n:::\n\nTable: Queries for retrieving article counts from online and print newspapers. The words for each category are joined by `OR` operators, and the resulting sub-queries are further combined as described in @sec-data-discourse. The query for the protest events is adapted from @wiedemannGeneralizedApproachProtest2022.\n\n### Results\n\n#### Regression {#sec-app1-reg}\n\n\\begingroup\n\\footnotesize\\selectfont\n\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n\n\n\\endgroup\n\n#### Instrumental variables {#sec-app1-iv}\n\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=31}\n\n::: {#fig-iv-basic .cell-output .cell-output-display execution_count=31}\n```{=tex}\n\\begin{tabular}{lrrrr}\n\\toprule\n{} & \\multicolumn{2}{l}{single} & \\multicolumn{2}{l}{combi} \\\\\n{} &      coef &      pval &      coef &      pval \\\\\n\\midrule\ncovid\\_parks\\_lag0                 &  0.007399 &  0.000427 &  0.018361 &  0.003697 \\\\\ncovid\\_grocery\\_and\\_pharmacy\\_lag0  &  0.002462 &  0.322549 & -0.016634 &  0.004366 \\\\\ncovid\\_workplaces\\_lag0            &  0.009365 &  0.000323 &  0.023269 &  0.005088 \\\\\nweather\\_wspd\\_lag0                & -0.004464 &  0.029327 & -0.008692 &  0.080421 \\\\\nweather\\_pres\\_lag0                & -0.001924 &  0.336838 & -0.003860 &  0.108943 \\\\\nweather\\_wpgt\\_lag0                & -0.002440 &  0.228822 &  0.003555 &  0.460912 \\\\\ncovid\\_stringency\\_index\\_lag0      & -0.002725 &  0.223267 & -0.003819 &  0.543408 \\\\\nweather\\_tmin\\_lag0                &  0.005269 &  0.009826 &  0.008303 &  0.544655 \\\\\nweather\\_tsun\\_lag0                &  0.002839 &  0.158879 &  0.002212 &  0.574665 \\\\\ncovid\\_transit\\_stations\\_lag0      &  0.007607 &  0.001031 & -0.006704 &  0.575280 \\\\\nweather\\_tmax\\_lag0                &  0.005306 &  0.009763 & -0.007860 &  0.691190 \\\\\ncovid\\_retail\\_and\\_recreation\\_lag0 &  0.006390 &  0.004574 & -0.002877 &  0.750704 \\\\\nweather\\_tavg\\_lag0                &  0.005415 &  0.008133 & -0.006334 &  0.827140 \\\\\ncovid\\_residential\\_lag0           & -0.009593 &  0.000037 &  0.000964 &  0.946339 \\\\\nweather\\_snow\\_lag0                & -0.000943 &  0.635986 & -0.000044 &  0.983521 \\\\\nweather\\_prcp\\_lag0                &  0.000650 &  0.742007 &  0.000033 &  0.988522 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nRegression coefficients and p-values for the impact of the standardized instruments on the treatment, controlling for known confounders. In the left column each instrument is regressed on its own, in the right column all instruments together; in both cases together with the known confounders. Results are sorted by p-values for the single regressions.\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=32}\n\n::: {#fig-xxx .cell-output .cell-output-display execution_count=32}\n```{=tex}\n\\begin{tabular}{lrrrr}\n\\toprule\n{} & \\multicolumn{2}{l}{single} & \\multicolumn{2}{l}{combi} \\\\\n{} &      coef &      pval &      coef &      pval \\\\\n\\midrule\ncovid\\_workplaces\\_seasonal\\_lag0            &  0.005450 &  0.018657 &  0.061583 &  0.000581 \\\\\ncovid\\_stringency\\_index\\_seasonal\\_lag0      &  0.000960 &  0.671867 & -0.037029 &  0.001844 \\\\\ncovid\\_stringency\\_index\\_resid\\_lag0         & -0.001769 &  0.393916 &  0.008695 &  0.007441 \\\\\ncovid\\_transit\\_stations\\_seasonal\\_lag0      &  0.004438 &  0.055265 & -0.067530 &  0.007920 \\\\\ncovid\\_grocery\\_and\\_pharmacy\\_resid\\_lag0     & -0.000722 &  0.787199 & -0.012199 &  0.008017 \\\\\ncovid\\_parks\\_seasonal\\_lag0                 &  0.009016 &  0.000025 &  0.054622 &  0.010427 \\\\\nweather\\_wspd\\_resid\\_lag0                   & -0.003569 &  0.075213 & -0.010740 &  0.023861 \\\\\nweather\\_pres\\_resid\\_lag0                   & -0.002234 &  0.271489 & -0.004196 &  0.088856 \\\\\ncovid\\_residential\\_resid\\_lag0              & -0.007442 &  0.002169 & -0.013473 &  0.122249 \\\\\ncovid\\_grocery\\_and\\_pharmacy\\_seasonal\\_lag0  &  0.004132 &  0.089332 & -0.028145 &  0.136855 \\\\\nweather\\_wpgt\\_resid\\_lag0                   & -0.001501 &  0.455060 &  0.006588 &  0.168684 \\\\\nweather\\_tmin\\_seasonal\\_lag0                &  0.008488 &  0.000049 &  0.097790 &  0.170820 \\\\\ncovid\\_residential\\_seasonal\\_lag0           & -0.006068 &  0.006505 &  0.039590 &  0.327475 \\\\\nweather\\_tavg\\_seasonal\\_lag0                &  0.008388 &  0.000055 & -0.118111 &  0.363049 \\\\\nweather\\_snow\\_seasonal\\_lag0                & -0.003542 &  0.098285 & -0.002250 &  0.414848 \\\\\ncovid\\_transit\\_stations\\_resid\\_lag0         &  0.005963 &  0.007810 &  0.005475 &  0.415100 \\\\\ncovid\\_parks\\_resid\\_lag0                    &  0.004218 &  0.039431 &  0.001542 &  0.608708 \\\\\nweather\\_wpgt\\_seasonal\\_lag0                & -0.003412 &  0.178187 & -0.003289 &  0.625309 \\\\\nweather\\_tmax\\_seasonal\\_lag0                &  0.008301 &  0.000070 &  0.026883 &  0.708668 \\\\\nweather\\_prcp\\_seasonal\\_lag0                &  0.003856 &  0.094078 & -0.001066 &  0.745277 \\\\\ncovid\\_workplaces\\_resid\\_lag0               &  0.005477 &  0.046993 & -0.001840 &  0.813105 \\\\\nweather\\_tsun\\_resid\\_lag0                   &  0.001202 &  0.549456 &  0.000744 &  0.823436 \\\\\nweather\\_pres\\_seasonal\\_lag0                & -0.000553 &  0.802315 &  0.000559 &  0.888299 \\\\\nweather\\_prcp\\_resid\\_lag0                   &  0.000378 &  0.849946 &  0.000324 &  0.889127 \\\\\nweather\\_tmin\\_resid\\_lag0                   &  0.000389 &  0.846085 & -0.000928 &  0.895813 \\\\\nweather\\_tsun\\_seasonal\\_lag0                &  0.006458 &  0.001907 & -0.001517 &  0.912921 \\\\\ncovid\\_retail\\_and\\_recreation\\_seasonal\\_lag0 &  0.004592 &  0.039789 & -0.002204 &  0.927198 \\\\\nweather\\_tavg\\_resid\\_lag0                   &  0.001155 &  0.565010 & -0.001125 &  0.934602 \\\\\nweather\\_wspd\\_seasonal\\_lag0                & -0.007099 &  0.005172 & -0.000372 &  0.958567 \\\\\nweather\\_snow\\_resid\\_lag0                   & -0.000248 &  0.900731 & -0.000097 &  0.963113 \\\\\nweather\\_tmax\\_resid\\_lag0                   &  0.001626 &  0.418105 &  0.000206 &  0.983523 \\\\\ncovid\\_retail\\_and\\_recreation\\_resid\\_lag0    &  0.004869 &  0.027698 & -0.000074 &  0.990800 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nhum\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=33}\n\n::: {#fig-zyz .cell-output .cell-output-display execution_count=33}\n```{=tex}\n\\begin{tabular}{lrrrr}\n\\toprule\n{} & \\multicolumn{2}{l}{single} & \\multicolumn{2}{l}{combi} \\\\\n{} &      coef &      pval &      coef &      pval \\\\\n\\midrule\npc\\_0  & -0.008100 &  0.000296 & -0.008117 &  0.000483 \\\\\npc\\_7  & -0.006557 &  0.005781 & -0.006781 &  0.005519 \\\\\npc\\_11 & -0.005450 &  0.007106 & -0.005409 &  0.007735 \\\\\npc\\_10 &  0.004375 &  0.040146 &  0.004072 &  0.056826 \\\\\npc\\_9  &  0.004529 &  0.027047 &  0.003862 &  0.061649 \\\\\npc\\_13 & -0.003495 &  0.082768 & -0.003278 &  0.104029 \\\\\npc\\_8  &  0.004386 &  0.042165 &  0.003447 &  0.115879 \\\\\npc\\_3  &  0.002674 &  0.180666 &  0.002644 &  0.185393 \\\\\npc\\_12 & -0.002423 &  0.231402 & -0.002373 &  0.241068 \\\\\npc\\_14 &  0.001392 &  0.482769 &  0.001196 &  0.546347 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nhom\n:::\n:::\n\n\n\\endgroup\n\n\\begingroup\n\\footnotesize\\selectfont\n\n::: {.cell execution_count=34}\n\n::: {#fig-iv-pc-season .cell-output .cell-output-display execution_count=34}\n```{=tex}\n\\begin{tabular}{lrrrr}\n\\toprule\n{} & \\multicolumn{2}{l}{single} & \\multicolumn{2}{l}{combi} \\\\\n{} &      coef &      pval &      coef &      pval \\\\\n\\midrule\npc\\_seasonal\\_12 & -0.009420 &  0.000010 & -0.010101 &  0.000022 \\\\\npc\\_resid\\_9     & -0.008289 &  0.000054 & -0.007300 &  0.000474 \\\\\npc\\_seasonal\\_0  & -0.007624 &  0.000558 & -0.005981 &  0.012243 \\\\\npc\\_seasonal\\_9  & -0.004470 &  0.047511 & -0.005710 &  0.027602 \\\\\npc\\_seasonal\\_10 & -0.004035 &  0.055418 & -0.004472 &  0.047731 \\\\\npc\\_resid\\_8     & -0.002603 &  0.196868 & -0.004066 &  0.051111 \\\\\npc\\_seasonal\\_1  & -0.005341 &  0.014663 & -0.004343 &  0.062980 \\\\\npc\\_resid\\_11    &  0.003080 &  0.122812 &  0.003674 &  0.068053 \\\\\npc\\_seasonal\\_6  &  0.004209 &  0.062713 &  0.004499 &  0.077235 \\\\\npc\\_resid\\_7     &  0.002354 &  0.239931 &  0.002818 &  0.161282 \\\\\n\\bottomrule\n\\end{tabular}\n```\n\nRegression coefficients and p-values for the impact of the principal components of the seasonal and residual (deseasoned) variables on the treatment, controlling for known confounders. In the left column each instrument is regressed on its own, in the right column all instruments together; in both cases together with the known confounders. Results are sorted by p-values for the combined regression.\n:::\n:::\n\n\n\\endgroup\n\n\n\n{{< pagebreak >}}\n\n\n\n## Appendix 2: Theory {#sec-reg}\n\nI want to determine the _Average Treatment Effect on the Treated (ATT)_ $\\tau_T$ for different protest groups[^CATT], and along multiple dimensions of newspaper coverage. I am not interested in the _Average Treatment Effect_ [on the whole population] that is often denoted by $\\tau$, so I write $\\tau:=\\tau_T$.\n\n[^CATT]: This could also be framed as the _Conditional ATT_ (CATT), because the treatment effect is conditional on which group has protested on the day. I prefer to frame it as multiple separate ATTs. This has the benefit that I can control (where the methods allows for it) for the occurrence of other treatments on the same day, and thus better isolate the effects of single protest groups.\n\nThe ATT is generally defined as follows [@dingFirstCourseCausal2023, ch. 13]:\n\n$$\n\\tau = E(Y|W=1) - E(Y(0) | W=1)\n$$\n\nThe treatment units are _days_, with a treatment vector $W = [W_1, ..., W_m], m = |G|$ containing the treatments for each group (that is, whether the given group has protested on that day), and an outcome vector $Y = [Y_1, ..., Y_n], n=|Y|$ containing the number of articles published on that day for each dimension of coverage. We can write this as follows:\n\n$$\n\\tau_{g,d} = E(Y_d|W_g=1) - E(Y_d(0) | W_g=1)\n$$\n\n### Regression {#sec-app2-reg}\n\nThe following assumptions allow us to use regression to determine the ATT:\n\n- __Unconfoundedness__, $W \\perp\\!\\!\\!\\perp Y(0) | X$: The counterfactual outcome if there was no treatment is independent from the actual treatment. It is not plausible that this assumption actually holds, but regression will just serve as a baseline model. This is also known as _ignorability_, _selection on observables_, or _conditional independence_.\n- __Overlap__, $e(X) < 1$ for the propensity score $e(X) = P(W=1|X)$: The treatment assignment is not deterministic.\n\nUnder these assumptions, we can identify $\\tau$ as follows [see @dingFirstCourseCausal2023, ch. 13 for proof]:\n\n$$\n\\begin{aligned}\n\\tau &= E(Y|W=1) - E(Y(0)|W=1) \\\\\n&= E(Y|W=1) - E(E(Y|W=0,X) | W=1)\n\\end{aligned}\n$$ {#eq-reg-indent}\n\nWe can specify a linear model for the expected outcome:\n\n$$\nE(Y|W,X) = \\beta + \\beta_W W + \\beta_X X\n$$ {#eq-reg-lin-model}\n\nWe can use @eq-reg-lin-model in @eq-reg-indent:\n\n$$\n\\begin{aligned}\n\\tau &= E(Y|W=1) - E(E(Y|W=0,X) | W=1) \\\\\n&= E(E(Y|W,X)|W=1) - E(E(Y|W=0,X) | W=1) \\\\\n&= E(\\beta + \\beta_W + \\beta_X X |W=1) - E(\\beta + \\beta_X X | W=1) \\\\\n&= \\beta_W\n\\end{aligned}\n$$ {#eq-reg-beta}\n\nThe coefficient $\\beta_W$ can be estimated via _Ordinary Least Squares_ (OLS) regression, and then serve as estimate for the ATT. Specifically, the linear regression model\n\n$$\nE(Y_d|W_g,X) = \\beta + \\beta_W W_g + \\beta_X X\n$$\n\nallows for the estimation of the ATT $\\hat\\tau_{g,d}=\\hat\\beta_W$ for all protest groups $g \\in G$ and outcome dimensions $d \\in D$. Standard errors and confidence intervals can also be obtained from the OLS procedure. The ATT is here identical to the ATE, because \"the linear model assumes constant causal effects across units\" [@dingFirstCourseCausal2023, p. 165].\n\n### Instrumental variables {#sec-app2-iv}\n\nThere are three conditions that make a variable $Z$ a valid instrument [@dingFirstCourseCausal2023, p. 279]:\n\n1. $Z$ is a random or almost random.\n2. $Z$ changes the distribution of the treatment $W$.\n3. $Z$ does not directly influence $Y$, but only indirectly via $W$ (_exclusion restriction_).\n\n#### Indirect least squares\n\nIn the case of a single instrument and a single treatment, we can use indirect least squares [@dingFirstCourseCausal2023, ch. 23.6.2; @pischkeLabourEconomicsPhD2019, slides on instrumental variables; @facurealvesCausalInferenceBrave2022, ch. 8]. It is also known simply as _instrumental variable_ method, and -- modified for the special case of a binary instrument -- as _Wald estimator_ [@dingFirstCourseCausal2023, ch. 21].\n\nTo estimate the ATT, we can set up the following linear model (sometimes designated as _structural equation_):\n\n\\begin{align}\nE(Y|W,U) &= \\beta + \\beta_W W + \\beta_U U && \\text{Structural equation} \\label{eqstruct}\n\\end{align}\n\nThis is very similar to @eq-reg-lin-model, only that now the unmeasured confounders are included rather than the known covariates. (We can leave out the known confounders X from the model without loss of generality, because when we do not include them they will also be unknown confounders, and can thus be treated as pasrt of the unknown confounders U.)\n\n@eq-reg-beta identifies the ATT as $\\tau=\\beta_W$ and is also applicable here. The assumptions are unconfoundedness and overlap (see @sec-app2-reg). In the context of regression, we have dealt with unconfoundedness given the known confounders $W \\perp\\!\\!\\!\\perp Y(0) | X$ which is implausible due to potential hidden confounders; but the equation here is not about $X$ but about $U$, so the analogous assumption is $W \\perp\\!\\!\\!\\perp Y(0) | U$, that is, unconfoundedness _given the unknown confounders_, which trivially applies.\n\nIn addition to the structural equation, we can set up two further equations that describe the impact of the instrument Z on both W and Y:\n\n\\begin{align}\nE(W|Z,U) &= \\alpha + \\alpha_Z Z + \\alpha_U U && \\text{First stage} \\\\\nE(Y|Z,U) &= \\gamma + \\gamma_Z Z + \\gamma_U U && \\text{Reduced form}\n\\end{align}\n\nThe randomization assumption implies that the instrument is not correlated with any variables that are not causally affected by the instrument. The exclusion restriction formulates that there is no path from $Z$ to $Y$ other than through $W$. Together, they imply that $Z$ is independent from $U$ in both equations. Since $Z$ is independent from the other predictor variables, the calculation of the coefficients $\\alpha_Z$ and $\\gamma_Z$ resolves to the simpler case of univariate OLS, where we have $\\alpha_Z=\\frac{Cov(W,Z)}{Var(Z)}$ and $\\gamma_Z=\\frac{Cov(Y,Z)}{Var(Z)}$:\n\n\\begin{align}\nE(W|Z,U) &= \\alpha + \\frac{Cov(W,Z)}{Var(Z)} Z + \\alpha_U U && \\text{First stage} \\\\\nE(Y|Z,U) &= \\gamma + \\frac{Cov(Y,Z)}{Var(Z)} Z + \\gamma_U U && \\text{Reduced form} \\label{eqreduced}\n\\end{align}\n\nSubstitution and reordering shows how $\\beta_W$ can be calculated from the covariances:\n\n\\begin{align}\nE(Y|Z,U) &= \\gamma + \\frac{Cov(Z,\\beta + \\beta_W W + \\beta_U U)}{Var(Z)} Z + \\gamma_U U && \\text{Substitute \\eqref{eqstruct} into \\eqref{eqreduced}} \\\\\n&= \\gamma + \\beta_W \\frac{Cov(Z, W)}{Var(Z)} Z + \\gamma_U U \\label{eqresult} \\\\\n0 &= \\beta_W \\frac{Cov(W,Z)}{Var(Z)} Z - \\frac{Cov(Y,Z)}{Var(Z)} Z && \\text{Subtract \\eqref{eqresult} from \\eqref{eqreduced}} \\\\\n&= (\\beta_W Cov(Z,W) - Cov(Y,Z)) \\frac{Z}{Var{Z}} \\\\\n&= (\\beta_W Cov(Z,W) - Cov(Y,Z)) \\\\\n\\beta_W &= \\frac{Cov(Y,Z)}{Cov(Z,W)}\n\\end{align}\n\nIn @eq-reg-beta we had a regression model of the same structure, and showed that the ATT can be estimated by the coefficient for the treatment, so we have:\n\n\\begin{align}\n\\tau_{g,d}=\\frac{Cov(Y_d,Z)}{Cov(Z,W_g)}\n\\end{align}\n\nA corresponding estimator is given using the sample covariances. Estimators for the variance are deduced in @dingFirstCourseCausal2023 [ch. 21].\n\nImpressively, the instrument allows us to control for confounders without needing to specify them -- if the strong assumptions of randomization and exclusion actually hold.\n\n#### Two-stage least squares\n\nAn alternative to indirect least squares that extends to multiple instruments and treatments is the _two-stage least squares_ (TSLS) estimator. It involves two OLS regression steps:\n\n1. Estimate $E(W|Z) = \\alpha + \\alpha_Z Z$ and obtain predictions $\\hat W$. These are the \"random components\" of $W$.\n2. Estimate $E(Y,\\hat W) = \\beta + \\beta_W \\hat W$, and obtain the causal estimate $\\hat\\tau = \\hat\\beta_W$.\n\nIn the case of a single instrument and a single treatment, two-stage least squares is identical to indirect least squares [@dingFirstCourseCausal2023, ch. 23].\n\n__Including covariates:__ Instrumental variable methods do not generally require the specification of any covariates or confounders. In the case that randomization holds only conditionally, we need to control for all covariates conditional to which the instrument is random. Besides this, adding covariates may also be useful for reducing variance and increasing statistical power. @torgovitskyWhenTSLSActually point out that adding covariates causes the estimate to differ from the LATE, which poses a problem that has often been ignored in practice.\n\n__Weak instrumental variables:__ When the instruments are weak, indirect and two-stage least squares become biased. There are adaptations specifically for weak instruments. Instead of indirect least squares, the _Weak IV_ estimator can be used [@dingFirstCourseCausal2023, ch. 21 & 23]; and an alternative to two-stage least squares is _limited information maximum likelihood_ [LIML; see @pischkeLabourEconomicsPhD2019, slides on weak instruments].\n\n#### Local treatment effects\n\nA subtlety is that all of the above methods do not actually give us the ATT or ATE, but rather the _Local_ Average Treatment Effect LATE, that is, the effect of those days where the instrument actually had an impact on the outcome. This can be intuitively explained by deducing the estimator from the notions of _compliers_, _defiers_, _always-takers_, and _never-takers_: Using the example of rainfall as a binary instrument for protest days, we have\n\n- _always-takers_: days where there would be a protest, regardless of rainfall;\n- _never-takers_: days where there would be no protest, regardless of rainfall;\n- _compliers_: days where the rainfall _positively_ determines whether there is a protest:\n  - non-rainy days with protests that would not have occurred if there had been rainfall and\n  - rainy days without protests where without rainfall there would have been protests;\n- _defiers_: days where the rainfall _negatively_ determines whether there is a protest. This is often implausible (also in our context) and therefore it is assumed that there are no defiers.\n\nIt can be proven that indirect least squares and other instrumental variable methods only estimate the treatment effect for the group of compliers [@dingFirstCourseCausal2023, ch. 21; @pischkeLabourEconomicsPhD2019, slides on the LATE theorem; @facurealvesCausalInferenceBrave2022, ch. 9].\n<!-- In the deduction above, this assumption is implicit in the form of the regression model (TODO: is it?), where $Z$ is assumed to have a constant effect on $Y$. -->\n\nIn the case of protests, an instrumental variable approach would ignore the effect of protests where the organizers and participants are very weather-resistant. If such protests are systematically more or less effective than the weather-complying protests, this will introduce bias. For Covid restrictions as an instrument, the instrumental variable approach would ignore the effect of protests that violate the restrictions.\n\n<!-- this is reasonably negligible because the climate protest movement is not known to have committed such violations. -->\n\n<!-- manually or https://www.pywhy.org/dowhy/v0.10/dowhy.causal_estimators.html#module-dowhy.causal_estimators.instrumental_variable_estimator -->\n\n### Synthetic control\n\nI assume that the outcome of each region $r \\in R$ is given by a _factor model_ [inspired by @abadieSyntheticControlMethods2010]:\n\n$$\nE(Y_r|X_r,W_r,U) = \\beta + \\beta_X X_r + \\beta_W W_r + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_r U^T)_{ij}\n$$\n\nwhere $Y_r$ is the outcome for region $r$, $X_r$ is a vector of known covariates of region $r$, $U$ is a vector of unknown global confounders, and $X_r U^T$ is a $|X_r|\\times |U|$ matrix of interactions between the regional covariates and the unknown global confounders; $\\beta, \\beta_X, \\beta_W, \\beta_U, \\beta_{UX}$ are global parameters of the model (with sizes that correspond to the respective variables) that specify the impact of the variables on the outcome variable; and $\\epsilon_r$ an error term with mean $0$.\n\nThe model allows for time-variant hidden confounders $U$ that are the same across all regions. And through the term $X_r U^T$ it also allows for interactions of the confounders with the regional covariates, including static ones as well as time-variant ones.\n\nThe counterfactual is given by omitting the impact of the treatment:\n\n$$\nE(Y_r(0)|X_r,W_r,U) = \\beta + \\beta_X X_r + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_r U^T)_{ij}\n$$\n\nLet $R_0 = \\{r \\in R|W_r=0\\}$ be the set of control regions. Assume the existence of scalar weights $\\gamma_s$ for all $s \\in R_0$ that allow the interpolation of the covariates of the treatment region from the covariates of the control region:\n\n\\begin{align}\n\\sum_{s \\in R_0} \\gamma_s = 1 \\text{ and } \\gamma_s \\geq 0\\: \\forall s \\in R_0 && \\text{Convexity} \\label{eq-convex} \\\\\nE\\left(\\sum_{s \\in R_0} \\gamma_s X_s\\right) = E(X_r) && \\text{Interpolation} \\label{eq-interpol}\n\\end{align}\n\nThen by interpolating the counterfactual from the control regions we obtain the estimator $\\hat Y_r(0) = \\sum_{s \\in R_0} \\gamma_s Y_s$:\n\n::: {.column-page}\n\\begin{align}\nE(\\hat Y_r(0)) &= E\\left\\{ \\sum_{s \\in R_0} \\gamma_s Y_s \\right\\} \\\\\n&= E\\left\\{ \\sum_{s \\in R_0} \\gamma_s E(Y_s|X_s,W_s,U) \\right\\} \\\\\n&= E\\left\\{ \\sum_{s \\in R_0} \\gamma_s E\\left[\\beta + \\beta_X X_s + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_s U^T)_{ij} \\right] \\right\\} \\\\\n&= E\\left\\{ \\beta + \\beta_X E\\left(\\sum_{s \\in R_0} \\gamma_s  X_s\\right) + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} \\left[E\\left(\\sum_{s \\in R_0} \\gamma_s  X_s\\right) U^T\\right]_{ij} \\right\\} && \\text{by assumption \\eqref{eq-convex}} \\\\\n&= E\\left\\{ \\beta + \\beta_X X_r + \\beta_U U + \\sum_{i=0}^{|X_r|} \\sum_{j=0}^{|U|} \\beta_{UX,ij} (X_r U^T)_{ij} \\right\\} && \\text{by assumption \\eqref{eq-interpol}} \\\\\n&= E\\left\\{ Y_r(0) \\right\\}\n\\end{align}\n:::\n\nThe ATT can thus be estimated by:\n\n\\begin{align}\n\\tau_r &= E(Y_r|W=1) - E(Y_r(0)|W=1) \\\\\n&= E(Y|W=1) - E(\\sum_{s \\in R_0} \\gamma_s Y_s|W=1) \\\\\n&= E(Y|W=1) - \\sum_{s \\in R_0} \\gamma_s E(Y_s|W=1)\n\\end{align}\n\nIn this setting it is not straightforward to single out the effect of different protest groups because there is no way to directly control for co-occurring protest events; therefore I only compute the average effect for all groups.\n\nWeights $\\gamma$ can be obtained by \"upside down regression\" [@facurealvesCausalInferenceBrave2022, ch. 15] to estimate $E(X_r)=\\gamma_1 X_1 + ... + \\gamma_n X_n$ for the control regions $1...n=R_0$. In principle, we can use OLS or nonnegative least squares (NLS) for the estimation. However, this allows the model to _extrapolate_ rather than _interpolate_ between the control regions. To estimate weights that interpolate (that is, they are positive and sum up to 1), we can define a loss function $\\left|X_r - \\sum_{s \\in R_0} \\gamma_s X_s\\right|$ and minimize it subject to the positivity and sum constraints on the weights, for example by using quadratic programming as minimization technique [@facurealvesCausalInferenceBrave2022, ch. 15; @abadieSyntheticControlMethods2010].\n\nSince the available control regions vary from day to day, many regressions have to be run. $X_r$ may be chosen to either represent (static) fundamental data about the regions that is suspected to be predictive of treatment or outcome [@abadieSyntheticControlMethods2010]; or it can just be previous time-series information about the outcome and other variables [@facurealvesCausalInferenceBrave2022, ch. 15].\n\n@fermanSyntheticControlsImperfect2021 suggest that demeaning the data based on the pre-treatment period makes the synthetic control method more robust.\n\n### Propensity scores {#sec-app2-ps}\n\nThe propensity score $e(X) = P(W=1|X)$ is the probability of the treatment given the confounding variables. It is often computed using logistic regression, but any machine learning model that produces reasonable probability estimates can be used; this makes it more flexible than linear models.\n\nVarious methods make use of propensity scores, mainly: _Propensity stratification, inverse propensity weighting, and propensity matching_. Propensity stratification requires the specification of a hyperparameter $k$ for the number of strata, with no reliable methods available for making a suitable choice [@dingFirstCourseCausal2023, ch. 11]. Propensity matching is very intuitive but also very problematic because it is usually not possible to establish a perfect matching between treated and control units, and any matching method introduces imbalance, so that the imbalance may even be increased rather than reduced [@kingWhyPropensityScores2019]. Therefore I focus on inverse propensity weighting.\n\n#### Inverse propensity weighting {#sec-app2-ipw}\n\nInverse propensity weighting (IPW) gives every sample a weight that is inverse to the propensity score: $\\frac{1}{e(X)}$ for treated units and $\\frac{1}{1-e(X)}$ for control units. We use the same assumptions as for regression (@sec-app2-reg):\n\n- __Unconfoundedness__, $W \\perp\\!\\!\\!\\perp Y(0) | X$: The counterfactual outcome if there was no treatment is independent from the actual treatment. (For @eq-prop we need the same not only for $Y(0)$ but also for $Y(1)$; but the calculation of the _ATT_ does not require this.)\n- __Overlap__, $e(X) < 1$: The treatment assignment is not deterministic.\n\nThen we can see that propensity weighting reveals the counterfactual outcome [@barterRebeccaBarterIntuition2017; @dingFirstCourseCausal2023, ch. 11]:\n\n$$\n\\begin{aligned}\nE\\left(\\frac{WY}{e(X)}\\right) &= E\\left[E\\left(\\frac{WY}{e(X)}|X\\right)\\right] \\\\\n&= E\\left[E\\left(\\frac{WY(1)}{e(X)}|X\\right)\\right] \\\\\n&= E\\left[\\frac{E(W|X)E(Y(1)|X)}{e(X)}\\right] && \\text{due to unconfoundedness} \\\\\n&= E\\left[\\frac{P(W=1|X)E(Y(1)|X)}{e(X)}\\right] && \\text{because W is binary} \\\\\n&= E\\left[\\frac{e(X)Y(1)}{e(X)}\\right] \\\\\n&= E(Y(1))\n\\end{aligned}\n$$ {#eq-prop}\n\nAnalogously we have $E(\\frac{(1-W)Y}{1-e(X)}) = E(Y(0))$. We can extend this for the counterfactual of the treated units $E(Y(0)|W=1) = E\\left(\\frac{e(X)}{P(W=1)}\\frac{(1-W)Y}{1-e(X)}\\right)$, see @dingFirstCourseCausal2023 [p. 166] for the proof.\n\nThis gives us an estimator for the ATT:\n\n$$\n\\begin{aligned}\n\\tau &= E(Y|W=1) - E(Y(0)|W=1) \\\\\n&= \\hat{\\bar{Y}}(1) - \\frac{1}{n} \\sum_{i=1}^{n} \\frac{e(X_i)}{P(W_i=1)}\\frac{(1-W_i)Y_i}{1-e(X_i)}\n\\end{aligned}\n$$ {#eq-prop-est}\n\nThe estimator from @eq-prop-est is reported to have various problems in practice, therefore I use the alternative _Hájek estimator_, which is empirically more stable [@dingFirstCourseCausal2023, pp. 146, 166; @abdiaPropensityScoresBased2017]:\n\n$$\n\\tau^{\\text{Hájek}} = \\hat{\\bar{Y}}(1) - \\frac{1}{n} \\frac{\\sum_{i=1}^{n}\\frac{e(X_i)}{P(W_i=1)}\\frac{(1-W_i)Y_i}{1-e(X_i)}}{\\sum_{i=1}^{n}\\frac{e(X_i)}{P(W_i=1)}\\frac{(1-W_i)}{1-e(X_i)}}\n$$\n\n#### Doubly robust estimation {#sec-app2-dre}\n\nBoth regression (@sec-reg) and IPW rely on the same assumptions of overlap and conditional unconfoundedness. They can be combined into a single estimator known as _augmented inverse propensity weighting_ or as the _doubly robust estimator_. It is consistent if at least one of the models is correctly specified -- that is, if either the treatment or the outcome is consistently estimated. If both models are correct, then it helps reducing the bias of the regression estimator, and reducing the variance of the propensity score estimator.\n\nDoubly robust estimation is defined, motivated, and proven in @dingFirstCourseCausal2023 [ch. 12, ch. 13.2].\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n## References\n\n<!--\n\nReferences and bibliography cover all relevant publications and state-of-the-art. Citing is done at appropriate points in the text.\n\n -->\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "report_files/figure-pdf"
    ],
    "filters": []
  }
}
