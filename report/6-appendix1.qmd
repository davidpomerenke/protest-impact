## Supplementary tables and figures

### Data

#### The German protest registrations dataset

The following table gives an overview of the German Protest Registrations (GPReg) dataset. _kpop_ = population in 1000; _cap?_ = whether the city is the political capital of its region; _reg?_ = whether the number of registered protesters (as per the organizers) is available; _obs?_ = whether the number of observed protesters (as per the police) is available; _incl?_ = whether the data is used in this thesis.

```{python}
# | echo: False

from IPython.display import Markdown
from src.paths import tables
from src.data.protests.german_protest_registrations.data_description import (
    pretty_overview_table,
)

df = pretty_overview_table(symbol="x")
# Markdown(df.to_markdown(index=False))
df.to_csv(tables / "gpreg-overview.csv", sep=";")
```

:::{.column-page}
\begingroup
\scriptsize\selectfont
\csvautobooktabular[separator=semicolon,respect sharp=true]{/Users/david/Repositories/protest-impact/report/tables/gpreg-overview.csv}
\endgroup
:::

#### Queries for retrieving article counts {#sec-app-queries}

The following table shows the queries for retrieving article counts from online and print newspapers. The words for each category are joined by `OR` operators, and the resulting sub-queries are further combined as described in @sec-data-discourse. The query for the protest events is adapted from @wiedemannGeneralizedApproachProtest2022.

```{python}
# | echo: False

from IPython.display import Markdown
from src.paths import tables
from src.data.protests.keywords import climate_query_table

df = climate_query_table()
# Markdown(df.to_markdown(index=False))
df.to_csv(tables / "queries.csv", index=False)
```

The table below shows the queries for retrieving article counts from online and print newspapers. The words for each category are joined by `OR` operators, and the resulting sub-queries are further combined as described in @sec-data-discourse. The query for the protest events is adapted from @wiedemannGeneralizedApproachProtest2022.

\begingroup
\footnotesize\selectfont
\csvautobooktabular[separator=comma,respect all]{/Users/david/Repositories/protest-impact/report/tables/queries.csv}
\endgroup

### Results

#### Regression {#sec-app1-reg}

\begingroup
\footnotesize\selectfont
```{python}
# | label: fig-reg-details
# | fig-cap: "Detailed results for the best regression model from @sec-res-reg. Dependent variable is the absolute number of articles mentioning climate change from the treatment date and the following day. Due to including time series lags there are overall 140 parameters plus a constant term, so only the 20 parameters with lowest p-values are displayed. Note that for the weekday dummies the first value (Friday) is dropped and the other dummies are to be interpreted in relation to it."
# | echo: False

import pandas as pd
from IPython.display import display
import warnings
from src.models.regression.hyperopt import best_regression

warnings.simplefilter(action='ignore', category=FutureWarning)

tables = best_regression().summary().tables
display(tables[0])
# results_as_html = tables[1].as_html()
# df = pd.read_html(results_as_html, header=0, index_col=0)[0]
# display(df.sort_values("P>|z|").head(20).sort_index())
```
\endgroup

\begingroup
\footnotesize\selectfont
```{python}
# | fig-cap: Part 2 of the previous figure (some rendering issue TODO)
# | echo: False

import pandas as pd
from IPython.display import display
import warnings
from src.models.regression.hyperopt import best_regression

warnings.simplefilter(action='ignore', category=FutureWarning)

tables = best_regression().summary().tables
results_as_html = tables[1].as_html()
df = pd.read_html(results_as_html, header=0, index_col=0)[0]
display(df.sort_values("P>|z|").head(20).sort_index())
```
\endgroup

\begingroup
\footnotesize\selectfont
```{python}
# | label: fig-reg-details-occ
# | fig-cap: "Detailed results for the best regression model from @sec-res-reg: Coefficients for the occurrence of a protest."
# | echo: False
display(
    df[(df.index.str.startswith("occ") & df.index.str.endswith("lag0"))].sort_index()
)
```
\endgroup

#### Propensity scores {#sec-app1-ps}

\begingroup
\footnotesize\selectfont
```
Nordrhein-Westfalen, Wednesday, 13. May 2020 (6 days ago)
has protests: no
Headlines:
EU-Klimaziel: Union will bei Lasten neu verteilen
EU-Klimaziel: Union will bei Lasten neu verteilen
CDU und CSU bremsen europäischen Klimaschutz
Programmieren gegen den Klimawandel
Protest gegen "Führerscheinfalle"
Klimaschutz-Lasten in EU fair verteilen
Klimaschutz macht keine Pause
Merkel will Lastenteilung beim EU-Klimaschutz neu verhandeln

Nordrhein-Westfalen, Thursday, 14. May 2020 (5 days ago)
has protests: no
Headlines:
CDU setzt auf Klimaschutz: Elektroauto für die Gemeinde
Preise für Klimaschutz, Fairness oder Toleranz
Kreis drückt beim Klimaschutz aufs Tempo
Eine Million Euro fließt in Klimaschutz
Umweltschützer: 1,2 Millionen Unterschriften für EU-Paket rund um Klimaschutz

Nordrhein-Westfalen, Friday, 15. May 2020 (4 days ago)
has protests: no
Headlines:
Gutachten: Pkw-Maut im Bund wäre Klimaschutz
Gutachten: Bundesweite Pkw-Maut wäre Klimaschutz
Petition gegen die Rheinspange
Petition gegen die Rheinspange
Neue Klimaschutzbeauftragte im Vor-Ort-Einsatz
Mahnwache " Datteln 4 stoppen"
Umweltrat kritisiert deutsche Klimapolitik
Neue Klimaschutzbeauftragte im ersten Einsatz
Krise bringt Klimaschutz
Decker arbeitet weiter klimaneutral
Klimawandel im Fokus
Umweltministerkonferenz: Klimaschutz in Wirtschaftshilfen verankern

Nordrhein-Westfalen, Saturday, 16. May 2020 (3 days ago)
has protests: yes
number of protests: 1
Protests:
GP: On 16 May 2020, people protested in Koln for more space for cyclists
  and pedestrians during the coronavirus pandemic.
  The protest was organised, amongst others, by ADFC, Greenpeace and VCD.
Headlines:
Gartenschau soll klimaneutral sein
Patriotismus ist wieder brutal
Petition gegen die Rheinspange
Verständnis, Proteste und nötige Opfer
Kreis fördert privaten Klimaschutz
Fit für den Klimaschutz
Klimaschutz für die Hosentasche
Klima-Demo auf zwei Reifen
Wissenschaftler: 'Demonstrierende nicht pauschal ausgrenzen'

Nordrhein-Westfalen, Sunday, 17. May 2020 (2 days ago)
has protests: yes
number of protests: 1
Protests:
EG: On 17 May 2020, around 120 to 150 people, including Ende Gelaende activists,
  protested in Datteln against the coal-fired power station Datteln 4.
Headlines:

Nordrhein-Westfalen, Monday, 18. May 2020 (1 days ago)
has protests: no

Headlines:
Demonstration gegen Kohlekraftwerk Datteln
Demonstration gegen Kohlekraftwerk Datteln
Demo für mehr Platz für Radfahrer
Seit 48 Wochen wird am Schloss fürs Klima gestreikt
Castop-Rauxeler Klima-Aktivistin: Nicht zu schweigen ist nicht radikal
Datteln 4: Klimabündnis protestierte gegen Inbetriebnahme
" Krise nicht gegen Klimaschutz ausspielen "
Kreis macht Tempo beim Klimaschutz
Besinnlicher Protest an der Tagebaukante

Nordrhein-Westfalen, Tuesday, 19. May 2020 (today)
has protests:
```
\endgroup

```{python}
# | echo: false
# | label: fig-loss-curves
# | fig-cap: Loss curves for the finetuning of the Longformer model for propensity score computation from texts.
import matplotlib.pyplot as plt
import numpy as np
from scipy import interpolate
import pandas as pd
import json
from src.paths import models

with open(models/ "propensity_scores/trainer_state.json") as f:
    training_loss = json.load(f)["log_history"]
validation_loss = [log for log in training_loss if "eval_loss" in log]

training_loss_values = [log["loss"] for log in training_loss if "loss" in log]
validation_loss_values = [
    log["eval_loss"] for log in validation_loss if "eval_loss" in log
]

training_steps = np.linspace(0, len(training_loss_values), len(training_loss_values))
validation_steps = np.linspace(
    0, len(training_loss_values), len(validation_loss_values)
)

f = interpolate.interp1d(validation_steps, validation_loss_values)
validation_loss_values_interp = f(training_steps)

f1_scores = [log["eval_f1"] for log in validation_loss if "eval_f1" in log]
f1_steps = np.linspace(0, len(training_loss_values), len(f1_scores))

fig, ax1 = plt.subplots(figsize=(8, 4))
ax1.plot(training_steps, pd.Series(training_loss_values).rolling(10).mean(), label="training loss")
ax1.plot(validation_steps, validation_loss_values, label="validation loss")
ax1.set_ylabel("Loss")
ax1.legend(loc="upper left")
ax1.set_ylim(0, 1.6)
ax2 = ax1.twinx()
ax2.scatter(f1_steps, f1_scores, label="F1 score", color="g", marker="x")
ax2.set_ylabel("F1 Score", color="r")
ax2.legend(loc="upper right")
ax2.set_ylim(0, 0.35)

plt.show()
```

#### Impact estimates for the other datasets


```{python}
# | label: fig-impact-ts-gpreg
# | fig-cap: Causal impact estimates on the _German protest registrations_ dataset by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=False, show_progress=False, protest_source="gpreg")
fig.suptitle("GPReg: Time series of the causal impact by method and coverage dimension")
axes[0].set_ylim(-30, 30)
axes[1].set_ylim(-30, 30)
axes[2].set_ylim(-5, 5)
axes[3].set_ylim(-5, 5)
axes[4].set_ylim(-200, 200)
plt.tight_layout()
plt.show()
```

```{python}
# | label: fig-impact-ts-gprep
# | fig-cap: Causal impact estimates on the _German protest reports_ dataset by method and newspaper coverage dimension. The protest day is at x=0. Pay attention to the differences in the y-axis scale.
# | column: page
# | echo: false
import matplotlib.pyplot as plt
from src.visualization.impacts import plot_trends

fig, axes = plot_trends(cumulative=False, show_progress=False, protest_source="gprep")
fig.suptitle("GPRep: Time series of the causal impact by method and coverage dimension")
axes[0].set_ylim(-30, 30)
axes[1].set_ylim(-30, 30)
axes[2].set_ylim(-5, 5)
axes[3].set_ylim(-5, 5)
axes[4].set_ylim(-200, 200)
plt.tight_layout()
plt.show()
```
