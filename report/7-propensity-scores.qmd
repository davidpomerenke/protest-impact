## NEW Propensity scores

Propensity score methods help to remove the impact of _known_ confounders. They rely on the propensity score that specifies how likely it is that a protest occurs on a given date and in a given region. They can be computed from knowledge about the region and the date, and from lagged treatment and outcome data from the previous days. To account to some extent for the impact of _unknown_ confounders, I also obtain propensity scores from press releases about climate-related events.

### Theory

The propensity score $e(X) = P(W=1|X)$ is the probability of the treatment given the confounding variables. It is often computed using logistic regression, but any machine learning model that produces reasonable probability estimates can be used; this makes it more flexible than linear models.

Various methods make use of propensity scores, mainly: _Propensity stratification, inverse propensity weighting, and propensity matching_. Propensity stratification requires the specification of a hyperparameter $k$ for the number of strata, with no reliable methods available for making a suitable choice [@dingFirstCourseCausal2023, ch. 11]. Propensity matching is very intuitive but also very problematic because it is usually not possible to establish a perfect matching between treated and control units, and any matching method introduces imbalance, so that the imbalance may even be increased rather than reduced [@kingWhyPropensityScores2019]. Therefore I focus on inverse propensity weighting.

### Inverse propensity weighting

Inverse propensity weighting (IPW) gives every sample a weight that is inverse to the propensity score: $\frac{1}{e(X)}$ for treated units and $\frac{1}{1-e(X)}$ for control units. We use the same assumptions as for regression (@sec-reg-math):

- __Unconfoundedness__, $W \perp\!\!\!\perp Y(0) | X$: The counterfactual outcome if there was no treatment is independent from the actual treatment. (For @eq-prop we need the same not only for $Y(0)$ but also for $Y(1)$; but the calculation of the _ATT_ does not require this.)
- __Overlap__, $e(X) < 1$: The treatment assignment is not deterministic.

Then we can see that propensity weighting reveals the counterfactual outcome [@barterRebeccaBarterIntuition2017; @dingFirstCourseCausal2023, ch. 11]:

$$
\begin{aligned}
E\left(\frac{WY}{e(X)}\right) &= E\left[E\left(\frac{WY}{e(X)}|X\right)\right] \\
&= E\left[E\left(\frac{WY(1)}{e(X)}|X\right)\right] \\
&= E\left[\frac{E(W|X)E(Y(1)|X)}{e(X)}\right] && \text{due to unconfoundedness} \\
&= E\left[\frac{P(W=1|X)E(Y(1)|X)}{e(X)}\right] && \text{because W is binary} \\
&= E\left[\frac{e(X)Y(1)}{e(X)}\right] \\
&= E(Y(1))
\end{aligned}
$$ {#eq-prop}

Analogously we have $E(\frac{(1-W)Y}{1-e(X)}) = E(Y(0))$. We can extend this for the counterfactual of the treated units $E(Y(0)|W=1) = E\left(\frac{e(X)}{P(W=1)}\frac{(1-W)Y}{1-e(X)}\right)$, see @dingFirstCourseCausal2023 [p. 166] for the proof.

This gives us an estimator for the ATT:

$$
\begin{aligned}
\tau &= E(Y|W=1) - E(Y(0)|W=1) \\
&= \hat{\bar{Y}}(1) - \frac{1}{n} \sum_{i=1}^{n} \frac{e(X_i)}{P(W_i=1)}\frac{(1-W_i)Y_i}{1-e(X_i)}
\end{aligned}
$$ {#eq-prop-est}

The estimator from @eq-prop-est is reported to have various problems in practice, therefore I use the alternative _Hájek estimator_, which is empirically more stable [@dingFirstCourseCausal2023, pp. 146, 166; @abdiaPropensityScoresBased2017]:

$$
\tau^{\text{Hájek}} = \hat{\bar{Y}}(1) - \frac{1}{n} \frac{\sum_{i=1}^{n}\frac{e(X_i)}{P(W_i=1)}\frac{(1-W_i)Y_i}{1-e(X_i)}}{\sum_{i=1}^{n}\frac{e(X_i)}{P(W_i=1)}\frac{(1-W_i)}{1-e(X_i)}}
$$

I use the implementation from the [DoWhy](https://www.pywhy.org/dowhy/v0.10/dowhy.causal_estimators.html#module-dowhy.causal_estimators.propensity_score_weighting_estimator) Python package, with a normalized weighting scheme (that is, the Hájek estimator) for ATT estimation.

### Doubly robust estimation

Both regression (@sec-reg) and IPW rely on the same assumptions of overlap and conditional unconfoundedness. They can be combined into a single estimator known as _augmented inverse propensity weighting_ or as the _doubly robust estimator_. It is consistent if at least one of the models is correctly specified -- that is, if either the treatment or the outcome is consistently estimated. If both models are correct, then it helps reducing the bias of the regression estimator, and reducing the variance of the propensity score estimator.

Doubly robust estimation is defined, motivated, and proven in @dingFirstCourseCausal2023 [ch. 12, ch. 13.2]. As an implementation I use the `LinearDRLearner` from the [EconML](https://econml.azurewebsites.net/_autosummary/econml.dr.LinearDRLearner.html) Python package.

### Propensity scores from press release texts

TODO

<!-- cite Wager, and causal NLP overview

Predicting propensity scores from text: cite causalNLP overviews
For example, @bundeskriminalamtbkaLagebildLetzteGeneration2023 hypothesize that "Die Fallzahlen unterliegen einem „wellenartigen“ Verlauf, welcher sich vornehmlich durch (das Ausbleiben von) Großveranstaltungen im gleichen Kontext erklären lässt."

possible models:

- gelectra: 100-300M parameters https://huggingface.co/deepset/gelectra-base
- igel: 6B parameters https://huggingface.co/philschmid/instruct-igel-001
- llama 2 german https://huggingface.co/flozi00/Llama-2-7b-german-assistant-v2

faster finetuning: https://github.com/huggingface/peft -->
