<!--

The difference between the goals and/or context of the thesis with existing solutions (e.g. found in literature) were studied and clearly described to support the problem definition, clearly indicating the innovative part of the thesis task.

the introduction defines the problem, sets it in terms of the state-of-the-art and clearly indicates what the contribution of the thesis is

 -->

## Introduction

### Problem statement

__Research questions.__ ... lack of structured data (timewise and detailwise and biaswise) ... following research questions:

<!--

At least three research questions are present and relevant.
+ research questions are well-positioned in the research context.
+ research questions are well-positioned in the literature.

 -->

- q1
- q2
- q3

---

This master thesis aims to find out whether, and to what extent, climate protests succeed in bringing more attention to the climate crisis, as measured by the amount of newspaper coverage that they and their topic receive. While I focus on climate protests in Germany, the methods that I use, and also a large part of the data sources that I use, are also transferable to other protest movements, not only those concerning the climate.

Since this is a thesis in artificial intelligence, I focus on applying, evaluating, and comparing multiple causal inference methods, that all try to answer the research question from different assumptions and methodical perspectives.

---

This poses the problem of confounding, that is, common causes of both newspaper attention and protest events: If, for example, extreme weather leads to more newspaper coverage on the one hand, and makes people more prone to protest, then it may seem as if the protest leads to more newspaper coverage, but it may not actually be the case. Other candidates for confounders include prior newspaper coverage and prior protest events themselves, as well as external events such as climate conferences, or the passing of laws. Due to these confounders, naively looking at the relationship between protests and discourse may give a biased impression, and causal inference techniques are required.

I want to compare multiple causal methods and see what they can tell us about the impact of protests. My research questions are:

1. Can the causal methods -- instrumental variable, synthetic control, and propensity score methods -- be applied to study the impact of protest events on newspaper attention? What limitations apply, and what problems occur? Are the estimates consistent, and how do they differ from each other and from simple regression estimates?

2. What is the _Average Treatment Effect on the Treated_[^ATT] (ATT) of protest events on newspaper coverage, for climate protests in general, and with respect to the protest group that organizes the protest?

3. What can we say about the hypothesis that climate protests _distract_ from discussing solutions to the climate crisis constructively?

[^ATT]: The _Average Treatment Effect on the Treated_ (ATT) is the effect that the protests that took place have actually caused, on average, in comparison to the case that they had not taken place. It differs from the _Average Treatment Effect_ (ATE) by focusing on the treated units rather than the whole population.

---

<!-- Citizens in democracies have an interest in understanding the effectiveness of protest movements, and which factors make them effective.

Protests play a _crucial role_ in democracies, complementing the sometimes insufficient institutional participation. Large protest movements are known to have brought about progress that we nowadays take as indispensable, especially in the areas of civil rights and women's rights.

Yet, the different forms of protest have always caused and do still cause _controversy_: Are they an appropriate means to achieve their respective goal? Should they be less radical, or perhaps more so, in order to effectively achieve that goal? There are three levels on which such questions may be of interest.

1.  The __general public__ wants to know what to think of protests. Especially persons who support the goal of the protest may wish to know whether they should endorse the protest; or oppose it and advocate for alternative means to achieve that goal. Opponents of the goal may wish to denounce the protest not only on the content-level, but also by claiming that the protest is an inappropriate way to achieve that goal. Supporters may then wish to prove them wrong by referring to evidence that proves the potential effectiveness of protesting.

    Making a scientific investigation in this context is a bit weird, because the result may just perpetuate existing beliefs. If one finds that protests are effective, this may increase their support and thereby make them more effective; while a negative statement may weaken their result and their effectiveness. At the same time, any scientific result may be impacted in large part by the prevailing beliefs about the effectiveness of protest. Research on this topic should therefore at least make sure that it does not implicitly aim to increase or decrease the support for protests, and should keep in mind that existing beliefs may be an important factor impacting the effectiveness of protests.

2.  __Protest supporters__ want to know which organizations they should support. Grassroots movements depend on funding, be it from individuals, from intermediary funds, or from philanthropists. These parties want to invest their donations efficiently, and can often choose from a pool of organizations that aim at similar goals with differing methods. The question of cost-effectiveness arises, and while cost is easy to count, effectiveness is very hard to estimate. Existing organizations use proxy measures including the number of press articles about the protest movement, which may not be ideal. Besides comparing different organizations, donors may also wish to compare protests with alternative methods such as lobbyism or individual action.

deeply strategic: [@englerThisUprisingHow2016]

@knuthFinanzierungKlimaaktivismusAm2023

1.  __Protest organizations__ themselves want to know how they can best achieve their goals. They regularly plan new activities and need to decide on strategical points, such as:
    -  Who do they want to address? (e. g., politicians, businesses, or the media)
    -  How radical should they be? (e. g., whether they should respect the boundaries of public goodwill, of the law, or of nonviolence)
    -  How much time should they invest into recruiting and marketing activities?
    -  How much attention should they pay to symbolicism, and to an integral appearance?
    -  What time periods should they choose? (e. g., whether to go along with external events and media attention waves, or to complement them)
    -  What places and what timing works best?

Answering these questions involves looking not only at the _impact_ of protests, but also at the _impact factors_. Here I do not study impact factors in detail, but I do compare the impacts of various climate protest movements, which may allow some inferences about strategy; and may enable further research about impact factors. -->

__Protest event analysis.__

<!-- Copy from below: Newspaper articles are primarily used in the existing literature. [@hutterProtestEventAnalysis2014] give a historical and systematic overview and highlight the problem that this source is biased. They describe how several definitions for protest event analysis (PEA) and the broader political claim analysis (PCA), as well as associated coding practices have helped to formalize the (manual) data extraction process, such that results have become more valid and comparable. -->

__Protest impact.__

Research into the impact of protest movements has recently been spearheaded by a series of literature reviews and expert interviews by Ozden and Glover. In the context of effective altruism, they aim to assess how effective protest movements are as a means for political change, and what factors determine their success. In their literature review on protest outcomes @jamesozdenLiteratureReviewProtest2022, they conclude that _causal inferences on protest outcomes are generally challenging to draw due to confounding, and it is even harder to determine the long-term effect_. They warn that the average effect size of protests is likely over-estimated in the existing literature, due to selection bias on the level of media coverage, researcher interest, and statistical significance (publication bias). Based on their review, they estimate that protest movements (consisting of many single protest events) may raise salience and support for the issue by 2-10%, and may influence voting behavior by 1-6 percentage points. The influence on public discourse may be high in certain cases, and in the case of the Black Lives Matter movement may have amplified coverage by a factor of 10.

In interviews with researchers, @jamesozdenExpertInterviewsProtest2022 establish that while there is much research on protest outcomes, the causal connections between protests and their outcomes are an underexplored research area (interview with Robyn Gulliver in the cited report); that a causal link between protests and certain outcomes is plausible, but hard to attribute to any specific protest group (interview with Ruud Wouters in the cited report); and that causal effects are typically only measurable only on a local level due to the lack of a control group at the national level. More generally, protest outcomes may be subject to confounding, and the causal arrow between protests and increased concern may point in either direction. The interviews with researchers, as well as interviews with UK policymakers [@jamesozdenPolicymakerInterviewsProtest2022], suggest that the causal effect of protest on policy is strongly if not completely mediated by public opinion.

In a follow-up, [@samgloverLiteratureReviewProtest2022; @jamesozdenWhatMakesProtest2023] review the factors that causally affect the success of protest movements. They attribute a high importance to the number of participants, and to the nonviolent nature of the protest, as well as a favourable sociopolitical context, including media coverage. A moderate effect is attributed to the diversity and the unity of the movement. They also look at the so-called _radical flank effect_, a theory that moderate movements benefit from the simultaneous presence of a more radical movement for the same issue. Their review finds moderate effects from a radical flank, but only if the radical flank is also nonviolent.

__Relevance of newspaper coverage__ as an impact proxy

There are multiple potential proxies for policy decisions: Election outcomes, public opinion measured by polling, and features of various levels of public discourse.

Within public discourse, there is a gradual tradeoff of media that is close to the legislative process, and media that is close to current affairs such as protest events. Parliamentary debate accompanies legislation. Parliamentary questions have fewer impact on policy, but may reveal what politicians are concerned about. Political debates outside the parliament, such as talk shows on television, may be even more responsive to current affairs. National newspapers and magazines drive political discourse forward in smaller steps, and are in turn influenced by the reports and discussions emerging from local newspapers. They report on real-world events, and on press agency releases, and on issues that are reported and discussed by Twitter users.

![Observable layers of public discourse. Adapted from a graphic from Stewart Brand [via @branderLayeredProtocols2022].](figures/discourse-layering.png){.column-margin #fig-wheel}

The end of this ladder of discourse -- compare @fig-wheel -- is very remote from having influence on policy; but it has the benefit that data is available on a much grander scale and frequency, which facilitates big data analyses (see @fig-lamppost).

!["Looking under the lamppost" by [Sketchplanations](https://sketchplanations.com/) (CC-BY-NC)](figures/lamppost.png){.column-margin #fig-lamppost}

__Causal impact evaluation.__

<!--

Research has advanced state of the art. Described thesis research would lead to a publication in an international peer-reviewed journal or an international peer-reviewed conference.

 -->

__Contribution.__

<!--

The research itself is very theoretical or highly interdisciplinary requiring the student to read into both challenging and theoretical material well beyond the scope of the programme.
+ this attitude is constructive and well-balanced.

 -->

- IV for single events
- SC for many single events
- PS for texts
- automated dataset
- complete dataset

### Literature review

#### Impact of protests on newspaper coverage

<!--
The "protest paradigm" [@mcleodManufacturePublicOpinion1992] theorizes that news coverage of protesters tends to be a double-edged sword, because the coverage of protests that challenge the status quo is usually negative. This paradigm is recently being challenged, and the formation of amore nuanced theory is underway that considers under what conditions the protest paradigm does or does not hold [see @harlowNewProtestParadigm2023].

@schwartzParadoxConfrontationExperimental2016: protests themselves have a negative impact on public support, but media coverage has a positive impact

@cristanchoProtestersNewsGates2022 investigate experimentally how different features of protests as well as of journalists have an impact on the prominence of the protests in the news (measured by front-page placement), finding that protest size is the most important feature

@hellmeierSpotlightAnalyzingSequential2018 find support for their hypothesis that salient protest events that receive a lot of media coverage lead to a higher coverage of subsequent protest events, and that the effect decreases with spatial and temporal distance.

cite Teune, Wasow, maybe Repke

@barrieDoesProtestInfluence: time series effects on tweets by uk mps, recent and very nice (not strictly causal, but really plausible; or could perhaps consider it a discontinuity design)

@chenHowClimateMovement2023a analyze the coverage of the climate movement on Twitter as well as in online newspapers. They use topic modelling to find major themes in discourse, and plot the quantitative evolution of these themes over time from 2018 to 2021, overlaying it with information about the occurrence of the semi-annual global climate strikes.
-->

#### Causal approaches to protest event analysis {#sec-weatherlit}

In the context of protest event analysis, the most commonly used methods are: regression with an extensive set of control variables; and the instrumental variable method using rainfall as an instrument.
<!-- and _difference in differences_, which is conceptually similar to the synthetic control method. -->
To my best knowledge, the synthetic control method and propensity score methods with text have not previously been applied to protest event analysis.

---

Among the protest effects literature that employs causal methods, the instrumental variable method is the most commonly used method. Usually, rainfall over a period ranging from one day up to one month is used to estimate the effect of protests during that timeframe on a later outcome, where a direct influence of the weather is very unlikely. With the exception of @huet-vaughnQuietRiotCausal2013, all previous literature has a setting where they look at a fixed timeframe and compare effects across regional units. Only Huet-Vaughn (2013) have a methodical approach that is more similar to mine, looking at a larger dataset where events are scattered across regions and also across time.

- @collinsEconomicAftermath1960s2007 use rainfall and local political structure as instruments to investigate the effect of riot severity on the later development of property values. They use rainfall in the month following the assassination of Martin Luther King, during which many protests occurred across the US, as an instrumental variable.

- @madestamPoliticalProtestsMatter2013 use rainfall as an instrumental variable to measure the effect of Tea Party rallies on votes for the Republican Party in the US. They use rainfall on a single important day of Tea Party rallies across counties in the US to measure the effect of additional protesters on Republican Party vote share half a year later, finding that an additional protester leads to way more additional votes than just a single one. They also measure the effect on newspaper coverage of the Tea Party, and find increased attention especially during later important Tea Party events. They operationalize rainfall as a dummy variable of whether there were at least 0.1 inches (2.5 mm) of rainfall.

- @huet-vaughnQuietRiotCausal2013 investigate the effect of protest violence on protest "success" across 15 years of single (potentially multi-day) protest events in France, using precipitation and temperature as instrumental variables. They operationalize precipitation as a dummy variable representing whether there was some precipitation during any day of a series of protest days, and temperature as a dummy variable about whether the maximum temperature during these days falls in the range of 60-75° Fahrenheit (16-24° Celsius), which is derived from studies about the effect of temperature on disorderly conduct.

- @negroWhichSideAre2019 are interested in the effect of the size of LGBTQ protests on the presence of "movement-affiliated organizations". They use two instrumental variables, the first one measuring whether the precipitation on the protest date exceeds 2.5 mm (as per @madestamPoliticalProtestsMatter2013), and the second one being the average rainfall in the last 10 years on the $\pm3$-day window around the protest date.^[In my opinion this is a good idea but it should be labeled as a control, not as an instrument. See the next section for discussion.] They find the first instrument to have a statistically significant effect on the protest size ($p<0.01$), but not the second one ($p\geq 0.05$).

- @wasowAgendaSeedingHow2020 use rainfall in the month following the murder of Martin Luther King to estimate the effect of violent protests on the vote share of the Democratic Party in the US in the elections half a year later. They operationalize rainfall as "average rainfall in millimeters from weather stations within a 50 mile radius of the county center." Using two-stage least-squares regression, they find a significant shift in vote share in predominantly white counties due to protests in the first week after the assassination. They also apply placebo tests using rainfall from the week before the assassination, and from the remainder of the month after the assassination (containing only 5% of the protests from that month), and do not find significant effects for either of them, which strengthens their result.

- @kleinteeselinkWeatherProtestEffect2021 use rainfall as an instrument to determine the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They use rainfall from the two weeks following the murder of George Floyd by the police to measure the effect of the per-county number of total protest attendees during this time window on the election half a year later. (A very similar setting as above.) They use a linear variable to operationalize rainfall. They use the "probability of rain" to control for "general climatic conditions that may correlate with voting-relevant characteristics such as the average age, income, and ethnic composition of a county." The operationalization and motivation for this are a bit unclear.^[I find it plausible that the rain forecast may be relevant because the organizers may decide already a few days in advance of the protest whether or not it should take place, and for this decision they cannot rely on the actual weather but merely on the forecast.] Moreover they stress the importance of taking spatial depencies into account, and solve the problem using a spatial weighting matrix. They use demographic control variables (racial composition and median age) as well as economic control variables (median income and unemployment rate) for all regression steps. Placebo tests for first-stage linear regression show that the coefficients for the effect of weather on protest attendance is much lower for time windows before the protests took place, but still highly statistically significant.

- @carenBlackLivesMatter2023 use multiple weather variables, also to estimate the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They operationalize days with _bad weather_ as days with either a maximum temperature above 90° Fahrenheit (32° Celsius), more than 0.1 inches (2.5 mm) of precipitation, or a wind speed of more than 10 mph (16 km/h). As their instrument they use the number of days with bad weather during the month that followed the murder of George Floyd by the police. Their treatment is _protest intensity_, which they define as the inverse hyperbolic sine (which behaves similarly to the logarithm) of the cumulative protest size, divided by the population size of the county. They use a large list of sociodemographic and political variables on the county level as control variables for all regression steps.

TODO: make a neat overview table of the different methodologies.

Other literature uses instruments that are less clearly random, such as whether the protest took place on a Friday, its distance to focal points, the commute time in the city where the protest takes place, or even sociological variables concerning the political structure and efficiency. Arguing that such instruments are valid requires solid expert knowledge (and perhaps insider knowledge), and such instruments are therefore less suitable for a data-driven analysis as I envision it here. (Even the weather variable is not completely free from such problems, unfortunately, as is discussed in the next section.)

__Causes of protests__

cite Seitz

### Causal impact estimation {#intro-causal}

Causality[^invented by Spohn xxxx]

Here I give an overview of the causal model that I generally assume. Then I give an overview of the different causal methods used in this project, how they exploit the causal model, and what additional assumptions they make. Since _time series methods_ may be used in various contexts, I also briefly introduce their structure and show how they can be applied to various machine learning problems that arise as part of the causal methods.



@fig-causal-graph-simple shows the causal relations between the 5 categories graphically.

```{dot}
// | label: fig-causal-graph-simple
// | fig-cap: Simple causal graph showing the structure of the research problem, ignoring the time-series aspect. I want to determine the effect of the treatment __W__ on the outcome __Y__, and there are known confounders __X__, but also unknown confounders __U__ that influence both treatment and outcome and thus complicate the matter. Instrumental variables __Z__ may help, because they only affect the outcome via their effect on the treatment.
// | fig-width: 180px
// | fig-height: 120px
// | column: body
// | fig-pos: 'H'
digraph D {
  rankdir=LR
  {X, U} -> {W, Y}
  {Z} -> {W}
  {W} -> {Y} [color=green]
}
```

The core of the model is the relation $W \rightarrow Y$ that I want to investigate. However, there are multiple problems of increasing difficulty:

1. The outcome __Y__ is affected not only by the treatment but also by the covariates __X__. This is a pretty common situation, even in experiments that are randomized, and we can approach it, for example, by using regression to control for the covariates.
2. Not only the outcome __Y__, but also the treatment __W__ is affected by the covariates __X__, which makes them _confounders_. This is a common feature of observational studies. We can use methods based on the _propensity score_ (the probability of receiving the treatment) to approach this problem, as long as we know all relevant confounders.
3. There are likely unknown confounders __U__. We are dealing with a sociological situation where a lot of variables could potentially be relevant. For example, external events like elections, legislative processes, or conferences could play a big role. Or the current mindset and stress level of journalists could play a role. Or many other things, that we may not even think of. Even though we cannot list all of these variables, there are alternative approaches:
   1. Assuming that the unknown confounders affect all regions similarly, we can make cross-region comparisons, for example, by using the __*synthetic control*__ method.
   2. We can leverage __*instrumental variables*__ __Z__, for which we assume that they do not affect the outcome __Y__ directly, and trace their effect on __Y__ via the treatment __W__.
   3. We can assume that certain texts such as press releases may cover many relevant unknown confounders, and learn __*propensity scores from texts*__, without needing to specify the confounders explicitly.

All three methods can be combined with controlling for known confounders. The following table gives an overview over the methods, which causal inference principles they use, what data they rely on, and whether they are useful for dealing with know and unknown confounders:

:::{.column-body}

\begin{tabular}{l| c c c c}
& Regression & Instr. var. & Synth. contr. & Prop. score \\
\hline
Instrumenting & & \bullet &  &  \\
Controlling & \bullet & (\bullet) & (\bullet) & (\bullet) \\
Balancing &  &  & \bullet & \bullet \\
\hline
Time series & \bullet & (\bullet) & (\bullet) & \bullet \\
Regions &  &  & \bullet &  \\
Weather &  & \bullet &  &  \\
Texts &  &  &  & (\bullet) \\
\hline
Confounders? & $\checkmark^1$ & $\checkmark^2$ & $\checkmark^3$ & $\checkmark^4$ \\
Hidden conf.? &  & $\checkmark^2$ & $\checkmark^3$ & $\checkmark^{4,5}$ \\
\end{tabular}

Core assumptions:$^1$ Linearity;$^2$ Valid instrument;$^3$ No regional confounding;$^4$ Overlap;$^5$ Hidden confounding is captured by text.

:::

Here I give a conceptual overview of the 3 mentioned methods that are potentially suitable for dealing with unknown confounders. Their exact assumptions and limitations will be discussed in their respective chapters.

__Regression__

```{dot}
// | label: fig-causal-graph-reg
// | fig-cap: Causal graph for naive analysis.
// | fig-width: 100px
// | fig-height: 100px
// | column: margin
digraph D {
  {W, X} -> {Y} [color=blue]
}
```

Naive regression is not a causal method, but is used for comparison with the causal methods. It neglects most of the causal model and only regards the direct relationship between treatment and outcome, possibly controlling for covariates, but neglecting their role as confounders. The result is known as the _prima facie_ causal effect. It suffers from _selection bias_, because the model does not take the treatment assignment process into account -- but it should, because the treatment is not randomized.

Controlling for the known confounders can already help to substantially reduce the bias, especially if the relationships are linear, and may as well be considered a causal method.

__Instrumental variables__

```{dot}
// | label: fig-causal-graph-iv
// | fig-cap: Causal graph for the instrumental variable method.
// | fig-width: 150px
// | fig-height: 150px
// | column: margin
digraph D {
  {W} -> {Y}
  {Z} -> {W} [color=blue]
  {X} -> {W, Y}
}
```

<!-- The _instrumental variable_ approach leverages _natural experiments_, where a random variable (or an almost random variable) influences the treatment. The _exclusion restriction_ (see @sec-app2-iv) assumes that the instrument does not have a direct impact on the outcome, but only via the treatment. We can then trace how the instrument affects the outcome via the treatment, and thereby establish the causal impact of the treatment on the outcome. -->

This method utilizes one or more instrumental variables. Valid isntruments affect the treatment but do not directly affect the outcome -- not via other paths and not even via confounding. This is especially true for approximately random variables, such as the weather. (The weather is not purely random but also contains regional and seasonal components; but we can try to isolate them or work around the problem.)

In the simplest case, we can compare the effect of __Z__ on __W__ with the effect of __Z__ on __Y__ to obtain the desired estimate for the effect of __W__ on __Y__. We can also apply _two-stage_ approaches to first isolate the part of __W__ that is caused by __Z__, and then estimate its impact on __Y__.

Thanks to instrumental variables, we can legitimately ignore the unknown confounders, which is really nice. A requirement is always that the instrument is valid and sufficiently strong, that is, that it has a strong effect on the treatment __W__.

__Synthetic control__

```{dot}
// | label: fig-causal-graph-synth
// | fig-cap: Causal graph for the synthetic control method.
// | fig-width: 180px
// | fig-height: 220px
// | column: margin
digraph D {
  {X, U} -> {W} -> {Y}
  {X, U} -> {Y}
  {region} -> {U} [style=dotted, color=blue, label="determine"]
  {date} -> {U} [style=dotted, color=blue]
}
```

<!-- The synthetic control method [@abadieSyntheticControlMethods2010; @cunninghamCausalInferenceMixtape2021, ch. 10] leverages the idea of comparing a region where a protest happens with other regions where no protest happens on the same day. However it goes beyond a simple comparison. Instead it constructs a _synthetic region_ from all the control regions that is as close as possible to the treatment region. The synthetic region can then be used to model the counterfactual of no protest for the treatment region. -->

The underlying assumption for the synthetic control method is that the unknown confounders affect the different regions uniformly: On any given day, the impact of the confounders is the same for all regions. This assumption is plausible especially for confounders coming from global and national politics and events; it is violated by regional confounders, but maybe they are not so important and we can live with it.

Under this assumption, we can perform matching based on the date: To estimate the impact of a protest group in one region on a given date, we find other regions where no such event has taken place, and compare the effect.

The synthetic control method goes a bit further and also takes the effect of known differences between the regions into account. From all the available control regions, it constructs a _synthetic region_. The synthetic region interpolates between the control regions such that the interpolated region is as close as possible to the treatment region in some respect. This interpolation can be performed in terms of sociodemographic similarity, or in terms of maximizing the predictive accuracy of the outcome variable, based on past observations. (This is a bit of a simplification, the details are explained in @sec-synth.)

__Propensity scores__

```{dot}
// | label: fig-causal-graph-prop
// | fig-cap: Causal graph for propensity score methods.
// | fig-width: 100px
// | fig-height: 150px
// | column: margin
digraph D {
  {W} -> {Y}
  {X} -> {W} [color=blue]
  {X} -> {Y}
}
```

<!-- Propensity score methods help to remove the impact of _known_ confounders. They rely on the propensity score that specifies how likely it is that a protest occurs on a given date and in a given region. They can be computed from knowledge about the region and the date, and from lagged treatment and outcome data from the previous days. To account to some extent for the impact of _unknown_ confounders, I also obtain propensity scores from press releases about climate-related events. -->

Propensity score methods estimate the probability (propensity) of receiving the treatment. There are various strategies for eliminating selection bias with the use of propensity scores: notably propensity score matching, propensity score stratification, inverse propensity weighting. Double machine learning estimators such as causal forests help with estimating heterogenous treatment effects.

Propensity score methods still suffer from _omitted variable bias_ if there are unknown confounders. This can be mitigated by learning propensity scores from less structured big data such as texts, using classification models from natural language processing. The advantage of doing so is that the unknown confounders need not be pre-specified. The assumption is that the texts need to contain all of the unknown confounders, and in some detectable form. While this will never completely be the case (and cannot be verified anyway), I can hope that it at least substantially reduces the bias.

__Time-series modelling__ {#sec-time-series}

The variables on one day may also be influenced by the same set of variables from the previous day. On the one hand, this makes modeling more complicated. On the other hand, it is an advantage, because we have the data from the previous days already in the dataset, and using them can help reduce the amount of unknown confounding. Specifically, I consider all variables from the previous day as potential confounders for the current day. Variables from multiple days earlier may still be relevant, but less so, so it will be acceptable to make a cutoff at some point. We can restrict the previous variables to those from the same region, or we can also include previous variables from other regions where it seems useful.

```{dot}
// | label: fig-causal-graph-time-series
// | fig-cap: Version of the causal graph (@fig-causal-graph-simple) from a time series perspective. The variables of each day are influenced by the variables from the previous days in the same region. We can model that by including all variables from one day as potential confounders for the following day.
// | fig-width: 200px
// | fig-height: 400px
// | column: margin

digraph D {
  rankdir=LR
  compound=true

  U0 [label="U"]
  W0 [label="W"]
  X0 [label="X"]
  Y0 [label="Y"]
  Z0 [label="Z"]

  U1 [label="U"]
  W1 [label="W"]
  X1 [label="X"]
  Y1 [label="Y"]
  Z1 [label="Z"]

  U2 [label="U"]
  W2 [label="W"]
  X2 [label="X"]
  Y2 [label="Y"]
  Z2 [label="Z"]

  subgraph cluster_0 {
    label="Day -2"
    {X0, U0} -> {W0} -> {Y0}
    {X0, U0} -> {Y0}
    {Z0} -> {W0}
    dummy_0 [shape=point style=invis constraint=false]
  }
  subgraph cluster_1 {
    label="Day -1"
    {X1, U1} -> {W1} -> {Y1}
    {X1, U1} -> {Y1}
    {Z1} -> {W1}
    dummy_1 [shape=point style=invis constraint=false]
  }
  subgraph cluster_2 {
    label="Day 0"
    {X2, U2} -> {W2} -> {Y2}
    {X2, U2} -> {Y2}
    {Z2} -> {W2}
    dummy_2 [shape=point style=invis constraint=false]
  }
  dummy_0 -> X1 [ltail=cluster_0 style=dotted label="include\nvariables" constraint=false]
  dummy_1 -> X2 [ltail=cluster_1 style=dotted label="include\nvariables" constraint=False]
}
```

<!--
In time-series models, be it for forecasting or classification, the predictor variables usually fall into 3 categories:

- __Historic variables:__ Variables that are only available for past dates but not for the date of the prediction. This is especially true for the target variable^[The lags of the target variable are more specifically called an __autoregressive__ variable.]; since its future value should be predicted, it should not be present as a predictor.
- __Future variables:__ Variables whose values are available for past dates as well as the date of the prediction.
- __Static variables:__ These are time-independent.

@tbl-time-series gives an overview how these categories are applicable within the different causal methods.

::: {#tbl-time-series}

| Target | Predictors | Method |
| ------ | ---------- | ------ |
| __Y__ | \boldmath$X_{f,s}, Y_h, W_f$ | Regression |
| __Y__ | \boldmath$X_{f,s}, Y_h, W_f, Z_f$ | IV stage 1 |
| __W__ | \boldmath$X_{f,s}, Y_h, W_h, Z_f$ | IV stage 1 |
| __Y__ | \boldmath$X_{f,s}, Y_h, W_h, \hat W_f$ | IV stage 2 |
| __Y__ | \boldmath$X_{f,s}, Y_h, Y_{R_0f}$ | Synthetic control |
| __W__ | \boldmath$X_{f,s}, Y_h, W_h$ | Propensity score |

: Subscripts $\scriptsize f, h, s$ denote future, historic and static variables.

:::

\begingroup
\color{Blue} -->


### Case study

The climate protest movement in Germany has only stepped into existence toward the end of the 2010's. Before then, climate activism was mostly associated with established environmental NGOs such as Greenpeace, which did not play a major role in the media. In 2015 the activist formation _Ende Gelände_ (EG) was established, and began organizing occupations, blockades, and demonstrations directly in coal mining areas [@EndeGelaende2023]. In late 2018 _Extinction Rebellion_ (XR) was established in Germany to protest the biodiversity crisis that comes along with the climate crisis, through demonstrations as well as blockades [@ExtinctionRebellion2023].

Around the same time, the global _Fridays for Future_ (FFF) movement gained traction in Germany, accumulating a huge momentum -- more than a million protesters --, especially among high school and university students, and later also among other social groups with sub-movements such as _Scientists for Future_, _Parents for Future_, and _Grandparents for Future_ [@FridaysFuture2023]. They emphasize constructive discourse and inclusivity, organize exclusively pre-registered demonstrations, and often collaborate with other protest groups. However, they mostly protest on Fridays, that is, during school time, which has caused outrage from conservative politicians and media. As part of this outrage, the argument was first raised that the protests may run counter to their goals by stirring discussions about the appropriateness of their methods, and thereby divert attention from climate policy issues themselves.^[Supporters of the movement may claim that the argument is hypocritical and is mostly used by persons who are actually opposed to climate policy.]

A contrary (or complimentary) strategy is taken by _Letzte Generation_ (originally _Aufstand der Letzten Generation_, ALG), which was founded by the participants of a hunger strike during the pre-election phase in 2021 [@LetzteGeneration2023]. Since 2021 the group -- consisting only of dozens or hundreds of members -- employs highly disruptive tactics: most prominently unregistered sit-ins on car highways, as well as supplementary action forms including throwing soup at paintings (which are protected by glass sheets), turning off oil pipelines, or vandalizing symbols of climate-afflicting luxury. The group has concrete demands including a citizen's assembly on climate policy, a ban on food waste, a speed limit for cars, and heavily subsidized public transport tickets. The protesters face a vast backlash, are criticized by politicians from across the poltical spectrum as well as by many media formats, and are pursued under terrorism laws by public prosecutors (who in Germany report to the regional governments); at the same time they have successfully negotiated with multiple mayors to support their concern, have held talks with the chancellor and the minister for traffic, and have been endorsed by the UN general secretary and by some religious organizations. Again, and this time perhaps with even more plausibility, the argument has been raised that the caused disruption runs counter to the goals of the group by diverting attention from climate change policy issues themselves, and by annoying the public.^[A version of this argument is presented by @jansteckelKlimaprotestAufAbwegen2022, and not without [controversy](https://twitter.com/jan_c_steckel/status/1601048858129477632).]

@moreincommonWieSchautDeutsche2023 survey support for the German climate protest movement in 2021 and 2023 and see an roughly 50% decline in support across the sociopolitical spectrum, which is accompanied by widespread disapproval of street blockades (mostly associated with ALG). @gonzattiAnalyseberichtZurStudie2023 use an "experimental" setting where participants are told about a fictitious climate protest in Germany, and also find low approval for street blockades and soup throwing, but do not find a positive or negative impact on support for climate policy for any protest form.
