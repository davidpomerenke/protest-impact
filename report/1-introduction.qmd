<!--

The difference between the goals and/or context of the thesis with existing solutions (e.g. found in literature) were studied and clearly described to support the problem definition, clearly indicating the innovative part of the thesis task.

the introduction defines the problem, sets it in terms of the state-of-the-art and clearly indicates what the contribution of the thesis is

 -->

## Introduction

### Problem statement

Are protests effective, and how much? Or do they also backfire, by distracting from the discussion of the protest concern, and by merely causing discussion about the protests themselves? Protest groups, participants, supporters, and opponents can use media impact analysis and count the number of newspaper articles that appear to be caused by a protest event. Such analyses may be biased due to possible confounding: Protests and increased media coverage may stem from shared sources. In the case of climate protests, extreme weather events, climate conferences, political decisions, or the intensity of public discussion are candidates for such confounders, and there may also be hidden confounders that do not easily come to mind.

<!--

At least three research questions are present and relevant.
+ research questions are well-positioned in the research context.
+ research questions are well-positioned in the literature.

 -->

__Research questions.__ This master thesis applies and evaluates multiple causal inference techniques that aim to rigorously estimate the causal impact of protest events on regional newspaper coverage. The methods are _regression_, _instrumental variables_[@staigerInstrumentalVariablesRegression1997], _synthetic control_ [@abadieSyntheticControlMethods2010], and _propensity score_ methods [@rosenbaumModelBasedDirectAdjustment1987]. Specifically, I aim to answer the following research questions:

1. Can the causal methods be applied to study the impact of protest events on newspaper attention? What limitations apply, and what problems occur? Are the estimates consistent, and how do they differ from each other?

2. What is the _Average Treatment Effect on the Treated_[^ATT] (ATT) of protest events on newspaper coverage; for climate protests in general, and with respect to the protest group that organizes the protest?

3. What can we say about the hypothesis that climate protests _distract_ from discussing solutions to the climate crisis constructively?

4. (Are datasets obtained (a) from authorities or (b) via semi-automated collection and processing suitable alternatives to manually curated protest event data?) - _I hope that I can still compare the datasets, otherwise I'll leave it out._

[^ATT]: The _Average Treatment Effect on the Treated_ (ATT) is the effect that the protests that took place have actually caused, on average, in comparison to the case that they had not taken place. It differs from the _Average Treatment Effect_ (ATE) by focusing on the effect of the protest days rather than the potential effect of all days. See @sec-app2-reg for mathematical definition.

__Protest event analysis.__ @hutterProtestEventAnalysis2014 gives the sociological foundations by definint the method of _protest event analysis_, and discusses coding methods for defining and distinguishing protest events.

__Protest impact.__ Research into the impact of protest movements has recently been spearheaded by a series of literature reviews and expert interviews by Ozden and Glover. In the context of effective altruism, they aim to assess how effective protest movements are as a means for political change, and what factors determine their success. In their literature review on protest outcomes @jamesozdenLiteratureReviewProtest2022, they conclude that _causal inferences on protest outcomes are generally challenging to draw due to confounding, and it is even harder to determine the long-term effect_. They warn that the average effect size of protests is likely over-estimated in the existing literature, due to selection bias on the level of media coverage, researcher interest, and statistical significance (publication bias). Based on their review, they estimate that protest movements (consisting of many single protest events) may raise salience and support for the issue by 2-10%, and may influence voting behavior by 1-6 percentage points. The influence on public discourse may be high in certain cases, and in the case of the Black Lives Matter movement may have amplified coverage by a factor of 10.

In interviews with researchers, @jamesozdenExpertInterviewsProtest2022 establish that while there is much research on protest outcomes, the causal connections between protests and their outcomes are an underexplored research area (interview with Robyn Gulliver in the cited report); that a causal link between protests and certain outcomes is plausible, but hard to attribute to any specific protest group (interview with Ruud Wouters in the cited report); and that causal effects are typically only measurable only on a local level due to the lack of a control group at the national level. More generally, protest outcomes may be subject to confounding, and the causal arrow between protests and increased concern may point in either direction. The interviews with researchers, as well as interviews with UK policymakers [@jamesozdenPolicymakerInterviewsProtest2022], suggest that the causal effect of protest on policy is strongly if not completely mediated by public opinion.

In a follow-up, [@samgloverLiteratureReviewProtest2022; @jamesozdenWhatMakesProtest2023] review the factors that causally affect the success of protest movements. They attribute a high importance to the number of participants, and to the nonviolent nature of the protest, as well as a favourable sociopolitical context, including media coverage. A moderate effect is attributed to the diversity and the unity of the movement. They also look at the so-called _radical flank effect_, a theory that moderate movements benefit from the simultaneous presence of a more radical movement for the same issue. Their review finds moderate effects from a radical flank, but only if the radical flank is also nonviolent.

__Relevance of newspaper coverage.__ Protest movements are often highly strategic [see @englerThisUprisingHow2016 for discussion]. Newspaper coverage is a typical criterion by which protest groups and funding organizations quantify impact: Four of the most relevant German climate protest groups maintain press review databases ([1](https://fridaysforfuture.de/presse/pressespiegel/), [2](https://letztegeneration.org/presse/berichterstattung-1/), [3](https://extinctionrebellion.de/presse/pressespiegel/), [4](https://www.ende-gelaende.org/pressespiegel/)), and a major international protest funding organizations uses the "number of triggered media items" as one of three evaluation criteria [@knuthFinanzierungKlimaaktivismusAm2023]. The reason is either that the protests aim to raise public attention in the first place, or that they consider media coverage as a proxy for further impact, including eventually policy change. Protests are directly observed by typically only a small number of people, and it is plausible that media coverage is an important mediator for further impact (todo: find citation). Alternative plausible mediators are social media posts, public opinion (as measured in opinion surveys), or parliamentary speech. For methodical reasons (see @sec-data-discourse), I focus on newspaper data, and more specifically _regional_ newspaper articles, because they allow for the application of the synthetic control method. These methodical decisions may well be considered as "looking under the lamppost" (@fig-lamppost), but they may enable the analysis of more interesting data in the future.

!["Looking under the lamppost" by [Sketchplanations](https://sketchplanations.com/) (CC-BY-NC)](figures/lamppost.png){.column-margin #fig-lamppost}

__Causal impact evaluation.__ Academic work on protest impact analysis is aware of the problem of confounding. Previous work has used _regression_, _difference-in-differences_, and to a large extent the _instrumental variables_ method (see @sec-lit-causal). With a single exception [@huet-vaughnQuietRiotCausal2013], the aggregate impact of protest movements that stretch over longer timespans is evaluated, rather than the impact of single events. Causal inference has developed the _synthetic control method_ [@abadieSyntheticControlMethods2010] for the analysis of single events, as well as extensions including _synthetic difference-in-differences_ [@arkhangelskySyntheticDifferenceinDifferences2021] and _Bayesian structural time series_ [@brodersenInferringCausalImpact2015a]. _Propensity score methods_ are not specifically made for the analysis of events but can be easily adapted by using time series data for the estimation of the propensity scores. Alternatively, they can be estimated from full text data [@keithTextCausalInference2020; @weldAdjustingConfoundersText2022]. _Event history analysis_ [@tekleEventHistoryAnalysis2012] is concerned with estimating the risk of the occurrence of events, which is not my research objective, but is relevant because it is similar to estimating propensity scores from time series. Related work using causal approaches for protest impact analysis is reviewed in more detail in @sec-lit-causal.

<!--

Research has advanced state of the art. Described thesis research would lead to a publication in an international peer-reviewed journal or an international peer-reviewed conference.

The research itself is very theoretical or highly interdisciplinary requiring the student to read into both challenging and theoretical material well beyond the scope of the programme.
+ this attitude is constructive and well-balanced.

 -->

__Contribution.__ TODO

<!-- - IV for single events
- SC for many single events
- PS for texts
- automated dataset
- complete dataset -->

### Literature review

#### Impact of protests on newspaper coverage

WIP: still have to tidy this up.

The "protest paradigm" [@mcleodManufacturePublicOpinion1992] theorizes that news coverage of protesters tends to be a double-edged sword, because the coverage of protests that challenge the status quo is usually negative. This paradigm is recently being challenged, and the formation of amore nuanced theory is underway that considers under what conditions the protest paradigm does or does not hold [see @harlowNewProtestParadigm2023].

@schwartzParadoxConfrontationExperimental2016: protests themselves have a negative impact on public support, but media coverage has a positive impact

@cristanchoProtestersNewsGates2022 investigate experimentally how different features of protests as well as of journalists have an impact on the prominence of the protests in the news (measured by front-page placement), finding that protest size is the most important feature

@hellmeierSpotlightAnalyzingSequential2018 find support for their hypothesis that salient protest events that receive a lot of media coverage lead to a higher coverage of subsequent protest events, and that the effect decreases with spatial and temporal distance.

@barrieDoesProtestInfluence: time series effects on tweets by uk mps, recent and very nice (not strictly causal, but really plausible; or could perhaps consider it a discontinuity design)

@chenHowClimateMovement2023a analyze the coverage of the climate movement on Twitter as well as in online newspapers. They use topic modelling to find major themes in discourse, and plot the quantitative evolution of these themes over time from 2018 to 2021, overlaying it with information about the occurrence of the semi-annual global climate strikes.

@AttentionClimateChange2023 find that the Covid-19 pandemic has led to a fewer discussion of climate protests on Twitter, albeit not to fewer discussion of the climate crisis itself.

Todo: Teune, Wasow, maybe Repke.

#### Causal approaches to protest event analysis {#sec-lit-causal}

In the context of protest event analysis, the most commonly used methods are: _regression_ with an extensive set of control variables; _difference in differences_; and the _instrumental variable_ method, mostly using rainfall or precipitation as an instrument. To my best knowledge, the synthetic control method and propensity score methods have not previously been applied to protest event analysis.

__Instrumental variables.__

_Instrumental variables_ is a commonly used method for causal impact estimation. Most related work investigates aggregate impacts from longer timespans (a week or a month), and the causal outcomes are often temporally separate (for example, the outcome of protests on election is estimated, where the election takes place multiple months after the protest period); With the exception of @huet-vaughnQuietRiotCausal2013, all previous literature has a setting where they look at a fixed timeframe and compare effects across regional units. Only @huet-vaughnQuietRiotCausal2013 have a methodical approach that is more similar to mine, looking at a larger dataset where events are scattered across regions and also across time.

- @collinsEconomicAftermath1960s2007 use rainfall and local political structure as instruments to investigate the effect of riot severity on the later development of property values. They use rainfall in the month following the assassination of Martin Luther King, during which many protests occurred across the US, as an instrumental variable.

- @madestamPoliticalProtestsMatter2013 use rainfall as an instrumental variable to measure the effect of Tea Party rallies on votes for the Republican Party in the US. They use rainfall on a single important day of Tea Party rallies across counties in the US to measure the effect of additional protesters on Republican Party vote share half a year later, finding that an additional protester leads to way more additional votes than just a single one. They also measure the effect on newspaper coverage of the Tea Party, and find increased attention especially during later important Tea Party events. They operationalize rainfall as a dummy variable of whether there were at least 0.1 inches (2.5 mm) of rainfall.

- @huet-vaughnQuietRiotCausal2013 investigate the effect of protest violence on protest "success" across 15 years of single (potentially multi-day) protest events in France, using precipitation and temperature as instrumental variables. They operationalize precipitation as a dummy variable representing whether there was some precipitation during any day of a series of protest days, and temperature as a dummy variable about whether the maximum temperature during these days falls in the range of 60-75° Fahrenheit (16-24° Celsius), which is derived from studies about the effect of temperature on disorderly conduct.

- @negroWhichSideAre2019 are interested in the effect of the size of LGBTQ protests on the presence of "movement-affiliated organizations". They use two instrumental variables, the first one measuring whether the precipitation on the protest date exceeds 2.5 mm (as per @madestamPoliticalProtestsMatter2013), and the second one being the average rainfall in the last 10 years on the $\pm3$-day window around the protest date.^[In my opinion this is a good idea but it should be labeled as a control, not as an instrument. See @sec-meth-data-instr for discussion.] They find the first instrument to have a statistically significant effect on the protest size ($p<0.01$), but not the second one ($p\geq 0.05$).

- @wasowAgendaSeedingHow2020 use rainfall in the month following the murder of Martin Luther King to estimate the effect of violent protests on the vote share of the Democratic Party in the US in the elections half a year later. They operationalize rainfall as "average rainfall in millimeters from weather stations within a 50 mile radius of the county center." Using two-stage least-squares regression, they find a significant shift in vote share in predominantly white counties due to protests in the first week after the assassination. They also apply placebo tests using rainfall from the week before the assassination, and from the remainder of the month after the assassination (containing only 5% of the protests from that month), and do not find significant effects for either of them, which strengthens their result.

- @kleinteeselinkWeatherProtestEffect2021 use rainfall as an instrument to determine the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They use rainfall from the two weeks following the murder of George Floyd by the police to measure the effect of the per-county number of total protest attendees during this time window on the election half a year later. (A very similar setting as above.) They use a linear variable to operationalize rainfall. They use the "probability of rain" to control for "general climatic conditions that may correlate with voting-relevant characteristics such as the average age, income, and ethnic composition of a county." The operationalization and motivation for this are a bit unclear.^[I find it plausible that the rain forecast may be relevant because the organizers may decide already a few days in advance of the protest whether or not it should take place, and for this decision they cannot rely on the actual weather but merely on the forecast.] Moreover they stress the importance of taking spatial depencies into account, and solve the problem using a spatial weighting matrix. They use demographic control variables (racial composition and median age) as well as economic control variables (median income and unemployment rate) for all regression steps. Placebo tests for first-stage linear regression show that the coefficients for the effect of weather on protest attendance is much lower for time windows before the protests took place, but still highly statistically significant.

- @carenBlackLivesMatter2023 use multiple weather variables, also to estimate the effect of the _Black Lives Matter_ protests on votes for the Democratic Party in the US. They operationalize days with _bad weather_ as days with either a maximum temperature above 90° Fahrenheit (32° Celsius), more than 0.1 inches (2.5 mm) of precipitation, or a wind speed of more than 10 mph (16 km/h). As their instrument they use the number of days with bad weather during the month that followed the murder of George Floyd by the police. Their treatment is _protest intensity_, which they define as the inverse hyperbolic sine (which behaves similarly to the logarithm) of the cumulative protest size, divided by the population size of the county. They use a large list of sociodemographic and political variables on the county level as control variables for all regression steps.

Other literature TODO uses instruments that are less clearly random, such as whether the protest took place on a Friday, its distance to focal points, the commute time in the city where the protest takes place, or even sociological variables concerning the political structure and efficiency. Arguing that such instruments are valid requires solid expert knowledge (and perhaps insider knowledge), and such instruments are therefore less suitable for a data-driven analysis as I envision it here. (Even the weather variable is not completely free from such problems, unfortunately, as is discussed in the next section.)

TODO: add citations

TODO literature that uses diff-in-diff

### Causal impact estimation {#intro-causal}

TODO: I'll go over this again, tidy it up and make it a bit more precise. And add citations for the methods and references to @sec-app2 with the formulas.

<!-- Causality[^invented by Spohn xxxx] -->

Here I give an overview of the causal model that I generally assume. Then I give an overview of the different causal methods used in this project, how they exploit the causal model, and what additional assumptions they make.

<!-- Since _time series methods_ may be used in various contexts, I also briefly introduce their structure and show how they can be applied to various machine learning problems that arise as part of the causal methods. -->

```{dot}
// | label: fig-causal-graph-simple
// | fig-cap: Simple causal graph showing the structure of the research problem, ignoring the time-series aspect. I want to determine the effect of the treatment __W__ on the outcome __Y__, and there are known confounders __X__, but also unknown confounders __U__ that influence both treatment and outcome and thus complicate the matter. Instrumental variables __Z__ may help, because they only affect the outcome via their effect on the treatment.
// | fig-width: 180px
// | fig-height: 120px
// | column: body
// | fig-pos: 'H'
digraph D {
  rankdir=LR
  {X, U} -> {W, Y}
  {Z} -> {W}
  {W} -> {Y} [color=green]
}
```

TODO: fix figure number

@fig-causal-graph-simple shows a typical causal situation: The impact of the treatment __W__ on the outcome __Y__ is of interest. Both treatment and outcome are also affected by known confounders __X__ and unknown confounders __U__. Instruments __Z__ affect the treatment, but do not have a direct impact on the outcome.

The core of the model is the relation $W \rightarrow Y$ that I want to investigate. However, there are multiple problems of increasing difficulty:

1. The outcome __Y__ is affected not only by the treatment but also by the covariates __X__. This is a common situation, even in experiments that are randomized, and we can approach it, for example, by using regression to control for the covariates.
2. Not only the outcome __Y__, but also the treatment __W__ is affected by the covariates __X__, which makes them _confounders_. This is a common feature of observational studies. We can use methods based on the _propensity score_ (the probability of receiving the treatment) to approach this problem, as long as we know all relevant confounders.
3. There are likely unknown confounders __U__. We are dealing with a sociological situation where a lot of variables could potentially be relevant. For example, external events like elections, legislative processes, or conferences could play a big role. Or the current mindset and stress level of journalists could play a role. Or many other things, that we may not even think of. Even though we cannot list all of these variables, there are alternative approaches:
   1. Assuming that the unknown confounders affect all regions similarly, we can make cross-region comparisons, for example, by using the __*synthetic control*__ method.
   2. We can leverage __*instrumental variables*__ __Z__, for which we assume that they do not affect the outcome __Y__ directly, and trace their effect on __Y__ via the treatment __W__.
   3. We can assume that certain texts such as press releases may cover many relevant unknown confounders, and learn __*propensity scores from texts*__, without needing to specify the confounders explicitly.

All three methods can be combined with controlling for known confounders. The following table gives an overview over the methods, which causal inference principles they use, what data they rely on, and whether they are useful for dealing with know and unknown confounders:

:::{.column-body}

\begin{tabular}{l| c c c c}
& Regression & Instr. var. & Synth. contr. & Prop. score \\
\hline
Instrumenting & & \bullet &  &  \\
Controlling & \bullet & (\bullet) & (\bullet) & (\bullet) \\
Balancing &  &  & \bullet & \bullet \\
\hline
Time series & \bullet & (\bullet) & (\bullet) & \bullet \\
Regions &  &  & \bullet &  \\
Weather &  & \bullet &  &  \\
Texts &  &  &  & (\bullet) \\
\hline
Confounders? & $\checkmark^1$ & $\checkmark^2$ & $\checkmark^3$ & $\checkmark^4$ \\
Hidden conf.? &  & $\checkmark^2$ & $\checkmark^3$ & $\checkmark^{4,5}$ \\
\end{tabular}

Core assumptions:$^1$ Linearity;$^2$ Valid instrument;$^3$ No regional confounding;$^4$ Overlap;$^5$ Hidden confounding is captured by text.

:::

Here I give a conceptual overview of the 3 mentioned methods that are potentially suitable for dealing with unknown confounders. Mathematical assumptions and definitions are given in @sec-app2.

```{dot}
// | label: fig-causal-graph-corr
// | fig-cap: Causal graph for naive analysis.
// | fig-width: 100px
// | fig-height: 100px
// | column: margin
digraph D {
  {W, X} -> {Y} [color=blue]
}
```

__Correlation.__ Naive regression is not a causal method, but is used for comparison with the causal methods. It neglects most of the causal model and only regards the direct relationship between treatment and outcome, possibly controlling for covariates, but neglecting their role as confounders. The result is known as the _prima facie_ causal effect. It suffers from _selection bias_, because the model does not take the treatment assignment process into account -- but it should, because the treatment is not randomized.

```{dot}
// | label: fig-causal-graph-reg
// | fig-cap: Causal graph for regression.
// | fig-width: 100px
// | fig-height: 100px
// | column: margin
digraph D {
  {W, X} -> {Y} [color=blue]
}
```

__Regression.__ Controlling for the known confounders can already help to substantially reduce the bias, especially if the relationships are linear, and may as well be considered a causal method.

```{dot}
// | label: fig-causal-graph-iv
// | fig-cap: Causal graph for the instrumental variable method.
// | fig-width: 150px
// | fig-height: 150px
// | column: margin
digraph D {
  {W} -> {Y}
  {Z} -> {W} [color=blue]
  {X} -> {W, Y}
}
```

__Instrumental variables.__ The _instrumental variable_ approach leverages _natural experiments_, where a random variable (or an almost random variable) influences the treatment. The _exclusion restriction_ (see @sec-app2-iv) assumes that the instrument does not have a direct impact on the outcome, but only via the treatment. We can then trace how the instrument affects the outcome via the treatment, and thereby establish the causal impact of the treatment on the outcome.

... This is especially true for approximately random variables, such as the weather. (The weather is not purely random but also contains regional and seasonal components; but we can try to isolate them or work around the problem.)

In the simplest case, we can compare the effect of __Z__ on __W__ with the effect of __Z__ on __Y__ to obtain the desired estimate for the effect of __W__ on __Y__. We can also apply _two-stage_ approaches to first isolate the part of __W__ that is caused by __Z__, and then estimate its impact on __Y__.

Thanks to instrumental variables, we can legitimately ignore the unknown confounders. A requirement is always that the instrument is valid and sufficiently strong, that is, that it has a strong effect on the treatment __W__.

```{dot}
// | label: fig-causal-graph-synth
// | fig-cap: Causal graph for the synthetic control method.
// | fig-width: 180px
// | fig-height: 220px
// | column: margin
digraph D {
  {X, U} -> {W} -> {Y}
  {X, U} -> {Y}
  {region} -> {U} [style=dotted, color=blue, label="determine"]
  {date} -> {U} [style=dotted, color=blue]
}
```

__Synthetic control.__ The synthetic control method [@abadieSyntheticControlMethods2010; @cunninghamCausalInferenceMixtape2021, ch. 10] leverages the idea of comparing a region where a protest happens with other regions where no protest happens on the same day. However it goes beyond a simple comparison. Instead it constructs a _synthetic region_ from all the control regions that is as close as possible to the treatment region. The synthetic region can then be used to model the counterfactual of no protest for the treatment region.

The underlying assumption for the synthetic control method is that the unknown confounders affect the different regions uniformly: On any given day, the impact of the confounders is the same for all regions. This assumption is plausible especially for confounders coming from global and national politics and events; it is violated by regional confounders, but maybe they are not so important and we can live with it.

Under this assumption, we can perform matching based on the date: To estimate the impact of a protest group in one region on a given date, we find other regions where no such event has taken place, and compare the effect.

The synthetic control method goes a bit further and also takes the effect of known differences between the regions into account. From all the available control regions, it constructs a _synthetic region_. The synthetic region interpolates between the control regions such that the interpolated region is as close as possible to the treatment region in some respect. This interpolation can be performed in terms of sociodemographic similarity, or in terms of maximizing the predictive accuracy of the outcome variable, based on past observations. (This is a bit of a simplification, the details are explained in @sec-synth.)

```{dot}
// | label: fig-causal-graph-prop
// | fig-cap: Causal graph for propensity score methods.
// | fig-width: 100px
// | fig-height: 150px
// | column: margin
digraph D {
  {W} -> {Y}
  {X} -> {W} [color=blue]
  {X} -> {Y}
}
```

__Propensity scores.__ Propensity score methods help to remove the impact of _known_ confounders. They rely on the propensity score that specifies how likely it is that a protest occurs on a given date and in a given region. They can be computed from knowledge about the region and the date, and from lagged treatment and outcome data from the previous days. To account to some extent for the impact of _unknown_ confounders, I also obtain propensity scores from press releases about climate-related events.

Propensity score methods estimate the probability (propensity) of receiving the treatment. There are various strategies for eliminating selection bias with the use of propensity scores: notably propensity score matching, propensity score stratification, inverse propensity weighting. Double machine learning estimators such as causal forests help with estimating heterogenous treatment effects.

Propensity score methods still suffer from _omitted variable bias_ if there are unknown confounders. This can be mitigated by learning propensity scores from less structured big data such as texts, using classification models from natural language processing. The advantage of doing so is that the unknown confounders need not be pre-specified. The assumption is that the texts need to contain all of the unknown confounders, and in some detectable form. While this will never completely be the case (and cannot be verified anyway), I can hope that it at least substantially reduces the bias.

__Time-series modelling.__ The variables on one day may also be influenced by the same set of variables from the previous day. On the one hand, this makes modeling more complicated. On the other hand, it is an advantage, because we have the data from the previous days already in the dataset, and using them can help reduce the amount of unknown confounding. Specifically, I consider all variables from the previous day as potential confounders for the current day. Variables from multiple days earlier may still be relevant, but less so, so it will be acceptable to make a cutoff at some point. We can restrict the previous variables to those from the same region, or we can also include previous variables from other regions where it seems useful. ...

```{dot}
// | label: fig-causal-graph-time-series
// | fig-cap: TODO fix the graph! Version of the causal graph (@fig-causal-graph-simple) from a time series perspective. The variables of each day are influenced by the variables from the previous days in the same region. We can model that by including all variables from one day as potential confounders for the following day.
// | fig-width: 200px
// | fig-height: 400px
// | column: margin

digraph D {
  rankdir=LR
  compound=true

  U0 [label="U"]
  W0 [label="W"]
  X0 [label="X"]
  Y0 [label="Y"]
  Z0 [label="Z"]

  U1 [label="U"]
  W1 [label="W"]
  X1 [label="X"]
  Y1 [label="Y"]
  Z1 [label="Z"]

  U2 [label="U"]
  W2 [label="W"]
  X2 [label="X"]
  Y2 [label="Y"]
  Z2 [label="Z"]

  subgraph cluster_0 {
    label="Day -2"
    {X0, U0} -> {W0} -> {Y0}
    {X0, U0} -> {Y0}
    {Z0} -> {W0}
    dummy_0 [shape=point style=invis constraint=false]
  }
  subgraph cluster_1 {
    label="Day -1"
    {X1, U1} -> {W1} -> {Y1}
    {X1, U1} -> {Y1}
    {Z1} -> {W1}
    dummy_1 [shape=point style=invis constraint=false]
  }
  subgraph cluster_2 {
    label="Day 0"
    {X2, U2} -> {W2} -> {Y2}
    {X2, U2} -> {Y2}
    {Z2} -> {W2}
    dummy_2 [shape=point style=invis constraint=false]
  }
  dummy_0 -> X1 [ltail=cluster_0 style=dotted label="include\nvariables" constraint=false]
  dummy_1 -> X2 [ltail=cluster_1 style=dotted label="include\nvariables" constraint=False]
}
```


### Case study

__Greenpeace (GP), Ende Gelände (EG), Extinction Rebellion (XR).__ The climate protest movement in Germany has only stepped into existence toward the end of the 2010's. Before then, climate activism was mostly associated with established environmental NGOs such as Greenpeace, which did not play a major role in the media. In 2015 the activist formation _Ende Gelände_ (EG) was established, and began organizing occupations, blockades, and demonstrations directly in coal mining areas [@EndeGelaende2023]. In late 2018 _Extinction Rebellion_ (XR) was established in Germany to protest the biodiversity crisis that comes along with the climate crisis, through demonstrations as well as blockades [@ExtinctionRebellion2023].

__Fridays for Future (FFF).__ Around the same time, the global _Fridays for Future_ (FFF) movement gained traction in Germany, accumulating a huge momentum -- more than a million protesters --, especially among high school and university students, and later also among other social groups with sub-movements such as _Scientists for Future_, _Parents for Future_, and _Grandparents for Future_ [@FridaysFuture2023]. They emphasize constructive discourse and inclusivity, organize exclusively pre-registered demonstrations, and often collaborate with other protest groups. However, they mostly protest on Fridays, that is, during school time, which has caused outrage from conservative politicians and media. As part of this outrage, the argument was first raised that the protests may run counter to their goals by stirring discussions about the appropriateness of their methods, and thereby divert attention from climate policy issues themselves.^[Supporters of the movement may claim that the argument is hypocritical and is mostly used by persons who are actually opposed to climate policy.]

__Letzte Generation (ALG) and controversy.__ A contrary (or complimentary) strategy is taken by _Letzte Generation_ (originally _Aufstand der Letzten Generation_, ALG), which was founded by the participants of a hunger strike during the pre-election phase in 2021 [@LetzteGeneration2023]. Since 2021 the group -- consisting only of dozens or hundreds of members -- employs highly disruptive tactics: most prominently unregistered sit-ins on car highways, as well as supplementary action forms including throwing soup at paintings (which are protected by glass sheets), turning off oil pipelines, or vandalizing symbols of climate-afflicting luxury. The group has concrete demands including a citizen's assembly on climate policy, a ban on food waste, a speed limit for cars, and heavily subsidized public transport tickets. The protesters face a vast backlash, are criticized by politicians from across the poltical spectrum as well as by many media formats, and are pursued under terrorism laws by public prosecutors (who in Germany report to the regional governments); at the same time they have successfully negotiated with multiple mayors to support their concern, have held talks with the chancellor and the minister for traffic, and have been endorsed by the UN general secretary and by some religious organizations. Again, and this time perhaps with even more plausibility, the argument has been raised that the caused disruption runs counter to the goals of the group by diverting attention from climate change policy issues themselves, and by annoying the public.^[A version of this argument is presented by @jansteckelKlimaprotestAufAbwegen2022, and not without [controversy](https://twitter.com/jan_c_steckel/status/1601048858129477632).]

__Related work on the German climate movement.__ @moreincommonWieSchautDeutsche2023 is a survey on support for the German climate protest movement in 2021 and 2023. Over this period they find a roughly 50% decline in support across the sociopolitical spectrum, which is accompanied by widespread disapproval of street blockades (mostly associated with ALG). @gonzattiAnalyseberichtZurStudie2023 use an "experimental" setting where participants are told about a fictitious climate protest in Germany, and also find low approval for street blockades and soup throwing, but do not find a positive or negative impact on support for climate policy for any protest form.
