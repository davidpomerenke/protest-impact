## Modeling and overview of methods

Here I give an overview of the causal model that I generally assume. Then I give an overview of the different causal methods used in this project, how they exploit the causal model, and what additional assumptions they make. Since _time series methods_ may be used in various contexts, I also briefly introduce their structure and show how they can be applied to various machine learning problems that arise as part of the causal methods.

We can group the variables from the dataset described in @sec-data into 4 causal categories, and add another category for variables that we do not know but that might be relevant. The _treatment units_ are _days_, and data is available for multiple regions. For each day in a given region, we have data in the following categories:

- Treatment __W__:
  - For each protest group, a dummy variable whether it organizes at least one protest event in the given region (_binary treatment_)^[Alternatively, I could use for each protest group the number of protesters in the given region as a _continuous treatment_; but this requires (a) slightly more complicated methods to deal with continuous treatments, and (b) difficult assumptions about scaling -- is the effect linear, logistic, or more complicated?]
- Outcome __Y__:
  - Number of newspaper articles published that mention the climate crisis, across 5 dimensions (see @sec-data-discourse): overall mentions; mentioning protest activity; mentioning long-term goals; mentioning specific short-term goals; using a drastic or catastrophic framing.
- Instruments __Z__:
  - Weather: min/max/avg temperature, air pressure, precipitation, snowfall, wind speed, and peak gust
  - Covid restrictions: stringency index of the restrictions, and movement variables for 6 location types
- Known confounders __X__:
  - Day of the week, as dummy variables
  - Holiday occurrence in the given region
  - Region:
    - represented as dummy variables
    - alternatively, represented using 29 sociodemographic indicators: voting behavior, average female income, ...
  - Time-series lags (that is, values from previous days) of some or all variables -- see @sec-time-series
- Unknown confounders __U__:
  - __?__



@fig-causal-graph-simple shows the causal relations between the 5 categories graphically.

```{dot}
// | label: fig-causal-graph-simple
// | fig-cap: Simple causal graph showing the structure of the research problem, ignoring the time-series aspect. I want to determine the effect of the treatment __W__ on the outcome __Y__, and there are known confounders __X__, but also unknown confounders __U__ that influence both treatment and outcome and thus complicate the matter. Instrumental variables __Z__ may help, because they only affect the outcome via their effect on the treatment.
// | fig-width: 180px
// | fig-height: 120px
// | column: body
// | fig-pos: 'H'
digraph D {
  rankdir=LR
  {X, U} -> {W, Y}
  {Z} -> {W}
  {W} -> {Y} [color=green]
}
```

The core of the model is the relation $W \rightarrow Y$ that I want to investigate. However, there are multiple problems of increasing difficulty:

1. The outcome __Y__ is affected not only by the treatment but also by the covariates __X__. This is a pretty common situation, even in experiments that are randomized, and we can approach it, for example, by using regression to control for the covariates.
2. Not only the outcome __Y__, but also the treatment __W__ is affected by the covariates __X__, which makes them _confounders_. This is a common feature of observational studies. We can use methods based on the _propensity score_ (the probability of receiving the treatment) to approach this problem, as long as we know all relevant confounders.
3. There are likely unknown confounders __U__. We are dealing with a sociological situation where a lot of variables could potentially be relevant. For example, external events like elections, legislative processes, or conferences could play a big role. Or the current mindset and stress level of journalists could play a role. Or many other things, that we may not even think of. Even though we cannot list all of these variables, there are alternative approaches:
   1. Assuming that the unknown confounders affect all regions similarly, we can make cross-region comparisons, for example, by using the __*synthetic control*__ method.
   2. We can leverage __*instrumental variables*__ __Z__, for which we assume that they do not affect the outcome __Y__ directly, and trace their effect on __Y__ via the treatment __W__.
   3. We can assume that certain texts such as press releases may cover many relevant unknown confounders, and learn __*propensity scores from texts*__, without needing to specify the confounders explicitly.

All three methods can be combined with controlling for known confounders. The following table gives an overview over the methods, which causal inference principles they use, what data they rely on, and whether they are useful for dealing with know and unknown confounders:

:::{.column-body}

\begin{tabular}{l| c c c c}
& Regression & Instr. var. & Synth. contr. & Prop. score \\
\hline
Instrumenting & & \bullet &  &  \\
Controlling & \bullet & (\bullet) & (\bullet) & (\bullet) \\
Balancing &  &  & \bullet & \bullet \\
\hline
Time series & \bullet & (\bullet) & (\bullet) & \bullet \\
Regions &  &  & \bullet &  \\
Weather &  & \bullet &  &  \\
Texts &  &  &  & (\bullet) \\
\hline
Confounders? & $\checkmark^1$ & $\checkmark^2$ & $\checkmark^3$ & $\checkmark^4$ \\
Hidden conf.? &  & $\checkmark^2$ & $\checkmark^3$ & $\checkmark^{4,5}$ \\
\end{tabular}

Core assumptions:$^1$ Linearity;$^2$ Valid instrument;$^3$ No regional confounding;$^4$ Overlap;$^5$ Hidden confounding is captured by text.

:::

### Overview of causal methods

Here I give a conceptual overview of the 3 mentioned methods that are potentially suitable for dealing with unknown confounders. Their exact assumptions and limitations will be discussed in their respective chapters.

In the context of protest event analysis, the most commonly used methods are: regression with an extensive set of control variables; and the instrumental variable method using rainfall as an instrument.
<!-- and _difference in differences_, which is conceptually similar to the synthetic control method. -->
To my best knowledge, the synthetic control method and propensity score methods with text have not previously been applied to protest event analysis.

#### Regression

```{dot}
// | label: fig-causal-graph-reg
// | fig-cap: Causal graph for naive analysis.
// | fig-width: 100px
// | fig-height: 100px
// | column: margin
digraph D {
  {W, X} -> {Y} [color=blue]
}
```

Naive regression is not a causal method, but is used for comparison with the causal methods. It neglects most of the causal model and only regards the direct relationship between treatment and outcome, possibly controlling for covariates, but neglecting their role as confounders. The result is known as the _prima facie_ causal effect. It suffers from _selection bias_, because the model does not take the treatment assignment process into account -- but it should, because the treatment is not randomized.

Controlling for the known confounders can already help to substantially reduce the bias, especially if the relationships are linear, and may as well be considered a causal method.

#### Instrumental variable

```{dot}
// | label: fig-causal-graph-iv
// | fig-cap: Causal graph for the instrumental variable method.
// | fig-width: 150px
// | fig-height: 150px
// | column: margin
digraph D {
  {W} -> {Y}
  {Z} -> {W} [color=blue]
  {X} -> {W, Y}
}
```

This method utilizes one or more instrumental variables. Valid isntruments affect the treatment but do not directly affect the outcome -- not via other paths and not even via confounding. This is especially true for approximately random variables, such as the weather. (The weather is not purely random but also contains regional and seasonal components; but we can try to isolate them or work around the problem.)

In the simplest case, we can compare the effect of __Z__ on __W__ with the effect of __Z__ on __Y__ to obtain the desired estimate for the effect of __W__ on __Y__. We can also apply _two-stage_ approaches to first isolate the part of __W__ that is caused by __Z__, and then estimate its impact on __Y__.

Thanks to instrumental variables, we can legitimately ignore the unknown confounders, which is really nice. A requirement is always that the instrument is valid and sufficiently strong, that is, that it has a strong effect on the treatment __W__.

#### Synthetic control

```{dot}
// | label: fig-causal-graph-synth
// | fig-cap: Causal graph for the synthetic control method.
// | fig-width: 180px
// | fig-height: 220px
// | column: margin
digraph D {
  {X, U} -> {W} -> {Y}
  {X, U} -> {Y}
  {region} -> {U} [style=dotted, color=blue, label="determine"]
  {date} -> {U} [style=dotted, color=blue]
}
```

The underlying assumption for the synthetic control method is that the unknown confounders affect the different regions uniformly: On any given day, the impact of the confounders is the same for all regions. This assumption is plausible especially for confounders coming from global and national politics and events; it is violated by regional confounders, but maybe they are not so important and we can live with it.

Under this assumption, we can perform matching based on the date: To estimate the impact of a protest group in one region on a given date, we find other regions where no such event has taken place, and compare the effect.

The synthetic control method goes a bit further and also takes the effect of known differences between the regions into account. From all the available control regions, it constructs a _synthetic region_. The synthetic region interpolates between the control regions such that the interpolated region is as close as possible to the treatment region in some respect. This interpolation can be performed in terms of sociodemographic similarity, or in terms of maximizing the predictive accuracy of the outcome variable, based on past observations. (This is a bit of a simplification, the details are explained in @sec-synth.)

#### Propensity scores

```{dot}
// | label: fig-causal-graph-prop
// | fig-cap: Causal graph for propensity score methods.
// | fig-width: 100px
// | fig-height: 150px
// | column: margin
digraph D {
  {W} -> {Y}
  {X} -> {W} [color=blue]
  {X} -> {Y}
}
```

Propensity score methods estimate the probability (propensity) of receiving the treatment. There are various strategies for eliminating selection bias with the use of propensity scores: notably propensity score matching, propensity score stratification, inverse propensity weighting. Double machine learning estimators such as causal forests help with estimating heterogenous treatment effects.

Propensity score methods still suffer from _omitted variable bias_ if there are unknown confounders. This can be mitigated by learning propensity scores from less structured big data such as texts, using classification models from natural language processing. The advantage of doing so is that the unknown confounders need not be pre-specified. The assumption is that the texts need to contain all of the unknown confounders, and in some detectable form. While this will never completely be the case (and cannot be verified anyway), I can hope that it at least substantially reduces the bias.

### Time-series modelling {#sec-time-series}

The variables on one day may also be influenced by the same set of variables from the previous day. On the one hand, this makes modeling more complicated. On the other hand, it is an advantage, because we have the data from the previous days already in the dataset, and using them can help reduce the amount of unknown confounding. Specifically, I consider all variables from the previous day as potential confounders for the current day. Variables from multiple days earlier may still be relevant, but less so, so it will be acceptable to make a cutoff at some point. We can restrict the previous variables to those from the same region, or we can also include previous variables from other regions where it seems useful.

```{dot}
// | label: fig-causal-graph-time-series
// | fig-cap: Version of the causal graph (@fig-causal-graph-simple) from a time series perspective. The variables of each day are influenced by the variables from the previous days in the same region. We can model that by including all variables from one day as potential confounders for the following day.
// | fig-width: 200px
// | fig-height: 400px
// | column: margin

digraph D {
  rankdir=LR
  compound=true

  U0 [label="U"]
  W0 [label="W"]
  X0 [label="X"]
  Y0 [label="Y"]
  Z0 [label="Z"]

  U1 [label="U"]
  W1 [label="W"]
  X1 [label="X"]
  Y1 [label="Y"]
  Z1 [label="Z"]

  U2 [label="U"]
  W2 [label="W"]
  X2 [label="X"]
  Y2 [label="Y"]
  Z2 [label="Z"]

  subgraph cluster_0 {
    label="Day -2"
    {X0, U0} -> {W0} -> {Y0}
    {X0, U0} -> {Y0}
    {Z0} -> {W0}
    dummy_0 [shape=point style=invis constraint=false]
  }
  subgraph cluster_1 {
    label="Day -1"
    {X1, U1} -> {W1} -> {Y1}
    {X1, U1} -> {Y1}
    {Z1} -> {W1}
    dummy_1 [shape=point style=invis constraint=false]
  }
  subgraph cluster_2 {
    label="Day 0"
    {X2, U2} -> {W2} -> {Y2}
    {X2, U2} -> {Y2}
    {Z2} -> {W2}
    dummy_2 [shape=point style=invis constraint=false]
  }
  dummy_0 -> X1 [ltail=cluster_0 style=dotted label="include\nvariables" constraint=false]
  dummy_1 -> X2 [ltail=cluster_1 style=dotted label="include\nvariables" constraint=False]
}
```

In time-series models, be it for forecasting or classification, the predictor variables usually fall into 3 categories:

- __Historic variables:__ Variables that are only available for past dates but not for the date of the prediction. This is especially true for the target variable^[The lags of the target variable are more specifically called an __autoregressive__ variable.]; since its future value should be predicted, it should not be present as a predictor.
- __Future variables:__ Variables whose values are available for past dates as well as the date of the prediction.
- __Static variables:__ These are time-independent.

@tbl-time-series gives an overview how these categories are applicable within the different causal methods.

::: {.column-page #tbl-time-series}

| Target | Predictors | Method |
| ------ | ---------- | ------ |
| __Y__ | \boldmath$X_{f,s}, Y_h, W_f$ | Regression |
| __Y__ | \boldmath$X_{f,s}, Y_h, W_f, Z_f$ | IV stage 1 |
| __W__ | \boldmath$X_{f,s}, Y_h, W_h, Z_f$ | IV stage 1 |
| __Y__ | \boldmath$X_{f,s}, Y_h, W_h, \hat W_f$ | IV stage 2 |
| __Y__ | \boldmath$X_{f,s}, Y_h, Y_{R_0f}$ | Synthetic control |
| __W__ | \boldmath$X_{f,s}, Y_h, W_h$ | Propensity score |

: Subscripts $\scriptsize f, h, s$ denote future, historic and static variables.

:::

\begingroup
\color{Blue}

### NEW Regional and national data

My setting throughout all methods is that I estimate models based on regional data. However, I do not fit separate models for each region, but always a single model on a dataset that includes all regions. This has the benefits that __(a)__ it leads to more generalizable results and __(b)__ it increases the size of the dataset by a factor of 14 (in comparison to using national data, or to estimating single regional models), and thereby increases statistical power.

To integrate multiple time series from the various regions into a single dataset, I add static __dummy variables__ for each region, as is common practice for time series data. To capture the effect of regional differences properly, it would be necessary to also add interaction terms of all 14 region dummies and all 5 treatment variables, as well as potentially some of the control variables. This would lead to at least 70 interaction terms, which would make the interpretation of the results much harder.

The __differences between the regions__ -- especially in size, population size, and number of newspapers -- are potentially problematic for the estimation of a global model. I minimize this problem by (a) including previous amounts of coverage and (b) using absolute rather than relative coverage. While the relative coverage of a protest event will presumably be lower in larger regions (because a smaller proportion of the region is affected by any event), this will not be the case in absolute terms. However, it may be the case that there are major protest events with a strong relation to regional politics, and that they have an impact throughout the whole region, and in that case the size of the region might matter. This would not be captured by the model and could lead to a high variance the treatment effect estimates.

On the other hand, the __national impact__ of protests is politically more interesting, so I also estimate a model on the national level, which has the structure as any of the regional models, but with aggregated treatment variables and newspaper coverage from national rather than regional newspapers.

### NEW Delayed and cumulative impact

Protests may have an impact on newspaper converage not only on the day that they occur but also in the following days and weeks. For estimating these delayed impacts, I do _not_ extend the lags of the outcome further into the future, because the amount of coverage on or after the protest date likely mediates the impact on future coverage. These mediated impacts are hard to isolate. By not including potential mediators in the predictors, I make sure that all indirect impacts are also clearly attributable to the treatment. I do _not_ extend the lags of the treatment further into the future either (mostly motivated by efficiency gains that are related to implementation details), so indirect impacts that are mediated by future protests (if they exist) are also included in the impact estimate.

Next to the impact for each single day, the cumulative impact is of interest. Point estimates (expected values) can be computed by summing the effects from multiple days. This is not so easy for the variance (and thus standard errors and confidence intervals), since the variance of the sum of the effects depends on their covariance. In regression models the covariance could be determined using multivariate regression, but `scikit-learn` does not support standard errors and the `statsmodels` library does not support multivariate regression, and the author is too lazy to learn `R`. Instead, I estimate separate models for each cumulative outcome variable; that is, a model for the 1-day impact, for the 2-day impact, for the 3-day impact, and so on.

### NEW Mathematical notation

I want to determine the _Average Treatment Effect on the Treated (ATT)_ $\tau_T$ for different protest groups^[CATT], and along multiple dimensions of newspaper coverage. I am not interested in the _Average Treatment Effect_ [on the whole population] that is often denoted by $\tau$, so I write $\tau:=\tau_T$.

[CATT]: This could also be framed as the _Conditional ATT_ (CATT), because the treatment effect is conditional on which group has protested on the day. I prefer to frame it as multiple separate ATTs. This has the benefit that I can control for the occurrence of other treatments on the same day, and thus better isolate the effects of single protest groups.

The treatment units are _days_, with a treatment vector $W = [W_1, ..., W_m], m = |G|$ containing the treatments for each group (that is, whether the given group has protested on that day), and an outcome vector $Y = [Y_1, ..., Y_n], n=|Y|$ containing the number of articles published on that day for each dimension of coverage.

The ATT is generally defined as follows [@dingFirstCourseCausal2023, ch. 13]:

$$
\tau = E(Y|W=1) - E(Y(0) | W=1)
$$

Considering the protest groups and coverage dimensions:

$$
\tau_{g,d} = E(Y_d|W_g=1) - E(Y_d(0) | W_g=1)
$$

\endgroup

###

- bootstrapping for comparable standard errors
- placebo tests to assess bias and variance
- cross-validation (ood with one year gap) of
  - regression -> prediction mse
  - iv -> f1 for predicting protests (first stage) (and mse for predicting coverage (second stage)) -- or just directly the outcome?
  - synth -> predictive quality within different pre-fit areas
  - prop scores -> prop score f1 -- and the outcome? (esp for doubly robust)
